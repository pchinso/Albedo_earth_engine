{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Earth Engine Variable Extraction Notebook\n",
    "\n",
    "This notebook provides functions to extract various environmental variables from Google Earth Engine (GEE) datasets. \n",
    "The primary goals are:\n",
    "- Define functions to retrieve specific variables based on user-defined parameters (region, time period, frequency).\n",
    "- For time-series data, aggregate it to hourly, daily, monthly, or yearly means.\n",
    "- Save the extracted data for each variable into a separate CSV file.\n",
    "\n",
    "**Instructions:**\n",
    "1. Run the GEE Authentication and Initialization cell first. You will need to authenticate with a Google account that has GEE access.\n",
    "2. Define your region of interest (AOI) as a GeoJSON-like dictionary.\n",
    "3. Call the specific extraction functions for the variables you need, providing the AOI, date range, frequency, and output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import csv\n",
    "import math # Ensure math is imported for potential calculations like wind\n",
    "import calendar\n",
    "\n",
    "# Optional: Folium for map display if needed later, can be commented out initially\n",
    "# import folium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger the authentication flow.\n",
    "# This will print a URL, open it, authorize, and copy the code back into the input box.\n",
    "try:\n",
    "    ee.Authenticate()\n",
    "except Exception as e:\n",
    "    print(f\"Authentication failed or already authenticated: {e}\")\n",
    "    # For automated environments or if auth was done in a previous session, \n",
    "    # this might raise an error if not needed, so we can often proceed.\n",
    "\n",
    "# Initialize the library. \n",
    "# Replace 'YOUR_GEE_PROJECT' with your actual GEE project ID if you have one,\n",
    "# otherwise, GEE often can use a default cloud project associated with your account.\n",
    "try:\n",
    "    ee.Initialize(project='YOUR_GEE_PROJECT') \n",
    "    print(\"GEE Initialized successfully.\")\n",
    "except Exception as e:\n",
    "    try:\n",
    "        # Fallback if project-specific initialization fails\n",
    "        ee.Initialize()\n",
    "        print(\"GEE Initialized successfully (default project).\")\n",
    "    except Exception as e_init:\n",
    "        print(f\"GEE Initialization failed: {e_init}\")\n",
    "        print(\"Please ensure you have authenticated and have a GEE-enabled project.\")\n",
    "\n",
    "# Define a helper to check GEE initialization status\n",
    "def check_gee_initialized():\n",
    "    try:\n",
    "        ee.ImageCollection('NASA/SRTM_GL1_003').limit(1).size().getInfo()\n",
    "        print(\"GEE is initialized and accessible.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"GEE not properly initialized or accessible: {e}\")\n",
    "        return False\n",
    "\n",
    "check_gee_initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Time Series Extraction Function\n",
    "def extract_gee_time_series(\n",
    "    variable_name: str,\n",
    "    region_geojson: dict, # GeoJSON dictionary for the region\n",
    "    start_date_str: str,\n",
    "    end_date_str: str,\n",
    "    frequency: str,  # 'hourly', 'daily', 'monthly', 'yearly'\n",
    "    gee_dataset_id: str,\n",
    "    gee_band_name: str, # Can be a list for multi-band calculations (e.g. wind)\n",
    "    scale: int,\n",
    "    output_dir: str,\n",
    "    gee_project: str = None, # Optional: GEE project for initialization if needed\n",
    "    reducer: ee.Reducer = ee.Reducer.mean(),\n",
    "    data_scaling_factor: float = None,\n",
    "    data_offset_factor: float = None,\n",
    "    post_process_function: callable = None, # Function to apply to the reduced value or dictionary of values\n",
    "    nan_value = None # Value to use if GEE returns None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Extracts time-series data from Google Earth Engine for a specified variable and frequency,\n",
    "    saves it to a CSV file, and returns the path to the CSV.\n",
    "\n",
    "    Parameters:\n",
    "    - variable_name: Name of the variable (used for CSV filename).\n",
    "    - region_geojson: GeoJSON dictionary defining the region of interest.\n",
    "    - start_date_str: Start date in 'YYYY-MM-DD' format.\n",
    "    - end_date_str: End date in 'YYYY-MM-DD' format.\n",
    "    - frequency: Aggregation frequency ('hourly', 'daily', 'monthly', 'yearly').\n",
    "    - gee_dataset_id: Earth Engine ImageCollection ID.\n",
    "    - gee_band_name: Name of the band(s) to extract. If a list, post_process_function must handle it.\n",
    "    - scale: Spatial resolution in meters for reduction.\n",
    "    - output_dir: Directory to save the output CSV file.\n",
    "    - gee_project: Optional GEE project ID for ee.Initialize().\n",
    "    - reducer: Earth Engine reducer to apply (default: ee.Reducer.mean()).\n",
    "    - data_scaling_factor: Optional factor to multiply the band data by.\n",
    "    - data_offset_factor: Optional offset to add to the band data.\n",
    "    - post_process_function: Optional function to apply to the raw reduced value(s).\n",
    "                             It should accept a dictionary of band values if multiple bands are processed,\n",
    "                             or a single value if one band is processed. It should return a dictionary\n",
    "                             of processed values or a single processed value.\n",
    "    - nan_value: Value to fill in if GEE returns no data for a period.\n",
    "\n",
    "    Returns:\n",
    "    - Path to the generated CSV file.\n",
    "    \"\"\"\n",
    "    if gee_project:\n",
    "        try:\n",
    "            ee.Initialize(project=gee_project)\n",
    "        except Exception:\n",
    "            ee.Initialize() # Fallback\n",
    "    \n",
    "    ee_region = ee.Geometry(region_geojson)\n",
    "    \n",
    "    start_date = datetime.datetime.strptime(start_date_str, '%Y-%m-%d')\n",
    "    end_date = datetime.datetime.strptime(end_date_str, '%Y-%m-%d')\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    date_periods = []\n",
    "    current_date = start_date\n",
    "    \n",
    "    if frequency == 'hourly':\n",
    "        delta = relativedelta(hours=1)\n",
    "        date_format_label = '%Y-%m-%d %H:%M:%S'\n",
    "        while current_date <= end_date:\n",
    "            period_end_date = current_date + delta - relativedelta(seconds=1) # End of the hour\n",
    "            date_periods.append({\n",
    "                \"start\": current_date.strftime('%Y-%m-%dT%H:%M:%S'),\n",
    "                \"end\": period_end_date.strftime('%Y-%m-%dT%H:%M:%S'),\n",
    "                \"label\": current_date.strftime(date_format_label)\n",
    "            })\n",
    "            current_date += delta\n",
    "    elif frequency == 'daily':\n",
    "        delta = relativedelta(days=1)\n",
    "        date_format_label = '%Y-%m-%d'\n",
    "        while current_date <= end_date:\n",
    "            date_periods.append({\n",
    "                \"start\": current_date.strftime('%Y-%m-%d'),\n",
    "                \"end\": (current_date + delta - relativedelta(days=1)).strftime('%Y-%m-%d'), # inclusive end\n",
    "                \"label\": current_date.strftime(date_format_label)\n",
    "            })\n",
    "            current_date += delta\n",
    "    elif frequency == 'monthly':\n",
    "        delta = relativedelta(months=1)\n",
    "        date_format_label = '%Y-%m'\n",
    "        while current_date <= end_date:\n",
    "            month_start = current_date.replace(day=1)\n",
    "            month_end = month_start + delta - relativedelta(days=1)\n",
    "            date_periods.append({\n",
    "                \"start\": month_start.strftime('%Y-%m-%d'),\n",
    "                \"end\": month_end.strftime('%Y-%m-%d'),\n",
    "                \"label\": month_start.strftime(date_format_label)\n",
    "            })\n",
    "            current_date += delta\n",
    "    elif frequency == 'yearly':\n",
    "        delta = relativedelta(years=1)\n",
    "        date_format_label = '%Y'\n",
    "        while current_date <= end_date:\n",
    "            year_start = current_date.replace(month=1, day=1)\n",
    "            year_end = year_start + delta - relativedelta(days=1)\n",
    "            date_periods.append({\n",
    "                \"start\": year_start.strftime('%Y-%m-%d'),\n",
    "                \"end\": year_end.strftime('%Y-%m-%d'),\n",
    "                \"label\": year_start.strftime(date_format_label)\n",
    "            })\n",
    "            current_date += delta\n",
    "    else:\n",
    "        raise ValueError(\"Invalid frequency. Choose from 'hourly', 'daily', 'monthly', 'yearly'.\")\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for period in date_periods:\n",
    "        try:\n",
    "            collection = ee.ImageCollection(gee_dataset_id) \\\n",
    "                           .filterDate(ee.Date(period[\"start\"]), ee.Date(period[\"end\"]).advance(1, 'day')) # GEE end date is exclusive\n",
    "            \n",
    "            if isinstance(gee_band_name, list): # For multi-band variables like wind\n",
    "                selected_bands_collection = collection.select(gee_band_name)\n",
    "            else: # Single band\n",
    "                selected_bands_collection = collection.select([gee_band_name])\n",
    "\n",
    "            # Check if collection is empty for the period\n",
    "            if selected_bands_collection.size().getInfo() == 0:\n",
    "                print(f\"No images found for {variable_name} in period {period['label']} for dataset {gee_dataset_id}\")\n",
    "                reduced_value = nan_value\n",
    "                if isinstance(gee_band_name, list) and nan_value is not None:\n",
    "                     # If multiple bands expected, fill with nan_value for each\n",
    "                    reduced_value = {band: nan_value for band in gee_band_name}\n",
    "                \n",
    "                if post_process_function and reduced_value is not None : # nan_value can be processed if needed\n",
    "                     processed_value = post_process_function(reduced_value)\n",
    "                else:\n",
    "                     processed_value = reduced_value\n",
    "                \n",
    "                # Ensure processed_value is a dictionary for DataFrame creation\n",
    "                if not isinstance(processed_value, dict) and isinstance(gee_band_name, list):\n",
    "                    # if single value came from post_process for multiple bands, try to map it\n",
    "                    # this might need adjustment based on post_process_function's behavior\n",
    "                    processed_value = {f\"{variable_name}_{b}\" if len(gee_band_name) > 1 else variable_name : processed_value for b in gee_band_name}\n",
    "                elif not isinstance(processed_value, dict):\n",
    "                    processed_value = {variable_name: processed_value}\n",
    "\n",
    "            else:\n",
    "                image_for_period = selected_bands_collection.mean() # Temporal aggregation\n",
    "\n",
    "                if data_scaling_factor is not None:\n",
    "                    image_for_period = image_for_period.multiply(data_scaling_factor)\n",
    "                if data_offset_factor is not None:\n",
    "                    image_for_period = image_for_period.add(data_offset_factor)\n",
    "                \n",
    "                # Perform reduction\n",
    "                reduction = image_for_period.reduceRegion(\n",
    "                    reducer=reducer,\n",
    "                    geometry=ee_region,\n",
    "                    scale=scale,\n",
    "                    maxPixels=1e10,\n",
    "                    bestEffort=True, # Added bestEffort\n",
    "                    tileScale=0.1 # Added tileScale\n",
    "                )\n",
    "                \n",
    "                raw_reduced_value = {}\n",
    "                if isinstance(gee_band_name, list):\n",
    "                    for band in gee_band_name:\n",
    "                        raw_reduced_value[band] = reduction.get(band).getInfo()\n",
    "                else:\n",
    "                    raw_reduced_value = reduction.get(gee_band_name).getInfo()\n",
    "\n",
    "                if post_process_function:\n",
    "                    processed_value = post_process_function(raw_reduced_value)\n",
    "                else:\n",
    "                    processed_value = raw_reduced_value\n",
    "\n",
    "            # Structure for DataFrame\n",
    "            current_row = {'timestamp': period['label']}\n",
    "            if isinstance(processed_value, dict):\n",
    "                current_row.update(processed_value)\n",
    "            else: # Single value result\n",
    "                current_row[variable_name] = processed_value\n",
    "            results.append(current_row)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing period {period['label']} for {variable_name}: {e}\")\n",
    "            # Add a row with nan_value or error indication\n",
    "            error_entry = {'timestamp': period['label']}\n",
    "            if isinstance(gee_band_name, list):\n",
    "                for band in gee_band_name:\n",
    "                    error_entry[f\"{variable_name}_{band}\"] = nan_value  # Or some error string\n",
    "            else:\n",
    "                error_entry[variable_name] = nan_value # Or some error string\n",
    "            results.append(error_entry)\n",
    "            continue # Continue to next period\n",
    "\n",
    "    if not results:\n",
    "        print(f\"No data extracted for {variable_name} in the given period.\")\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    # Ensure timestamp is the first column\n",
    "    cols = ['timestamp'] + [col for col in df.columns if col != 'timestamp']\n",
    "    df = df[cols]\n",
    "\n",
    "    # Sanitize filename\n",
    "    safe_start_date = start_date_str.replace('-', '')\n",
    "    safe_end_date = end_date_str.replace('-', '')\n",
    "    csv_filename = f\"{variable_name}_{frequency}_{safe_start_date}_{safe_end_date}.csv\"\n",
    "    csv_path = os.path.join(output_dir, csv_filename)\n",
    "    df.to_csv(csv_path, index=False, na_rep=str(nan_value) if nan_value is not None else 'NaN') # Use nan_value for na_rep\n",
    "    \n",
    "    print(f\"Successfully saved data for {variable_name} to {csv_path}\")\n",
    "    return csv_path\n",
    "\n",
    "# --- Helper function for MODIS LST to Celsius ---\n",
    "def convert_modis_lst_to_celsius(lst_value):\n",
    "    \"\"\"Converts MODIS LST (scaled Kelvin) to Celsius.\"\"\"\n",
    "    if lst_value is None:\n",
    "        return None\n",
    "    return (lst_value * 0.02) - 273.15\n",
    "\n",
    "# --- Specific Variable Extraction Functions ---\n",
    "\n",
    "# Albedo\n",
    "def extract_albedo_bsa(region_geojson, start_date_str, end_date_str, frequency, output_dir, scale=500):\n",
    "    return extract_gee_time_series(\n",
    "        variable_name=\"Albedo_BSA\",\n",
    "        region_geojson=region_geojson,\n",
    "        start_date_str=start_date_str,\n",
    "        end_date_str=end_date_str,\n",
    "        frequency=frequency,\n",
    "        gee_dataset_id='MODIS/061/MCD43A3', # As per reference notebook\n",
    "        gee_band_name='Albedo_BSA_shortwave', # As per reference notebook\n",
    "        scale=scale,\n",
    "        output_dir=output_dir,\n",
    "        data_scaling_factor=0.001, # MODIS albedo scaling\n",
    "        nan_value=np.nan # Use numpy's NaN for missing values\n",
    "    )\n",
    "\n",
    "def extract_albedo_wsa(region_geojson, start_date_str, end_date_str, frequency, output_dir, scale=500):\n",
    "    return extract_gee_time_series(\n",
    "        variable_name=\"Albedo_WSA\",\n",
    "        region_geojson=region_geojson,\n",
    "        start_date_str=start_date_str,\n",
    "        end_date_str=end_date_str,\n",
    "        frequency=frequency,\n",
    "        gee_dataset_id='MODIS/061/MCD43A3', # As per reference notebook\n",
    "        gee_band_name='Albedo_WSA_shortwave', # As per reference notebook\n",
    "        scale=scale,\n",
    "        output_dir=output_dir,\n",
    "        data_scaling_factor=0.001, # MODIS albedo scaling\n",
    "        nan_value=np.nan\n",
    "    )\n",
    "\n",
    "# Solar Radiation (using LST Day as proxy, similar to reference notebook)\n",
    "# Note: This is an approximation. A direct solar radiation dataset would be better if available and suitable.\n",
    "def post_process_solar_radiation(lst_day_value):\n",
    "    \"\"\"Approximates solar radiation from MODIS LST Day value.\"\"\"\n",
    "    if lst_day_value is None:\n",
    "        return None\n",
    "    # If input is a dict (from multi-band processing in generic func),\n",
    "    # extract the value. This handles cases where post_process_function\n",
    "    # might receive a dict even for single-band selection if the generic\n",
    "    # function's internal logic changes or if it's called directly with a dict.\n",
    "    if isinstance(lst_day_value, dict):\n",
    "        val = lst_day_value.get('LST_Day_1km', None)\n",
    "        if val is None: return None\n",
    "    else:\n",
    "        val = lst_day_value\n",
    "\n",
    "    temp_kelvin = val * 0.02 # MODIS LST scaling to Kelvin\n",
    "    stefan_boltzmann = 5.67e-8  # W/(m^2 K^4)\n",
    "    # This is a simplified Stefan-Boltzmann law application, assuming emissivity = 1\n",
    "    # The reference notebook had this calculation. True GHI/DNI would come from datasets like ERA5 or specific solar datasets.\n",
    "    return stefan_boltzmann * (temp_kelvin ** 4)\n",
    "\n",
    "def extract_radiacion_solar(region_geojson, start_date_str, end_date_str, frequency, output_dir, scale=1000):\n",
    "    return extract_gee_time_series(\n",
    "        variable_name=\"Radiacion_Solar_Approximated_from_LST\",\n",
    "        region_geojson=region_geojson,\n",
    "        start_date_str=start_date_str,\n",
    "        end_date_str=end_date_str,\n",
    "        frequency=frequency,\n",
    "        gee_dataset_id='MODIS/061/MOD11A1', # Using LST dataset as per reference\n",
    "        gee_band_name='LST_Day_1km',       # Using LST Day band\n",
    "        scale=scale,\n",
    "        output_dir=output_dir,\n",
    "        post_process_function=post_process_solar_radiation,\n",
    "        nan_value=np.nan\n",
    "    )\n",
    "\n",
    "# Temperature\n",
    "def extract_temperatura_dia(region_geojson, start_date_str, end_date_str, frequency, output_dir, scale=1000):\n",
    "    return extract_gee_time_series(\n",
    "        variable_name=\"Temperatura_Dia_Celsius\",\n",
    "        region_geojson=region_geojson,\n",
    "        start_date_str=start_date_str,\n",
    "        end_date_str=end_date_str,\n",
    "        frequency=frequency,\n",
    "        gee_dataset_id='MODIS/061/MOD11A1', # As per reference notebook\n",
    "        gee_band_name='LST_Day_1km',\n",
    "        scale=scale,\n",
    "        output_dir=output_dir,\n",
    "        post_process_function=lambda x: convert_modis_lst_to_celsius(x.get('LST_Day_1km') if isinstance(x, dict) else x) if x is not None else None, # LST to Celsius\n",
    "        nan_value=np.nan\n",
    "    )\n",
    "\n",
    "def extract_temperatura_noche(region_geojson, start_date_str, end_date_str, frequency, output_dir, scale=1000):\n",
    "    return extract_gee_time_series(\n",
    "        variable_name=\"Temperatura_Noche_Celsius\",\n",
    "        region_geojson=region_geojson,\n",
    "        start_date_str=start_date_str,\n",
    "        end_date_str=end_date_str,\n",
    "        frequency=frequency,\n",
    "        gee_dataset_id='MODIS/061/MOD11A1', # As per reference notebook\n",
    "        gee_band_name='LST_Night_1km',\n",
    "        scale=scale,\n",
    "        output_dir=output_dir,\n",
    "        post_process_function=lambda x: convert_modis_lst_to_celsius(x.get('LST_Night_1km') if isinstance(x, dict) else x) if x is not None else None, # LST to Celsius\n",
    "        nan_value=np.nan\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Wind Speed and Direction ---\n",
    "def post_process_wind_data(wind_components):\n",
    "    \"\"\"Calculates wind speed and direction from u and v components.\"\"\"\n",
    "    u = wind_components.get('u_component_of_wind_10m')\n",
    "    v = wind_components.get('v_component_of_wind_10m')\n",
    "    \n",
    "    if u is None or v is None:\n",
    "        return {'Viento_Velocidad': np.nan, 'Viento_Direccion': np.nan}\n",
    "        \n",
    "    speed = math.sqrt(u**2 + v**2)\n",
    "    # Wind direction: meteorological convention (degrees from North, clockwise)\n",
    "    # atan2(u,v) gives angle w.r.t positive y-axis (North). Convert to degrees.\n",
    "    # Then adjust to be 0-360.\n",
    "    # direction_rad = math.atan2(u, v) # u is eastward, v is northward\n",
    "    # direction_deg = math.degrees(direction_rad)\n",
    "    # direction_met = (270 - direction_deg) % 360 # As in reference notebook\n",
    "    # A common formula for meteorological wind direction from u,v components:\n",
    "    direction_met = (180 / math.pi) * math.atan2(-u, -v) + 180 \n",
    "    direction_met = direction_met % 360 # Ensure it's within 0-360\n",
    "\n",
    "    return {'Viento_Velocidad': speed, 'Viento_Direccion': direction_met}\n",
    "\n",
    "def extract_viento(region_geojson, start_date_str, end_date_str, frequency, output_dir, scale=10000):\n",
    "    # Note: ERA5 Land is hourly. If 'daily', 'monthly', 'yearly' frequency is requested,\n",
    "    # the generic function will average the hourly u/v components first, then calculate speed/direction.\n",
    "    return extract_gee_time_series(\n",
    "        variable_name=\"Viento\", # Base name, will be expanded by post_process_wind_data keys\n",
    "        region_geojson=region_geojson,\n",
    "        start_date_str=start_date_str,\n",
    "        end_date_str=end_date_str,\n",
    "        frequency=frequency,\n",
    "        gee_dataset_id='ECMWF/ERA5_LAND/HOURLY', # As per reference notebook\n",
    "        gee_band_name=['u_component_of_wind_10m', 'v_component_of_wind_10m'],\n",
    "        scale=scale,\n",
    "        output_dir=output_dir,\n",
    "        post_process_function=post_process_wind_data,\n",
    "        nan_value=np.nan\n",
    "    )\n",
    "\n",
    "# --- Topography (Elevation, Slope, Aspect) ---\n",
    "# These are static, so they don't depend on date range or frequency in the same way.\n",
    "# The function will calculate mean values over the region for a single point in time (the SRTM image is static).\n",
    "def extract_topography(region_geojson, output_dir, scale=30, variable_name_prefix=\"Topografia_\"):\n",
    "    \"\"\"\n",
    "    Extracts mean Elevation, Slope, and Aspect for a region and saves to a CSV.\n",
    "    Output CSV will have one row with columns: 'Elevation', 'Slope', 'Aspect'.\n",
    "    \"\"\"\n",
    "    ee_region = ee.Geometry(region_geojson)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        srtm = ee.Image('USGS/SRTMGL1_003') # SRTM is a single image\n",
    "        elevation = srtm.select('elevation')\n",
    "        slope = ee.Terrain.slope(elevation)\n",
    "        aspect = ee.Terrain.aspect(elevation)\n",
    "        \n",
    "        topography_image = ee.Image.cat([elevation, slope, aspect]).rename(['Elevacion', 'Pendiente', 'Aspecto'])\n",
    "        \n",
    "        reduction = topography_image.reduceRegion(\n",
    "            reducer=ee.Reducer.mean(),\n",
    "            geometry=ee_region,\n",
    "            scale=scale,\n",
    "            maxPixels=1e10,\n",
    "            bestEffort=True,\n",
    "            tileScale=0.1\n",
    "        )\n",
    "        \n",
    "        # GetInfo once\n",
    "        reduced_data = reduction.getInfo()\n",
    "\n",
    "        # Handle cases where a key might be missing (though unlikely for these specific bands from SRTM)\n",
    "        data_for_df = {\n",
    "            'Elevacion': reduced_data.get('Elevacion', np.nan),\n",
    "            'Pendiente': reduced_data.get('Pendiente', np.nan),\n",
    "            'Aspecto': reduced_data.get('Aspecto', np.nan)\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame([data_for_df])\n",
    "        \n",
    "        # Define a simple, non-temporal filename\n",
    "        csv_filename = f\"{variable_name_prefix}mean_values.csv\"\n",
    "        csv_path = os.path.join(output_dir, csv_filename)\n",
    "        df.to_csv(csv_path, index=False, na_rep=str(np.nan))\n",
    "        \n",
    "        print(f\"Successfully saved topography data to {csv_path}\")\n",
    "        return csv_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting topography data: {e}\")\n",
    "        # Create a CSV with NaNs if there's an error\n",
    "        df = pd.DataFrame([{'Elevacion': np.nan, 'Pendiente': np.nan, 'Aspecto': np.nan}])\n",
    "        csv_filename = f\"{variable_name_prefix}mean_values_error.csv\"\n",
    "        csv_path = os.path.join(output_dir, csv_filename)\n",
    "        df.to_csv(csv_path, index=False, na_rep=str(np.nan))\n",
    "        return csv_path\n",
    "\n",
    "\n",
    "# --- Land Cover (Principal Type and Percentage) ---\n",
    "# This is typically analyzed for a specific year or period, not as a continuous time series like temperature.\n",
    "# The function will find the dominant land cover type and its percentage for a given year.\n",
    "def extract_land_cover(region_geojson, year_str, output_dir, scale=500, variable_name_prefix=\"Cobertura_\"):\n",
    "    \"\"\"\n",
    "    Extracts the principal land cover type and its percentage for a region and year.\n",
    "    Saves to a CSV with columns: 'Year', 'Cobertura_Terrestre_Principal', 'Cobertura_Terrestre_Porcentaje'.\n",
    "    Uses MODIS MCD12Q1 dataset.\n",
    "    \"\"\"\n",
    "    ee_region = ee.Geometry(region_geojson)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        # MODIS Land Cover Type 1 (IGBP classification)\n",
    "        # MCD12Q1 provides yearly data. Filter for the specific year.\n",
    "        start_date = f\"{year_str}-01-01\"\n",
    "        end_date = f\"{year_str}-12-31\" # End of the year\n",
    "\n",
    "        land_cover_collection = ee.ImageCollection('MODIS/061/MCD12Q1') \\\n",
    "                                  .filterDate(start_date, end_date) \\\n",
    "                                  .select('LC_Type1') # IGBP classification band\n",
    "\n",
    "        # Get the image for the year (should be one)\n",
    "        land_cover_image = land_cover_collection.first()\n",
    "\n",
    "        # A robust check to see if the image is valid and has bands\n",
    "        # Attempt to get band names; if it fails or is empty, image is likely invalid/empty\n",
    "        valid_image = False\n",
    "        try:\n",
    "            if land_cover_image.bandNames().size().getInfo() > 0:\n",
    "                valid_image = True\n",
    "        except Exception: # Handles cases where land_cover_image might be null or not a proper image\n",
    "            valid_image = False\n",
    "\n",
    "        if not valid_image:\n",
    "             print(f\"No MODIS land cover data found or image is invalid for year {year_str}.\")\n",
    "             data_for_df = {'Year': year_str, 'Cobertura_Terrestre_Principal': np.nan, 'Cobertura_Terrestre_Porcentaje': np.nan}\n",
    "        else:\n",
    "            # Calculate frequency histogram of land cover types in the region\n",
    "            histogram = land_cover_image.reduceRegion(\n",
    "                reducer=ee.Reducer.frequencyHistogram(),\n",
    "                geometry=ee_region,\n",
    "                scale=scale,\n",
    "                maxPixels=1e10,\n",
    "                bestEffort=True,\n",
    "                tileScale=0.1\n",
    "            ).get('LC_Type1') # Get the histogram for the band\n",
    "\n",
    "            histogram_info = histogram.getInfo() # This can be slow for very large regions\n",
    "\n",
    "            if not histogram_info: # Check if histogram is empty\n",
    "                print(f\"Land cover histogram is empty for year {year_str} in the region.\")\n",
    "                data_for_df = {'Year': year_str, 'Cobertura_Terrestre_Principal': np.nan, 'Cobertura_Terrestre_Porcentaje': np.nan}\n",
    "            else:\n",
    "                # Convert keys (class IDs) to integers and find the principal class\n",
    "                class_counts = {int(k): v for k, v in histogram_info.items()}\n",
    "                total_pixels = sum(class_counts.values())\n",
    "                \n",
    "                if total_pixels == 0:\n",
    "                    principal_class_id = np.nan\n",
    "                    percentage = np.nan\n",
    "                else:\n",
    "                    principal_class_id = max(class_counts, key=class_counts.get)\n",
    "                    percentage = (class_counts[principal_class_id] / total_pixels) * 100\n",
    "                \n",
    "                data_for_df = {\n",
    "                    'Year': year_str,\n",
    "                    'Cobertura_Terrestre_Principal': principal_class_id,\n",
    "                    'Cobertura_Terrestre_Porcentaje': percentage\n",
    "                }\n",
    "\n",
    "        df = pd.DataFrame([data_for_df])\n",
    "        csv_filename = f\"{variable_name_prefix}{year_str}.csv\"\n",
    "        csv_path = os.path.join(output_dir, csv_filename)\n",
    "        df.to_csv(csv_path, index=False, na_rep=str(np.nan))\n",
    "        \n",
    "        print(f\"Successfully saved land cover data for {year_str} to {csv_path}\")\n",
    "        return csv_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting land cover data for {year_str}: {e}\")\n",
    "        df = pd.DataFrame([{'Year': year_str, 'Cobertura_Terrestre_Principal': np.nan, 'Cobertura_Terrestre_Porcentaje': np.nan}])\n",
    "        csv_filename = f\"{variable_name_prefix}{year_str}_error.csv\"\n",
    "        csv_path = os.path.join(output_dir, csv_filename)\n",
    "        df.to_csv(csv_path, index=False, na_rep=str(np.nan))\n",
    "        return csv_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Example Usage of Extraction Functions\n",
    "\n",
    "Below are examples of how to use the implemented functions. \n",
    "- You'll need to define your `region_of_interest` (as a GeoJSON-like Python dictionary).\n",
    "- Specify your desired `start_date`, `end_date`, `year_for_landcover`, and `output_directory`.\n",
    "- Uncomment the function calls you wish to run.\n",
    "- Ensure the `output_directory` exists or the functions will create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example Parameters (USER: PLEASE DEFINE THESE) ---\n",
    "\n",
    "# Define your Region of Interest (AOI) as a GeoJSON-like dictionary.\n",
    "# Example: A small rectangle in an arbitrary location. \n",
    "# REPLACE with your actual coordinates.\n",
    "region_of_interest = {\n",
    "    'type': 'Polygon',\n",
    "    'coordinates': [[\n",
    "        [-74.0, 40.7], [-74.0, 40.8], [-73.9, 40.8], [-73.9, 40.7], [-74.0, 40.7]\n",
    "    ]]\n",
    "}\n",
    "\n",
    "# Define your date range for time-series data\n",
    "example_start_date = '2020-01-01'\n",
    "example_end_date = '2020-01-31' # For a shorter example run; extend as needed\n",
    "\n",
    "# Define the year for land cover analysis\n",
    "example_year_lc = '2020'\n",
    "\n",
    "# Define the output directory for CSV files\n",
    "output_csv_directory = 'gee_output_data' \n",
    "# The functions will attempt to create this directory if it doesn't exist.\n",
    "\n",
    "# Define the desired frequency for time-series aggregation\n",
    "# Options: 'hourly', 'daily', 'monthly', 'yearly'\n",
    "example_frequency = 'daily' \n",
    "\n",
    "# --- Ensure output directory exists ---\n",
    "# import os # Already imported above\n",
    "# os.makedirs(output_csv_directory, exist_ok=True) # Generic function handles this\n",
    "\n",
    "# --- Example Calls (Uncomment to run) ---\n",
    "\n",
    "# print(f\"--- Extracting Albedo BSA ({example_frequency}) ---\")\n",
    "# extract_albedo_bsa(\n",
    "#     region_geojson=region_of_interest,\n",
    "#     start_date_str=example_start_date,\n",
    "#     end_date_str=example_end_date,\n",
    "#     frequency=example_frequency,\n",
    "#     output_dir=output_csv_directory\n",
    "# )\n",
    "\n",
    "# print(f\"--- Extracting Albedo WSA ({example_frequency}) ---\")\n",
    "# extract_albedo_wsa(\n",
    "#     region_geojson=region_of_interest,\n",
    "#     start_date_str=example_start_date,\n",
    "#     end_date_str=example_end_date,\n",
    "#     frequency=example_frequency,\n",
    "#     output_dir=output_csv_directory\n",
    "# )\n",
    "\n",
    "# print(f\"--- Extracting Approximated Solar Radiation ({example_frequency}) ---\")\n",
    "# extract_radiacion_solar(\n",
    "#     region_geojson=region_of_interest,\n",
    "#     start_date_str=example_start_date,\n",
    "#     end_date_str=example_end_date,\n",
    "#     frequency=example_frequency,\n",
    "#     output_dir=output_csv_directory\n",
    "# )\n",
    "\n",
    "# print(f\"--- Extracting Day Temperature ({example_frequency}) ---\")\n",
    "# extract_temperatura_dia(\n",
    "#     region_geojson=region_of_interest,\n",
    "#     start_date_str=example_start_date,\n",
    "#     end_date_str=example_end_date,\n",
    "#     frequency=example_frequency,\n",
    "#     output_dir=output_csv_directory\n",
    "# )\n",
    "\n",
    "# print(f\"--- Extracting Night Temperature ({example_frequency}) ---\")\n",
    "# extract_temperatura_noche(\n",
    "#     region_geojson=region_of_interest,\n",
    "#     start_date_str=example_start_date,\n",
    "#     end_date_str=example_end_date,\n",
    "#     frequency=example_frequency,\n",
    "#     output_dir=output_csv_directory\n",
    "# )\n",
    "\n",
    "# print(f\"--- Extracting Wind Data ({example_frequency}) ---\")\n",
    "# # Note: Wind data from ERA5 is hourly. Generic function will average u/v components\n",
    "# # to the target frequency before calculating speed/direction.\n",
    "# extract_viento(\n",
    "#     region_geojson=region_of_interest,\n",
    "#     start_date_str=example_start_date,\n",
    "#     end_date_str=example_end_date,\n",
    "#     frequency=example_frequency, # e.g., 'daily' will average hourly components to daily means first\n",
    "#     output_dir=output_csv_directory\n",
    "# )\n",
    "\n",
    "# print(f\"--- Extracting Topography Data (Static) ---\")\n",
    "# extract_topography(\n",
    "#     region_geojson=region_of_interest,\n",
    "#     output_dir=output_csv_directory\n",
    "# )\n",
    "\n",
    "# print(f\"--- Extracting Land Cover Data for {example_year_lc} ---\")\n",
    "# extract_land_cover(\n",
    "#     region_geojson=region_of_interest,\n",
    "#     year_str=example_year_lc,\n",
    "#     output_dir=output_csv_directory\n",
    "# )\n",
    "\n",
    "print(\"--- Example Usage Cell Complete ---\")\n",
    "print(f\"If you uncommented any calls, check the '{output_csv_directory}' folder for CSV files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
