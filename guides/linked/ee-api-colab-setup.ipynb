{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ee-api-colab-setup.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "krsLgVBYZw_A"
      },
      "source": [
        "#@title Copyright 2019 Google LLC. { display-mode: \"form\" }\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV1xZ1CPi3Nw"
      },
      "source": [
        "<table class=\"ee-notebook-buttons\" align=\"left\"><td>\n",
        "<a target=\"_blank\"  href=\"http://colab.research.google.com/github/google/earthengine-community/blob/master/guides/linked/ee-api-colab-setup.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /> Run in Google Colab</a>\n",
        "</td><td>\n",
        "<a target=\"_blank\"  href=\"https://github.com/google/earthengine-community/blob/master/guides/linked/ee-api-colab-setup.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /> View source on GitHub</a></td></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAZiVi13zTE7"
      },
      "source": [
        "# Earth Engine Python API Colab Setup\n",
        "\n",
        "This notebook demonstrates how to setup the Earth Engine Python API in Colab and provides several examples of how to print and visualize Earth Engine processed data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a69CuP5Q6OI7"
      },
      "source": [
        "## Import API and get credentials\n",
        "\n",
        "The Earth Engine API is installed by default in Google Colaboratory so requires only importing and authenticating. These steps must be completed for each new Colab session, if you restart your Colab kernel, or if your Colab virtual machine is recycled due to inactivity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNh-QBc36Mvk"
      },
      "source": [
        "### Import the API\n",
        "\n",
        "Run the following cell to import the API into your session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65RChERMzQHZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5d69d2ee-19a3-4fd0-f314-f13e5935f4c5"
      },
      "source": [
        "import ee\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import folium"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-dN42MTzg-w"
      },
      "source": [
        "### Authenticate and initialize\n",
        "\n",
        "Run the `ee.Authenticate` function to authenticate your access to Earth Engine servers and `ee.Initialize` to initialize it. Upon running the following cell you'll be asked to grant Earth Engine access to your Google account. Follow the instructions printed to the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMp9Ei9b0XXL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c7463434-698e-424e-fa60-797cd977a909"
      },
      "source": [
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize(project='gen-lang-client-0253961861')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V2"
      ],
      "metadata": {
        "id": "3GIS85utg4Ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_date(date_str):\n",
        "    \"\"\"Convierte una cadena de fecha en formato YYYY-MM-DD a objeto datetime.\"\"\"\n",
        "    try:\n",
        "        return datetime.datetime.strptime(date_str, '%Y-%m-%d')\n",
        "    except ValueError:\n",
        "        raise ValueError(\"El formato de fecha debe ser YYYY-MM-DD\")\n",
        "\n",
        "def get_date_ranges(start_date, end_date, frequency, max_chunk_days=30):\n",
        "    \"\"\"\n",
        "    Genera rangos de fechas seg√∫n la frecuencia especificada, divididos en chunks para evitar problemas de memoria.\n",
        "\n",
        "    Args:\n",
        "        start_date (datetime): Fecha de inicio\n",
        "        end_date (datetime): Fecha de fin\n",
        "        frequency (str): 'daily', 'monthly', o 'annual'\n",
        "        max_chunk_days (int): N√∫mero m√°ximo de d√≠as por chunk para frecuencia diaria\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de tuplas (fecha_inicio, fecha_fin) para cada per√≠odo\n",
        "    \"\"\"\n",
        "    date_ranges = []\n",
        "\n",
        "    if frequency == 'daily':\n",
        "        # Para frecuencia diaria, dividir en chunks para evitar problemas de memoria\n",
        "        current = start_date\n",
        "        while current <= end_date:\n",
        "            chunk_end = min(current + datetime.timedelta(days=max_chunk_days-1), end_date)\n",
        "            date_ranges.append((current.strftime('%Y-%m-%d'), chunk_end.strftime('%Y-%m-%d')))\n",
        "            current = chunk_end + datetime.timedelta(days=1)\n",
        "\n",
        "    elif frequency == 'monthly':\n",
        "        current = datetime.datetime(start_date.year, start_date.month, 1)\n",
        "        while current <= end_date:\n",
        "            next_month = current + relativedelta(months=1)\n",
        "            end_of_month = (next_month - datetime.timedelta(days=1))\n",
        "            if end_of_month > end_date:\n",
        "                end_of_month = end_date\n",
        "            date_ranges.append((current.strftime('%Y-%m-%d'), end_of_month.strftime('%Y-%m-%d')))\n",
        "            current = next_month\n",
        "\n",
        "    elif frequency == 'annual':\n",
        "        current_year = start_date.year\n",
        "        while current_year <= end_date.year:\n",
        "            year_start = max(datetime.datetime(current_year, 1, 1), start_date)\n",
        "            year_end = min(datetime.datetime(current_year, 12, 31), end_date)\n",
        "            date_ranges.append((year_start.strftime('%Y-%m-%d'), year_end.strftime('%Y-%m-%d')))\n",
        "            current_year += 1\n",
        "\n",
        "    return date_ranges\n",
        "\n",
        "def test_point_data_extraction(collection, point, band_name=None, scale=500):\n",
        "    \"\"\"\n",
        "    Prueba la extracci√≥n de datos para un punto espec√≠fico y verifica si hay valores v√°lidos.\n",
        "\n",
        "    Args:\n",
        "        collection (ee.ImageCollection): Colecci√≥n de im√°genes\n",
        "        point (ee.Geometry.Point): Punto de inter√©s\n",
        "        band_name (str, optional): Nombre de la banda espec√≠fica a extraer\n",
        "        scale (int): Escala en metros\n",
        "\n",
        "    Returns:\n",
        "        tuple: (bool, int) - (True si hay datos extra√≠bles, n√∫mero de im√°genes con datos v√°lidos)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Verificar si la colecci√≥n est√° vac√≠a\n",
        "        count = collection.size().getInfo()\n",
        "        if count == 0:\n",
        "            return False, 0\n",
        "\n",
        "        # Limitar a 10 im√°genes para la prueba\n",
        "        test_collection = collection.limit(10)\n",
        "\n",
        "        # Si se especifica una banda, verificar que exista\n",
        "        if band_name:\n",
        "            first_image = test_collection.first()\n",
        "            if first_image is None:\n",
        "                return False, 0\n",
        "\n",
        "            available_bands = first_image.bandNames().getInfo()\n",
        "            if band_name not in available_bands:\n",
        "                return False, 0\n",
        "\n",
        "            test_collection = test_collection.select(band_name)\n",
        "\n",
        "        # Funci√≥n para extraer valores y verificar si son v√°lidos\n",
        "        def check_valid_data(image):\n",
        "            # Extraer valor en el punto\n",
        "            value_dict = image.reduceRegion(\n",
        "                reducer=ee.Reducer.first(),\n",
        "                geometry=point,\n",
        "                scale=scale\n",
        "            )\n",
        "\n",
        "            # Verificar si hay valores no nulos\n",
        "            # M√©todo correcto para Python: verificar si el diccionario tiene elementos despu√©s de getInfo()\n",
        "            value_info = value_dict.getInfo()\n",
        "            has_data = 1 if value_info and any(v is not None for v in value_info.values()) else 0\n",
        "\n",
        "            return image.set('has_data', has_data)\n",
        "\n",
        "        # Aplicar la funci√≥n a cada imagen en la colecci√≥n\n",
        "        test_collection = test_collection.map(check_valid_data)\n",
        "\n",
        "        # Contar im√°genes con datos v√°lidos\n",
        "        images_with_data = test_collection.filterMetadata('has_data', 'equals', 1).size().getInfo()\n",
        "\n",
        "        return images_with_data > 0, images_with_data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error al probar extracci√≥n de datos: {e}\")\n",
        "        return False, 0\n",
        "\n",
        "def check_data_availability(point, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Verifica la disponibilidad de datos para un punto y per√≠odo espec√≠ficos.\n",
        "\n",
        "    Args:\n",
        "        point (ee.Geometry.Point): Punto de inter√©s\n",
        "        start_date (str): Fecha de inicio en formato YYYY-MM-DD\n",
        "        end_date (str): Fecha de fin en formato YYYY-MM-DD\n",
        "\n",
        "    Returns:\n",
        "        dict: Diccionario con la disponibilidad de cada tipo de datos\n",
        "    \"\"\"\n",
        "    availability = {\n",
        "        'albedo': {'available': False, 'images': 0, 'extractable': False, 'extractable_images': 0},\n",
        "        'radiation': {'available': False, 'images': 0, 'extractable': False, 'extractable_images': 0},\n",
        "        'temperature': {'available': False, 'images': 0, 'extractable': False, 'extractable_images': 0},\n",
        "        'wind': {'available': False, 'images': 0, 'extractable': False, 'extractable_images': 0},\n",
        "        'elevation': {'available': False, 'extractable': False},\n",
        "        'landcover': {'available': False, 'images': 0, 'extractable': False, 'extractable_images': 0}\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Verificar albedo\n",
        "        albedo_collection = ee.ImageCollection('MODIS/061/MCD43A3') \\\n",
        "            .filterDate(start_date, end_date) \\\n",
        "            .filterBounds(point)\n",
        "        albedo_count = albedo_collection.size().getInfo()\n",
        "        availability['albedo']['available'] = albedo_count > 0\n",
        "        availability['albedo']['images'] = albedo_count\n",
        "\n",
        "        if albedo_count > 0:\n",
        "            # Verificar si se pueden extraer datos de albedo\n",
        "            has_data, valid_count = test_point_data_extraction(\n",
        "                albedo_collection, point, 'Albedo_BSA_vis')\n",
        "            availability['albedo']['extractable'] = has_data\n",
        "            availability['albedo']['extractable_images'] = valid_count\n",
        "\n",
        "            print(f\"üìä Disponibilidad de datos de albedo: {albedo_count} im√°genes en la colecci√≥n, {valid_count} extra√≠bles para el punto\")\n",
        "        else:\n",
        "            print(f\"üìä Disponibilidad de datos de albedo: {albedo_count} im√°genes\")\n",
        "\n",
        "        # Verificar radiaci√≥n solar\n",
        "        radiation_collection = ee.ImageCollection('MODIS/061/MCD18A1') \\\n",
        "            .filterDate(start_date, end_date) \\\n",
        "            .filterBounds(point)\n",
        "        radiation_count = radiation_collection.size().getInfo()\n",
        "        availability['radiation']['available'] = radiation_count > 0\n",
        "        availability['radiation']['images'] = radiation_count\n",
        "\n",
        "        if radiation_count > 0:\n",
        "            # Verificar si se pueden extraer datos de radiaci√≥n\n",
        "            # Primero verificar qu√© bandas est√°n disponibles\n",
        "            first_image = radiation_collection.first()\n",
        "            if first_image:\n",
        "                available_bands = first_image.bandNames().getInfo()\n",
        "                test_band = None\n",
        "                if 'DSR' in available_bands:\n",
        "                    test_band = 'DSR'\n",
        "                elif 'Direct' in available_bands:\n",
        "                    test_band = 'Direct'\n",
        "                elif 'Diffuse' in available_bands:\n",
        "                    test_band = 'Diffuse'\n",
        "\n",
        "                if test_band:\n",
        "                    has_data, valid_count = test_point_data_extraction(\n",
        "                        radiation_collection, point, test_band)\n",
        "                    availability['radiation']['extractable'] = has_data\n",
        "                    availability['radiation']['extractable_images'] = valid_count\n",
        "\n",
        "                    print(f\"üìä Disponibilidad de datos de radiaci√≥n solar: {radiation_count} im√°genes en la colecci√≥n, {valid_count} extra√≠bles para el punto\")\n",
        "                else:\n",
        "                    print(f\"üìä Disponibilidad de datos de radiaci√≥n solar: {radiation_count} im√°genes, pero no se encontraron bandas esperadas\")\n",
        "            else:\n",
        "                print(f\"üìä Disponibilidad de datos de radiaci√≥n solar: {radiation_count} im√°genes, pero no se pudo acceder a la primera imagen\")\n",
        "        else:\n",
        "            print(f\"üìä Disponibilidad de datos de radiaci√≥n solar: {radiation_count} im√°genes\")\n",
        "\n",
        "        # Verificar temperatura\n",
        "        temperature_collection = ee.ImageCollection('MODIS/061/MOD11A1') \\\n",
        "            .filterDate(start_date, end_date) \\\n",
        "            .filterBounds(point)\n",
        "        temperature_count = temperature_collection.size().getInfo()\n",
        "        availability['temperature']['available'] = temperature_count > 0\n",
        "        availability['temperature']['images'] = temperature_count\n",
        "\n",
        "        if temperature_count > 0:\n",
        "            # Verificar si se pueden extraer datos de temperatura\n",
        "            has_data, valid_count = test_point_data_extraction(\n",
        "                temperature_collection, point, 'LST_Day_1km')\n",
        "            availability['temperature']['extractable'] = has_data\n",
        "            availability['temperature']['extractable_images'] = valid_count\n",
        "\n",
        "            print(f\"üìä Disponibilidad de datos de temperatura: {temperature_count} im√°genes en la colecci√≥n, {valid_count} extra√≠bles para el punto\")\n",
        "        else:\n",
        "            print(f\"üìä Disponibilidad de datos de temperatura: {temperature_count} im√°genes\")\n",
        "\n",
        "        # Verificar viento\n",
        "        wind_collection = ee.ImageCollection('ECMWF/ERA5_LAND/HOURLY') \\\n",
        "            .filterDate(start_date, end_date) \\\n",
        "            .filterBounds(point) \\\n",
        "            .limit(24)  # Solo verificar un d√≠a (24 horas)\n",
        "        wind_count = wind_collection.size().getInfo()\n",
        "        availability['wind']['available'] = wind_count > 0\n",
        "        availability['wind']['images'] = wind_count\n",
        "\n",
        "        if wind_count > 0:\n",
        "            # Verificar si se pueden extraer datos de viento\n",
        "            has_data, valid_count = test_point_data_extraction(\n",
        "                wind_collection, point, 'u_component_of_wind_10m')\n",
        "            availability['wind']['extractable'] = has_data\n",
        "            availability['wind']['extractable_images'] = valid_count\n",
        "\n",
        "            print(f\"üìä Disponibilidad de datos de viento: {wind_count} im√°genes en la colecci√≥n, {valid_count} extra√≠bles para el punto\")\n",
        "        else:\n",
        "            print(f\"üìä Disponibilidad de datos de viento: {wind_count} im√°genes\")\n",
        "\n",
        "        # Verificar elevaci√≥n (siempre disponible globalmente)\n",
        "        elevation = ee.Image('USGS/SRTMGL1_003').select('elevation')\n",
        "        elevation_value = elevation.reduceRegion(\n",
        "            reducer=ee.Reducer.first(),\n",
        "            geometry=point,\n",
        "            scale=30\n",
        "        ).getInfo()\n",
        "        availability['elevation']['available'] = 'elevation' in elevation_value and elevation_value['elevation'] is not None\n",
        "        availability['elevation']['extractable'] = availability['elevation']['available']\n",
        "\n",
        "        print(f\"üìä Disponibilidad de datos de elevaci√≥n: {'S√≠' if availability['elevation']['available'] else 'No'}\")\n",
        "\n",
        "        # Verificar cobertura terrestre\n",
        "        year = int(start_date.split('-')[0])\n",
        "        landcover_collection = ee.ImageCollection('MODIS/006/MCD12Q1') \\\n",
        "            .filterDate(f\"{year}-01-01\", f\"{year}-12-31\") \\\n",
        "            .filterBounds(point)\n",
        "        landcover_count = landcover_collection.size().getInfo()\n",
        "        availability['landcover']['available'] = landcover_count > 0\n",
        "        availability['landcover']['images'] = landcover_count\n",
        "\n",
        "        if landcover_count > 0:\n",
        "            # Verificar si se pueden extraer datos de cobertura terrestre\n",
        "            has_data, valid_count = test_point_data_extraction(\n",
        "                landcover_collection, point, 'LC_Type1')\n",
        "            availability['landcover']['extractable'] = has_data\n",
        "            availability['landcover']['extractable_images'] = valid_count\n",
        "\n",
        "            print(f\"üìä Disponibilidad de datos de cobertura terrestre: {landcover_count} im√°genes en la colecci√≥n, {valid_count} extra√≠bles para el punto\")\n",
        "        else:\n",
        "            print(f\"üìä Disponibilidad de datos de cobertura terrestre: {landcover_count} im√°genes\")\n",
        "\n",
        "        # Resumen general\n",
        "        available_count = sum(1 for v in availability.values() if v['available'])\n",
        "        extractable_count = sum(1 for v in availability.values() if v['extractable'])\n",
        "\n",
        "        print(f\"\\nüìã Resumen de disponibilidad:\")\n",
        "        print(f\"  - {available_count}/6 tipos de datos disponibles en las colecciones\")\n",
        "        print(f\"  - {extractable_count}/6 tipos de datos extra√≠bles para el punto espec√≠fico\")\n",
        "\n",
        "        if extractable_count == 0:\n",
        "            print(\"\\n‚ö†Ô∏è ADVERTENCIA: No hay datos extra√≠bles para esta ubicaci√≥n y per√≠odo.\")\n",
        "            print(\"‚ö†Ô∏è Sugerencias:\")\n",
        "            print(\"  - Prueba con un per√≠odo m√°s reciente (2021-2022)\")\n",
        "            print(\"  - Verifica las coordenadas (algunas regiones tienen menos cobertura)\")\n",
        "            print(\"  - Intenta con una ubicaci√≥n diferente\")\n",
        "        elif extractable_count < 3:\n",
        "            print(\"\\n‚ö†Ô∏è ADVERTENCIA: Pocos tipos de datos extra√≠bles para esta ubicaci√≥n y per√≠odo.\")\n",
        "            print(\"‚ö†Ô∏è El CSV resultante tendr√° informaci√≥n limitada.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error al verificar disponibilidad de datos: {e}\")\n",
        "\n",
        "    return availability\n",
        "\n",
        "def check_available_bands(image_collection, expected_bands):\n",
        "    \"\"\"\n",
        "    Verifica si las bandas esperadas est√°n disponibles en la colecci√≥n de im√°genes.\n",
        "\n",
        "    Args:\n",
        "        image_collection (ee.ImageCollection): Colecci√≥n de im√°genes\n",
        "        expected_bands (list): Lista de nombres de bandas esperadas\n",
        "\n",
        "    Returns:\n",
        "        tuple: (bool, list) - (True si todas las bandas est√°n disponibles, lista de bandas disponibles)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Obtener la primera imagen de la colecci√≥n\n",
        "        first_image = image_collection.first()\n",
        "        if first_image is None:\n",
        "            print(\"‚ö†Ô∏è Advertencia: Colecci√≥n de im√°genes vac√≠a\")\n",
        "            return False, []\n",
        "\n",
        "        # Obtener las bandas disponibles\n",
        "        available_bands = first_image.bandNames().getInfo()\n",
        "        if not available_bands:\n",
        "            print(\"‚ö†Ô∏è Advertencia: No se pudieron obtener los nombres de las bandas\")\n",
        "            return False, []\n",
        "\n",
        "        # Verificar si todas las bandas esperadas est√°n disponibles\n",
        "        all_available = all(band in available_bands for band in expected_bands)\n",
        "\n",
        "        if not all_available:\n",
        "            missing_bands = [band for band in expected_bands if band not in available_bands]\n",
        "            print(f\"‚ö†Ô∏è Advertencia: Algunas bandas esperadas no est√°n disponibles: {missing_bands}\")\n",
        "            print(f\"‚ö†Ô∏è Bandas disponibles: {available_bands}\")\n",
        "\n",
        "        return all_available, available_bands\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error al verificar bandas disponibles: {e}\")\n",
        "        return False, []\n",
        "\n",
        "def get_albedo_data(point, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Extrae datos de albedo (black-sky y white-sky) para un punto y per√≠odo espec√≠ficos.\n",
        "\n",
        "    Args:\n",
        "        point (ee.Geometry.Point): Punto de inter√©s\n",
        "        start_date (str): Fecha de inicio en formato YYYY-MM-DD\n",
        "        end_date (str): Fecha de fin en formato YYYY-MM-DD\n",
        "\n",
        "    Returns:\n",
        "        ee.ImageCollection: Colecci√≥n de im√°genes con datos de albedo\n",
        "    \"\"\"\n",
        "    albedo_collection = ee.ImageCollection('MODIS/061/MCD43A3') \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .filterBounds(point)\n",
        "\n",
        "    # Verificar bandas disponibles\n",
        "    expected_bands = ['Albedo_BSA_vis', 'Albedo_WSA_vis', 'Albedo_BSA_nir', 'Albedo_WSA_nir', 'Albedo_BSA_shortwave', 'Albedo_WSA_shortwave']\n",
        "    bands_available, available_bands = check_available_bands(albedo_collection, expected_bands)\n",
        "\n",
        "    if bands_available:\n",
        "        albedo_collection = albedo_collection.select(expected_bands)\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No se pudieron seleccionar todas las bandas de albedo esperadas\")\n",
        "        # Seleccionar solo las bandas disponibles que coinciden con el patr√≥n esperado\n",
        "        available_albedo_bands = [band for band in available_bands if 'Albedo' in band]\n",
        "        if available_albedo_bands:\n",
        "            print(f\"üîÑ Seleccionando bandas de albedo disponibles: {available_albedo_bands}\")\n",
        "            albedo_collection = albedo_collection.select(available_albedo_bands)\n",
        "\n",
        "    return albedo_collection\n",
        "\n",
        "def get_solar_radiation_data(point, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Extrae datos de radiaci√≥n solar para un punto y per√≠odo espec√≠ficos.\n",
        "\n",
        "    Args:\n",
        "        point (ee.Geometry.Point): Punto de inter√©s\n",
        "        start_date (str): Fecha de inicio en formato YYYY-MM-DD\n",
        "        end_date (str): Fecha de fin en formato YYYY-MM-DD\n",
        "\n",
        "    Returns:\n",
        "        ee.ImageCollection: Colecci√≥n de im√°genes con datos de radiaci√≥n solar\n",
        "    \"\"\"\n",
        "    radiation_collection = ee.ImageCollection('MODIS/061/MCD18A1') \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .filterBounds(point)\n",
        "\n",
        "    # Verificar bandas disponibles\n",
        "    # Nombres de bandas actualizados seg√∫n el error reportado\n",
        "    expected_bands = ['DSR', 'Direct', 'Diffuse']\n",
        "    bands_available, available_bands = check_available_bands(radiation_collection, expected_bands)\n",
        "\n",
        "    if bands_available:\n",
        "        radiation_collection = radiation_collection.select(expected_bands)\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No se pudieron seleccionar todas las bandas de radiaci√≥n solar esperadas\")\n",
        "        # Intentar seleccionar bandas disponibles relacionadas con radiaci√≥n solar\n",
        "        radiation_bands = [band for band in available_bands if 'DSR' in band or 'Direct' in band or 'Diffuse' in band]\n",
        "        if radiation_bands:\n",
        "            print(f\"üîÑ Seleccionando bandas de radiaci√≥n solar disponibles: {radiation_bands}\")\n",
        "            radiation_collection = radiation_collection.select(radiation_bands)\n",
        "\n",
        "    return radiation_collection\n",
        "\n",
        "def get_temperature_data(point, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Extrae datos de temperatura superficial para un punto y per√≠odo espec√≠ficos.\n",
        "\n",
        "    Args:\n",
        "        point (ee.Geometry.Point): Punto de inter√©s\n",
        "        start_date (str): Fecha de inicio en formato YYYY-MM-DD\n",
        "        end_date (str): Fecha de fin en formato YYYY-MM-DD\n",
        "\n",
        "    Returns:\n",
        "        ee.ImageCollection: Colecci√≥n de im√°genes con datos de temperatura\n",
        "    \"\"\"\n",
        "    temperature_collection = ee.ImageCollection('MODIS/061/MOD11A1') \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .filterBounds(point)\n",
        "\n",
        "    # Verificar bandas disponibles\n",
        "    expected_bands = ['LST_Day_1km', 'LST_Night_1km', 'QC_Day', 'QC_Night']\n",
        "    bands_available, available_bands = check_available_bands(temperature_collection, expected_bands)\n",
        "\n",
        "    if bands_available:\n",
        "        temperature_collection = temperature_collection.select(expected_bands)\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No se pudieron seleccionar todas las bandas de temperatura esperadas\")\n",
        "        # Intentar seleccionar bandas disponibles relacionadas con temperatura\n",
        "        temp_bands = [band for band in available_bands if 'LST' in band]\n",
        "        if temp_bands:\n",
        "            print(f\"üîÑ Seleccionando bandas de temperatura disponibles: {temp_bands}\")\n",
        "            temperature_collection = temperature_collection.select(temp_bands)\n",
        "\n",
        "    return temperature_collection\n",
        "\n",
        "def get_wind_data_chunk(point, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Extrae datos de viento para un punto y per√≠odo espec√≠ficos (un chunk).\n",
        "\n",
        "    Args:\n",
        "        point (ee.Geometry.Point): Punto de inter√©s\n",
        "        start_date (str): Fecha de inicio en formato YYYY-MM-DD\n",
        "        end_date (str): Fecha de fin en formato YYYY-MM-DD\n",
        "\n",
        "    Returns:\n",
        "        ee.ImageCollection: Colecci√≥n de im√°genes con datos de viento\n",
        "    \"\"\"\n",
        "    # Obtener datos de viento horarios\n",
        "    wind_collection = ee.ImageCollection('ECMWF/ERA5_LAND/HOURLY') \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .filterBounds(point)\n",
        "\n",
        "    # Verificar bandas disponibles\n",
        "    expected_bands = ['u_component_of_wind_10m', 'v_component_of_wind_10m']\n",
        "    bands_available, available_bands = check_available_bands(wind_collection, expected_bands)\n",
        "\n",
        "    if bands_available:\n",
        "        wind_collection = wind_collection.select(expected_bands)\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No se pudieron seleccionar todas las bandas de viento esperadas\")\n",
        "        # Intentar seleccionar bandas disponibles relacionadas con viento\n",
        "        wind_bands = [band for band in available_bands if 'wind' in band.lower()]\n",
        "        if wind_bands:\n",
        "            print(f\"üîÑ Seleccionando bandas de viento disponibles: {wind_bands}\")\n",
        "            wind_collection = wind_collection.select(wind_bands)\n",
        "\n",
        "    # M√©todo alternativo para agrupar por d√≠a sin usar startOfDay()\n",
        "    # Usamos format() para truncar la hora y obtener solo la fecha\n",
        "    def add_date_band(image):\n",
        "        # Obtener la fecha como string en formato YYYY-MM-DD\n",
        "        date_string = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd')\n",
        "        # A√±adir como propiedad\n",
        "        return image.set('date_string', date_string)\n",
        "\n",
        "    # A√±adir la propiedad de fecha a cada imagen\n",
        "    wind_collection_with_date = wind_collection.map(add_date_band)\n",
        "\n",
        "    # Obtener lista de fechas √∫nicas como strings\n",
        "    unique_dates = wind_collection_with_date.aggregate_array('date_string').distinct()\n",
        "\n",
        "    # Funci√≥n para calcular la media diaria\n",
        "    def calculate_daily_mean(date_string):\n",
        "        # Filtrar im√°genes para esta fecha\n",
        "        daily_images = wind_collection_with_date.filter(ee.Filter.eq('date_string', date_string))\n",
        "        # Calcular la media\n",
        "        mean_image = daily_images.mean()\n",
        "        # Convertir la fecha string a timestamp\n",
        "        timestamp = ee.Date(date_string).millis()\n",
        "        # A√±adir timestamp y fecha string como propiedades\n",
        "        return mean_image.set('system:time_start', timestamp).set('date_string', date_string)\n",
        "\n",
        "    # Calcular medias diarias\n",
        "    daily_wind = ee.ImageCollection.fromImages(unique_dates.map(calculate_daily_mean))\n",
        "\n",
        "    return daily_wind\n",
        "\n",
        "def get_elevation_data(point):\n",
        "    \"\"\"\n",
        "    Extrae datos de elevaci√≥n y variables topogr√°ficas derivadas para un punto espec√≠fico.\n",
        "\n",
        "    Args:\n",
        "        point (ee.Geometry.Point): Punto de inter√©s\n",
        "\n",
        "    Returns:\n",
        "        ee.Image: Imagen con datos de elevaci√≥n y variables derivadas\n",
        "    \"\"\"\n",
        "    # Obtener datos de elevaci√≥n SRTM\n",
        "    elevation = ee.Image('USGS/SRTMGL1_003').select('elevation')\n",
        "\n",
        "    # Calcular pendiente y aspecto (orientaci√≥n)\n",
        "    slope = ee.Terrain.slope(elevation)\n",
        "    aspect = ee.Terrain.aspect(elevation)\n",
        "\n",
        "    # Combinar en una sola imagen\n",
        "    topo = elevation.addBands(slope).addBands(aspect).rename(['elevation', 'slope', 'aspect'])\n",
        "\n",
        "    return topo\n",
        "\n",
        "def get_landcover_data(point, year):\n",
        "    \"\"\"\n",
        "    Extrae datos de cobertura terrestre para un punto y a√±o espec√≠ficos.\n",
        "\n",
        "    Args:\n",
        "        point (ee.Geometry.Point): Punto de inter√©s\n",
        "        year (int): A√±o para el cual obtener la cobertura terrestre\n",
        "\n",
        "    Returns:\n",
        "        ee.Image: Imagen con datos de cobertura terrestre\n",
        "    \"\"\"\n",
        "    # Usar el producto de cobertura terrestre MODIS\n",
        "    landcover_collection = ee.ImageCollection('MODIS/006/MCD12Q1') \\\n",
        "        .filterBounds(point)\n",
        "\n",
        "    # Filtrar por el a√±o especificado\n",
        "    year_start = f\"{year}-01-01\"\n",
        "    year_end = f\"{year}-12-31\"\n",
        "    landcover = landcover_collection.filterDate(year_start, year_end).first()\n",
        "\n",
        "    if landcover is None:\n",
        "        print(f\"‚ö†Ô∏è Advertencia: No hay datos de cobertura terrestre disponibles para el a√±o {year}\")\n",
        "        # Intentar con a√±os anteriores si no hay datos para el a√±o especificado\n",
        "        for prev_year in range(year-1, year-5, -1):\n",
        "            print(f\"üîÑ Intentando con datos de cobertura terrestre del a√±o {prev_year}...\")\n",
        "            prev_year_start = f\"{prev_year}-01-01\"\n",
        "            prev_year_end = f\"{prev_year}-12-31\"\n",
        "            landcover = landcover_collection.filterDate(prev_year_start, prev_year_end).first()\n",
        "            if landcover is not None:\n",
        "                print(f\"‚úÖ Se encontraron datos de cobertura terrestre para el a√±o {prev_year}\")\n",
        "                break\n",
        "\n",
        "        if landcover is None:\n",
        "            return None\n",
        "\n",
        "    # Verificar bandas disponibles\n",
        "    expected_bands = ['LC_Type1']\n",
        "    bands_available, available_bands = check_available_bands(landcover_collection, expected_bands)\n",
        "\n",
        "    if bands_available:\n",
        "        landcover = landcover.select('LC_Type1')\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No se pudieron seleccionar las bandas de cobertura terrestre esperadas\")\n",
        "        # Intentar seleccionar bandas disponibles relacionadas con cobertura terrestre\n",
        "        lc_bands = [band for band in available_bands if 'LC' in band or 'Type' in band]\n",
        "        if lc_bands:\n",
        "            print(f\"üîÑ Seleccionando bandas de cobertura terrestre disponibles: {lc_bands}\")\n",
        "            landcover = landcover.select(lc_bands[0])  # Seleccionar la primera banda disponible\n",
        "\n",
        "    return landcover\n",
        "\n",
        "def extract_point_values(image_collection, point, scale=500, band_name=None):\n",
        "    \"\"\"\n",
        "    Extrae valores para un punto espec√≠fico de una colecci√≥n de im√°genes.\n",
        "\n",
        "    Args:\n",
        "        image_collection (ee.ImageCollection): Colecci√≥n de im√°genes\n",
        "        point (ee.Geometry.Point): Punto de inter√©s\n",
        "        scale (int): Escala en metros\n",
        "        band_name (str, optional): Nombre de la banda espec√≠fica a extraer\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de diccionarios con fecha y valores\n",
        "    \"\"\"\n",
        "    # Verificar si la colecci√≥n est√° vac√≠a\n",
        "    count = image_collection.size().getInfo()\n",
        "    if count == 0:\n",
        "        print(\"‚ö†Ô∏è Advertencia: Colecci√≥n de im√°genes vac√≠a\")\n",
        "        return []\n",
        "\n",
        "    # Si se especifica una banda, verificar que exista\n",
        "    if band_name:\n",
        "        first_image = image_collection.first()\n",
        "        if first_image is None:\n",
        "            print(\"‚ö†Ô∏è Advertencia: No hay im√°genes en la colecci√≥n\")\n",
        "            return []\n",
        "\n",
        "        available_bands = first_image.bandNames().getInfo()\n",
        "        if band_name not in available_bands:\n",
        "            print(f\"‚ö†Ô∏è Advertencia: La banda '{band_name}' no est√° disponible. Bandas disponibles: {available_bands}\")\n",
        "            return []\n",
        "\n",
        "    def extract_from_image(image):\n",
        "        try:\n",
        "            # Si se especifica una banda, seleccionarla\n",
        "            if band_name:\n",
        "                image = image.select(band_name)\n",
        "\n",
        "            # Extraer valor en el punto\n",
        "            value = image.reduceRegion(\n",
        "                reducer=ee.Reducer.first(),\n",
        "                geometry=point,\n",
        "                scale=scale\n",
        "            )\n",
        "\n",
        "            # Crear feature con fecha y valor\n",
        "            return ee.Feature(None, {\n",
        "                'date': ee.Date(image.get('system:time_start')).format('YYYY-MM-dd'),\n",
        "                'values': value\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error al extraer valores de la imagen: {e}\")\n",
        "            return ee.Feature(None, {\n",
        "                'date': ee.Date(image.get('system:time_start')).format('YYYY-MM-dd'),\n",
        "                'values': {}\n",
        "            })\n",
        "\n",
        "    try:\n",
        "        # Aplicar la funci√≥n a cada imagen en la colecci√≥n\n",
        "        features = image_collection.map(extract_from_image)\n",
        "\n",
        "        # Convertir a lista para descargar\n",
        "        result = features.aggregate_array('properties').getInfo()\n",
        "\n",
        "        # Filtrar resultados para eliminar valores vac√≠os\n",
        "        filtered_result = []\n",
        "        for item in result:\n",
        "            if item['values'] and len(item['values']) > 0 and any(v is not None for v in item['values'].values()):\n",
        "                filtered_result.append(item)\n",
        "\n",
        "        if len(filtered_result) == 0:\n",
        "            print(f\"‚ö†Ô∏è No se encontraron valores v√°lidos para el punto en ninguna de las {count} im√°genes\")\n",
        "        else:\n",
        "            print(f\"‚úÖ Se encontraron valores v√°lidos en {len(filtered_result)} de {count} im√°genes\")\n",
        "\n",
        "        return filtered_result\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error al extraer valores de la colecci√≥n: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_static_values(image, point, scale=500):\n",
        "    \"\"\"\n",
        "    Extrae valores para un punto espec√≠fico de una imagen est√°tica.\n",
        "\n",
        "    Args:\n",
        "        image (ee.Image): Imagen\n",
        "        point (ee.Geometry.Point): Punto de inter√©s\n",
        "        scale (int): Escala en metros\n",
        "\n",
        "    Returns:\n",
        "        dict: Diccionario con valores\n",
        "    \"\"\"\n",
        "    if image is None:\n",
        "        print(\"‚ö†Ô∏è Advertencia: Imagen nula\")\n",
        "        return {}\n",
        "\n",
        "    try:\n",
        "        values = image.reduceRegion(\n",
        "            reducer=ee.Reducer.first(),\n",
        "            geometry=point,\n",
        "            scale=scale\n",
        "        ).getInfo()\n",
        "\n",
        "        # Verificar si se obtuvieron valores v√°lidos\n",
        "        if not values or all(v is None for v in values.values()):\n",
        "            print(\"‚ö†Ô∏è No se encontraron valores v√°lidos para el punto en la imagen est√°tica\")\n",
        "            return {}\n",
        "\n",
        "        return values\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error al extraer valores est√°ticos: {e}\")\n",
        "        return {}\n",
        "\n",
        "def safe_merge(df_list):\n",
        "    \"\"\"\n",
        "    Combina de forma segura una lista de DataFrames, verificando que tengan la columna 'date'.\n",
        "\n",
        "    Args:\n",
        "        df_list (list): Lista de DataFrames a combinar\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame combinado o DataFrame vac√≠o con columna 'date'\n",
        "    \"\"\"\n",
        "    # Filtrar DataFrames vac√≠os o sin columna 'date'\n",
        "    valid_dfs = [df for df in df_list if not df.empty and 'date' in df.columns]\n",
        "\n",
        "    if not valid_dfs:\n",
        "        # Retornar DataFrame vac√≠o con columna 'date'\n",
        "        return pd.DataFrame({'date': []})\n",
        "\n",
        "    # Comenzar con el primer DataFrame v√°lido\n",
        "    result = valid_dfs[0].copy()\n",
        "\n",
        "    # Combinar con el resto de DataFrames v√°lidos\n",
        "    for df in valid_dfs[1:]:\n",
        "        result = pd.merge(result, df, on='date', how='outer')\n",
        "\n",
        "    return result\n",
        "\n",
        "def process_albedo_data(albedo_collection, point, frequency, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Procesa datos de albedo y los agrega seg√∫n la frecuencia especificada.\n",
        "\n",
        "    Args:\n",
        "        albedo_collection (ee.ImageCollection): Colecci√≥n de im√°genes de albedo\n",
        "        point (ee.Geometry.Point): Punto de inter√©s\n",
        "        frequency (str): 'daily', 'monthly', o 'annual'\n",
        "        start_date (datetime): Fecha de inicio\n",
        "        end_date (datetime): Fecha de fin\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de diccionarios con datos de albedo agregados\n",
        "    \"\"\"\n",
        "    # Verificar bandas disponibles\n",
        "    first_image = albedo_collection.first()\n",
        "    if first_image is None:\n",
        "        print(\"‚ö†Ô∏è Advertencia: No hay im√°genes de albedo disponibles\")\n",
        "        return []\n",
        "\n",
        "    available_bands = first_image.bandNames().getInfo()\n",
        "\n",
        "    # Extraer valores para cada banda disponible\n",
        "    valid_dfs = []\n",
        "\n",
        "    # Bandas BSA (Black-Sky Albedo)\n",
        "    bsa_bands = [band for band in available_bands if 'BSA' in band]\n",
        "    for band in bsa_bands:\n",
        "        try:\n",
        "            data = extract_point_values(albedo_collection.select(band), point)\n",
        "            if data:\n",
        "                df_name = band.lower().replace('albedo_', '')\n",
        "                df = pd.DataFrame([{'date': item['date'], df_name: item['values'].get(band, None)} for item in data])\n",
        "                if not df.empty and 'date' in df.columns:\n",
        "                    # Convertir valores a escala correcta (dividir por 1000)\n",
        "                    df[df_name] = df[df_name].apply(lambda x: x / 1000.0 if x is not None else None)\n",
        "                    valid_dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error al procesar datos de {band}: {e}\")\n",
        "\n",
        "    # Bandas WSA (White-Sky Albedo)\n",
        "    wsa_bands = [band for band in available_bands if 'WSA' in band]\n",
        "    for band in wsa_bands:\n",
        "        try:\n",
        "            data = extract_point_values(albedo_collection.select(band), point)\n",
        "            if data:\n",
        "                df_name = band.lower().replace('albedo_', '')\n",
        "                df = pd.DataFrame([{'date': item['date'], df_name: item['values'].get(band, None)} for item in data])\n",
        "                if not df.empty and 'date' in df.columns:\n",
        "                    # Convertir valores a escala correcta (dividir por 1000)\n",
        "                    df[df_name] = df[df_name].apply(lambda x: x / 1000.0 if x is not None else None)\n",
        "                    valid_dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error al procesar datos de {band}: {e}\")\n",
        "\n",
        "    # Verificar si hay datos disponibles\n",
        "    if not valid_dfs:\n",
        "        print(\"‚ö†Ô∏è Advertencia: No hay datos de albedo disponibles para el per√≠odo seleccionado\")\n",
        "        return []\n",
        "\n",
        "    # Combinar DataFrames de forma segura\n",
        "    albedo_df = safe_merge(valid_dfs)\n",
        "\n",
        "    # Si el DataFrame resultante est√° vac√≠o o no tiene columna 'date', retornar lista vac√≠a\n",
        "    if albedo_df.empty or 'date' not in albedo_df.columns:\n",
        "        print(\"‚ö†Ô∏è El DataFrame combinado de albedo est√° vac√≠o o no tiene columna 'date'\")\n",
        "        return []\n",
        "\n",
        "    # Convertir fechas a datetime\n",
        "    albedo_df['date'] = pd.to_datetime(albedo_df['date'])\n",
        "\n",
        "    # Agregar seg√∫n frecuencia\n",
        "    if frequency == 'daily':\n",
        "        return albedo_df.to_dict('records')\n",
        "    elif frequency == 'monthly':\n",
        "        albedo_df.set_index('date', inplace=True)\n",
        "        monthly_df = albedo_df.resample('M').mean()\n",
        "        monthly_df.index = monthly_df.index.strftime('%Y-%m-%d')\n",
        "        return monthly_df.reset_index().to_dict('records')\n",
        "    elif frequency == 'annual':\n",
        "        albedo_df.set_index('date', inplace=True)\n",
        "        annual_df = albedo_df.resample('Y').mean()\n",
        "        annual_df.index = annual_df.index.strftime('%Y-%m-%d')\n",
        "        return annual_df.reset_index().to_dict('records')\n",
        "\n",
        "def process_radiation_data(radiation_collection, point, frequency, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Procesa datos de radiaci√≥n solar y los agrega seg√∫n la frecuencia especificada.\n",
        "\n",
        "    Args:\n",
        "        radiation_collection (ee.ImageCollection): Colecci√≥n de im√°genes de radiaci√≥n\n",
        "        point (ee.Geometry.Point): Punto de inter√©s\n",
        "        frequency (str): 'daily', 'monthly', o 'annual'\n",
        "        start_date (datetime): Fecha de inicio\n",
        "        end_date (datetime): Fecha de fin\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de diccionarios con datos de radiaci√≥n agregados\n",
        "    \"\"\"\n",
        "    # Verificar bandas disponibles\n",
        "    first_image = radiation_collection.first()\n",
        "    if first_image is None:\n",
        "        print(\"‚ö†Ô∏è Advertencia: No hay im√°genes de radiaci√≥n solar disponibles\")\n",
        "        return []\n",
        "\n",
        "    available_bands = first_image.bandNames().getInfo()\n",
        "\n",
        "    # Extraer valores para cada banda disponible\n",
        "    valid_dfs = []\n",
        "\n",
        "    for band in available_bands:\n",
        "        try:\n",
        "            data = extract_point_values(radiation_collection.select(band), point)\n",
        "            if data:\n",
        "                df_name = f\"radiation_{band.lower()}\"\n",
        "                df = pd.DataFrame([{'date': item['date'], df_name: item['values'].get(band, None)} for item in data])\n",
        "                if not df.empty and 'date' in df.columns:\n",
        "                    valid_dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error al procesar datos de radiaci√≥n {band}: {e}\")\n",
        "\n",
        "    # Verificar si hay datos disponibles\n",
        "    if not valid_dfs:\n",
        "        print(\"‚ö†Ô∏è Advertencia: No hay datos de radiaci√≥n solar disponibles para el per√≠odo seleccionado\")\n",
        "        return []\n",
        "\n",
        "    # Combinar DataFrames de forma segura\n",
        "    radiation_df = safe_merge(valid_dfs)\n",
        "\n",
        "    # Si el DataFrame resultante est√° vac√≠o o no tiene columna 'date', retornar lista vac√≠a\n",
        "    if radiation_df.empty or 'date' not in radiation_df.columns:\n",
        "        print(\"‚ö†Ô∏è El DataFrame combinado de radiaci√≥n est√° vac√≠o o no tiene columna 'date'\")\n",
        "        return []\n",
        "\n",
        "    # Convertir fechas a datetime\n",
        "    radiation_df['date'] = pd.to_datetime(radiation_df['date'])\n",
        "\n",
        "    # Agregar seg√∫n frecuencia\n",
        "    if frequency == 'daily':\n",
        "        return radiation_df.to_dict('records')\n",
        "    elif frequency == 'monthly':\n",
        "        radiation_df.set_index('date', inplace=True)\n",
        "        monthly_df = radiation_df.resample('M').mean()\n",
        "        monthly_df.index = monthly_df.index.strftime('%Y-%m-%d')\n",
        "        return monthly_df.reset_index().to_dict('records')\n",
        "    elif frequency == 'annual':\n",
        "        radiation_df.set_index('date', inplace=True)\n",
        "        annual_df = radiation_df.resample('Y').mean()\n",
        "        annual_df.index = annual_df.index.strftime('%Y-%m-%d')\n",
        "        return annual_df.reset_index().to_dict('records')\n",
        "\n",
        "def process_temperature_data(temperature_collection, point, frequency, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Procesa datos de temperatura y los agrega seg√∫n la frecuencia especificada.\n",
        "\n",
        "    Args:\n",
        "        temperature_collection (ee.ImageCollection): Colecci√≥n de im√°genes de temperatura\n",
        "        point (ee.Geometry.Point): Punto de inter√©s\n",
        "        frequency (str): 'daily', 'monthly', o 'annual'\n",
        "        start_date (datetime): Fecha de inicio\n",
        "        end_date (datetime): Fecha de fin\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de diccionarios con datos de temperatura agregados\n",
        "    \"\"\"\n",
        "    # Verificar bandas disponibles\n",
        "    first_image = temperature_collection.first()\n",
        "    if first_image is None:\n",
        "        print(\"‚ö†Ô∏è Advertencia: No hay im√°genes de temperatura disponibles\")\n",
        "        return []\n",
        "\n",
        "    available_bands = first_image.bandNames().getInfo()\n",
        "\n",
        "    # Extraer valores para bandas de temperatura\n",
        "    valid_dfs = []\n",
        "    temp_bands = [band for band in available_bands if 'LST' in band]\n",
        "\n",
        "    for band in temp_bands:\n",
        "        try:\n",
        "            data = extract_point_values(temperature_collection.select(band), point)\n",
        "            if data:\n",
        "                df_name = f\"temp_{band.lower().replace('lst_', '')}\"\n",
        "                df = pd.DataFrame([{'date': item['date'], df_name: item['values'].get(band, None)} for item in data])\n",
        "                if not df.empty and 'date' in df.columns:\n",
        "                    # Convertir valores a escala correcta (convertir a Celsius)\n",
        "                    df[df_name] = df[df_name].apply(lambda x: (x * 0.02) - 273.15 if x is not None else None)\n",
        "                    valid_dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error al procesar datos de temperatura {band}: {e}\")\n",
        "\n",
        "    # Verificar si hay datos disponibles\n",
        "    if not valid_dfs:\n",
        "        print(\"‚ö†Ô∏è Advertencia: No hay datos de temperatura disponibles para el per√≠odo seleccionado\")\n",
        "        return []\n",
        "\n",
        "    # Combinar DataFrames de forma segura\n",
        "    temp_df = safe_merge(valid_dfs)\n",
        "\n",
        "    # Si el DataFrame resultante est√° vac√≠o o no tiene columna 'date', retornar lista vac√≠a\n",
        "    if temp_df.empty or 'date' not in temp_df.columns:\n",
        "        print(\"‚ö†Ô∏è El DataFrame combinado de temperatura est√° vac√≠o o no tiene columna 'date'\")\n",
        "        return []\n",
        "\n",
        "    # A√±adir temperatura media si hay datos de d√≠a y noche\n",
        "    day_col = next((col for col in temp_df.columns if 'day' in col.lower()), None)\n",
        "    night_col = next((col for col in temp_df.columns if 'night' in col.lower()), None)\n",
        "\n",
        "    if day_col and night_col:\n",
        "        temp_df['temp_mean'] = temp_df[[day_col, night_col]].mean(axis=1)\n",
        "    elif day_col:\n",
        "        temp_df['temp_mean'] = temp_df[day_col]\n",
        "    elif night_col:\n",
        "        temp_df['temp_mean'] = temp_df[night_col]\n",
        "\n",
        "    # Convertir fechas a datetime\n",
        "    temp_df['date'] = pd.to_datetime(temp_df['date'])\n",
        "\n",
        "    # Agregar seg√∫n frecuencia\n",
        "    if frequency == 'daily':\n",
        "        return temp_df.to_dict('records')\n",
        "    elif frequency == 'monthly':\n",
        "        temp_df.set_index('date', inplace=True)\n",
        "        monthly_df = temp_df.resample('M').mean()\n",
        "        monthly_df.index = monthly_df.index.strftime('%Y-%m-%d')\n",
        "        return monthly_df.reset_index().to_dict('records')\n",
        "    elif frequency == 'annual':\n",
        "        temp_df.set_index('date', inplace=True)\n",
        "        annual_df = temp_df.resample('Y').mean()\n",
        "        annual_df.index = annual_df.index.strftime('%Y-%m-%d')\n",
        "        return annual_df.reset_index().to_dict('records')\n",
        "\n",
        "def process_wind_data_chunked(point, start_date, end_date, frequency, max_chunk_days=30):\n",
        "    \"\"\"\n",
        "    Procesa datos de viento en chunks para evitar problemas de memoria.\n",
        "\n",
        "    Args:\n",
        "        point (ee.Geometry.Point): Punto de inter√©s\n",
        "        start_date (datetime): Fecha de inicio\n",
        "        end_date (datetime): Fecha de fin\n",
        "        frequency (str): 'daily', 'monthly', o 'annual'\n",
        "        max_chunk_days (int): N√∫mero m√°ximo de d√≠as por chunk\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de diccionarios con datos de viento agregados\n",
        "    \"\"\"\n",
        "    # Generar rangos de fechas en chunks\n",
        "    date_ranges = get_date_ranges(start_date, end_date, 'daily', max_chunk_days)\n",
        "\n",
        "    # Procesar cada chunk\n",
        "    all_wind_data = []\n",
        "\n",
        "    for i, (chunk_start, chunk_end) in enumerate(date_ranges):\n",
        "        print(f\"üîÑ Procesando chunk de viento {i+1}/{len(date_ranges)}: {chunk_start} a {chunk_end}\")\n",
        "\n",
        "        try:\n",
        "            # Obtener datos para este chunk\n",
        "            wind_collection = get_wind_data_chunk(point, chunk_start, chunk_end)\n",
        "\n",
        "            # Verificar bandas disponibles\n",
        "            first_image = wind_collection.first()\n",
        "            if first_image is None:\n",
        "                print(f\"‚ö†Ô∏è No hay im√°genes de viento disponibles para el chunk {chunk_start} a {chunk_end}\")\n",
        "                continue\n",
        "\n",
        "            available_bands = first_image.bandNames().getInfo()\n",
        "\n",
        "            # Extraer valores para cada componente\n",
        "            valid_dfs = []\n",
        "\n",
        "            # Buscar componentes U y V del viento\n",
        "            u_band = next((band for band in available_bands if 'u_component' in band.lower()), None)\n",
        "            v_band = next((band for band in available_bands if 'v_component' in band.lower()), None)\n",
        "\n",
        "            if u_band:\n",
        "                try:\n",
        "                    u_data = extract_point_values(wind_collection.select(u_band), point)\n",
        "                    if u_data:\n",
        "                        u_df = pd.DataFrame([{'date': item['date'], 'wind_u': item['values'].get(u_band, None)} for item in u_data])\n",
        "                        if not u_df.empty and 'date' in u_df.columns:\n",
        "                            valid_dfs.append(u_df)\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Error al procesar datos de componente U del viento: {e}\")\n",
        "\n",
        "            if v_band:\n",
        "                try:\n",
        "                    v_data = extract_point_values(wind_collection.select(v_band), point)\n",
        "                    if v_data:\n",
        "                        v_df = pd.DataFrame([{'date': item['date'], 'wind_v': item['values'].get(v_band, None)} for item in v_data])\n",
        "                        if not v_df.empty and 'date' in v_df.columns:\n",
        "                            valid_dfs.append(v_df)\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Error al procesar datos de componente V del viento: {e}\")\n",
        "\n",
        "            # Verificar si hay datos disponibles\n",
        "            if not valid_dfs:\n",
        "                print(f\"‚ö†Ô∏è No hay datos de viento disponibles para el chunk {chunk_start} a {chunk_end}\")\n",
        "                continue\n",
        "\n",
        "            # Combinar DataFrames de forma segura\n",
        "            wind_df = safe_merge(valid_dfs)\n",
        "\n",
        "            # Si el DataFrame resultante est√° vac√≠o o no tiene columna 'date', continuar con el siguiente chunk\n",
        "            if wind_df.empty or 'date' not in wind_df.columns:\n",
        "                print(f\"‚ö†Ô∏è El DataFrame combinado de viento est√° vac√≠o para el chunk {chunk_start} a {chunk_end}\")\n",
        "                continue\n",
        "\n",
        "            # Calcular velocidad y direcci√≥n del viento si hay ambos componentes\n",
        "            if 'wind_u' in wind_df.columns and 'wind_v' in wind_df.columns:\n",
        "                wind_df['wind_speed'] = wind_df.apply(lambda row: np.sqrt(row['wind_u']**2 + row['wind_v']**2) if pd.notnull(row['wind_u']) and pd.notnull(row['wind_v']) else None, axis=1)\n",
        "                wind_df['wind_direction'] = wind_df.apply(lambda row: (270 - np.degrees(np.arctan2(row['wind_v'], row['wind_u']))) % 360 if pd.notnull(row['wind_u']) and pd.notnull(row['wind_v']) else None, axis=1)\n",
        "\n",
        "            # Convertir fechas a datetime\n",
        "            wind_df['date'] = pd.to_datetime(wind_df['date'])\n",
        "\n",
        "            # Agregar a la lista de todos los datos\n",
        "            all_wind_data.append(wind_df)\n",
        "\n",
        "            # Pausa para evitar sobrecargar la API\n",
        "            time.sleep(1)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error al procesar chunk de viento {chunk_start} a {chunk_end}: {e}\")\n",
        "            # Continuar con el siguiente chunk\n",
        "            continue\n",
        "\n",
        "    # Verificar si hay datos disponibles\n",
        "    if not all_wind_data:\n",
        "        print(\"‚ö†Ô∏è Advertencia: No hay datos de viento disponibles para el per√≠odo seleccionado\")\n",
        "        return []\n",
        "\n",
        "    # Combinar todos los chunks\n",
        "    combined_wind_df = pd.concat(all_wind_data, ignore_index=True)\n",
        "\n",
        "    # Eliminar duplicados si los hay\n",
        "    combined_wind_df.drop_duplicates(subset=['date'], keep='first', inplace=True)\n",
        "\n",
        "    # Agregar seg√∫n frecuencia\n",
        "    if frequency == 'daily':\n",
        "        return combined_wind_df.to_dict('records')\n",
        "    elif frequency == 'monthly':\n",
        "        combined_wind_df.set_index('date', inplace=True)\n",
        "        monthly_df = combined_wind_df.resample('M').mean()\n",
        "        monthly_df.index = monthly_df.index.strftime('%Y-%m-%d')\n",
        "        return monthly_df.reset_index().to_dict('records')\n",
        "    elif frequency == 'annual':\n",
        "        combined_wind_df.set_index('date', inplace=True)\n",
        "        annual_df = combined_wind_df.resample('Y').mean()\n",
        "        annual_df.index = annual_df.index.strftime('%Y-%m-%d')\n",
        "        return annual_df.reset_index().to_dict('records')\n",
        "\n",
        "def merge_all_data(albedo_data, radiation_data, temperature_data, wind_data, topo_data, landcover_data):\n",
        "    \"\"\"\n",
        "    Combina todos los datos en un solo DataFrame.\n",
        "\n",
        "    Args:\n",
        "        albedo_data (list): Lista de diccionarios con datos de albedo\n",
        "        radiation_data (list): Lista de diccionarios con datos de radiaci√≥n\n",
        "        temperature_data (list): Lista de diccionarios con datos de temperatura\n",
        "        wind_data (list): Lista de diccionarios con datos de viento\n",
        "        topo_data (dict): Diccionario con datos topogr√°ficos\n",
        "        landcover_data (dict): Diccionario con datos de cobertura terrestre\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame con todos los datos combinados\n",
        "    \"\"\"\n",
        "    # Convertir listas a DataFrames\n",
        "    dfs = []\n",
        "\n",
        "    # Solo agregar DataFrames v√°lidos con columna 'date'\n",
        "    if albedo_data:\n",
        "        try:\n",
        "            df = pd.DataFrame(albedo_data)\n",
        "            if not df.empty and 'date' in df.columns:\n",
        "                dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error al convertir datos de albedo a DataFrame: {e}\")\n",
        "\n",
        "    if radiation_data:\n",
        "        try:\n",
        "            df = pd.DataFrame(radiation_data)\n",
        "            if not df.empty and 'date' in df.columns:\n",
        "                dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error al convertir datos de radiaci√≥n a DataFrame: {e}\")\n",
        "\n",
        "    if temperature_data:\n",
        "        try:\n",
        "            df = pd.DataFrame(temperature_data)\n",
        "            if not df.empty and 'date' in df.columns:\n",
        "                dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error al convertir datos de temperatura a DataFrame: {e}\")\n",
        "\n",
        "    if wind_data:\n",
        "        try:\n",
        "            df = pd.DataFrame(wind_data)\n",
        "            if not df.empty and 'date' in df.columns:\n",
        "                dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error al convertir datos de viento a DataFrame: {e}\")\n",
        "\n",
        "    # Si no hay DataFrames v√°lidos, retornar DataFrame vac√≠o con columna 'date'\n",
        "    if not dfs:\n",
        "        print(\"‚ö†Ô∏è Advertencia: No hay datos disponibles para el per√≠odo seleccionado\")\n",
        "        return pd.DataFrame({'date': []})\n",
        "\n",
        "    # Combinar DataFrames de forma segura\n",
        "    merged_df = safe_merge(dfs)\n",
        "\n",
        "    # Si el DataFrame resultante est√° vac√≠o o no tiene columna 'date', retornar DataFrame vac√≠o con columna 'date'\n",
        "    if merged_df.empty or 'date' not in merged_df.columns:\n",
        "        print(\"‚ö†Ô∏è El DataFrame combinado est√° vac√≠o o no tiene columna 'date'\")\n",
        "        return pd.DataFrame({'date': []})\n",
        "\n",
        "    # A√±adir datos topogr√°ficos (constantes para todas las fechas)\n",
        "    if topo_data:\n",
        "        for key, value in topo_data.items():\n",
        "            merged_df[key] = value\n",
        "\n",
        "    # A√±adir datos de cobertura terrestre (constantes para todas las fechas)\n",
        "    if landcover_data:\n",
        "        for key, value in landcover_data.items():\n",
        "            merged_df[key] = value\n",
        "\n",
        "    return merged_df\n",
        "\n",
        "def visualize_location(lat, lon, zoom=10):\n",
        "    \"\"\"\n",
        "    Visualiza la ubicaci√≥n en un mapa interactivo.\n",
        "\n",
        "    Args:\n",
        "        lat (float): Latitud\n",
        "        lon (float): Longitud\n",
        "        zoom (int): Nivel de zoom\n",
        "    \"\"\"\n",
        "    # Crear mapa centrado en la ubicaci√≥n\n",
        "    m = folium.Map(location=[lat, lon], zoom_start=zoom)\n",
        "\n",
        "    # A√±adir marcador\n",
        "    folium.Marker(\n",
        "        location=[lat, lon],\n",
        "        popup=f\"Lat: {lat}, Lon: {lon}\",\n",
        "        icon=folium.Icon(color=\"red\", icon=\"info-sign\")\n",
        "    ).add_to(m)\n",
        "\n",
        "    # Mostrar mapa\n",
        "    display(m)\n",
        "\n",
        "def plot_data(df, variable, title=None, ylabel=None):\n",
        "    \"\"\"\n",
        "    Genera un gr√°fico de l√≠nea para una variable espec√≠fica.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame con los datos\n",
        "        variable (str): Nombre de la columna a graficar\n",
        "        title (str, optional): T√≠tulo del gr√°fico\n",
        "        ylabel (str, optional): Etiqueta del eje Y\n",
        "    \"\"\"\n",
        "    if df.empty or variable not in df.columns:\n",
        "        print(f\"‚ö†Ô∏è No hay datos disponibles para graficar {variable}\")\n",
        "        return\n",
        "\n",
        "    # Verificar que hay datos no nulos para graficar\n",
        "    if df[variable].isna().all():\n",
        "        print(f\"‚ö†Ô∏è Todos los valores de {variable} son nulos, no se puede graficar\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(df['date'], df[variable], marker='o', linestyle='-')\n",
        "    plt.title(title or f\"{variable} a lo largo del tiempo\")\n",
        "    plt.xlabel(\"Fecha\")\n",
        "    plt.ylabel(ylabel or variable)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def validate_date_range(start_date, end_date, frequency):\n",
        "    \"\"\"\n",
        "    Valida el rango de fechas y la frecuencia, mostrando advertencias si es necesario.\n",
        "\n",
        "    Args:\n",
        "        start_date (datetime): Fecha de inicio\n",
        "        end_date (datetime): Fecha de fin\n",
        "        frequency (str): Frecuencia de los datos ('daily', 'monthly', o 'annual')\n",
        "\n",
        "    Returns:\n",
        "        bool: True si el rango es v√°lido, False si es potencialmente problem√°tico\n",
        "    \"\"\"\n",
        "    # Calcular la duraci√≥n en d√≠as\n",
        "    duration_days = (end_date - start_date).days + 1\n",
        "\n",
        "    # Validar seg√∫n la frecuencia\n",
        "    if frequency == 'daily':\n",
        "        if duration_days > 90:  # M√°s de 3 meses\n",
        "            print(f\"‚ö†Ô∏è ADVERTENCIA: Has seleccionado {duration_days} d√≠as con frecuencia diaria.\")\n",
        "            print(\"‚ö†Ô∏è Esto puede causar problemas de memoria o tiempos de procesamiento muy largos.\")\n",
        "            print(\"‚ö†Ô∏è Se recomienda reducir el rango de fechas o cambiar a frecuencia mensual.\")\n",
        "            return False\n",
        "    elif frequency == 'monthly':\n",
        "        if duration_days > 1095:  # M√°s de 3 a√±os\n",
        "            print(f\"‚ö†Ô∏è ADVERTENCIA: Has seleccionado un per√≠odo de m√°s de 3 a√±os con frecuencia mensual.\")\n",
        "            print(\"‚ö†Ô∏è Esto puede causar tiempos de procesamiento largos.\")\n",
        "            print(\"‚ö†Ô∏è Considera reducir el rango de fechas o cambiar a frecuencia anual para per√≠odos muy largos.\")\n",
        "            return False\n",
        "\n",
        "    return True\n",
        "\n",
        "def suggest_alternative_dates(point):\n",
        "    \"\"\"\n",
        "    Sugiere fechas alternativas con buena disponibilidad de datos.\n",
        "\n",
        "    Args:\n",
        "        point (ee.Geometry.Point): Punto de inter√©s\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de a√±os con buena disponibilidad de datos\n",
        "    \"\"\"\n",
        "    print(\"üîç Buscando per√≠odos con mejor disponibilidad de datos...\")\n",
        "\n",
        "    # Lista de a√±os a verificar (m√°s recientes primero)\n",
        "    years_to_check = list(range(2022, 2015, -1))\n",
        "    good_years = []\n",
        "\n",
        "    for year in years_to_check:\n",
        "        year_start = f\"{year}-01-01\"\n",
        "        year_end = f\"{year}-12-31\"\n",
        "\n",
        "        # Verificar albedo\n",
        "        albedo_collection = ee.ImageCollection('MODIS/061/MCD43A3') \\\n",
        "            .filterDate(year_start, year_end) \\\n",
        "            .filterBounds(point)\n",
        "        albedo_count = albedo_collection.size().getInfo()\n",
        "\n",
        "        # Verificar si se pueden extraer datos de albedo\n",
        "        albedo_extractable = False\n",
        "        if albedo_count > 0:\n",
        "            has_data, valid_count = test_point_data_extraction(\n",
        "                albedo_collection, point, 'Albedo_BSA_vis')\n",
        "            albedo_extractable = has_data\n",
        "\n",
        "        # Verificar radiaci√≥n\n",
        "        radiation_collection = ee.ImageCollection('MODIS/061/MCD18A1') \\\n",
        "            .filterDate(year_start, year_end) \\\n",
        "            .filterBounds(point)\n",
        "        radiation_count = radiation_collection.size().getInfo()\n",
        "\n",
        "        # Verificar si se pueden extraer datos de radiaci√≥n\n",
        "        radiation_extractable = False\n",
        "        if radiation_count > 0:\n",
        "            first_image = radiation_collection.first()\n",
        "            if first_image:\n",
        "                available_bands = first_image.bandNames().getInfo()\n",
        "                test_band = None\n",
        "                if 'DSR' in available_bands:\n",
        "                    test_band = 'DSR'\n",
        "                elif 'Direct' in available_bands:\n",
        "                    test_band = 'Direct'\n",
        "                elif 'Diffuse' in available_bands:\n",
        "                    test_band = 'Diffuse'\n",
        "\n",
        "                if test_band:\n",
        "                    has_data, valid_count = test_point_data_extraction(\n",
        "                        radiation_collection, point, test_band)\n",
        "                    radiation_extractable = has_data\n",
        "\n",
        "        # Verificar temperatura\n",
        "        temperature_collection = ee.ImageCollection('MODIS/061/MOD11A1') \\\n",
        "            .filterDate(year_start, year_end) \\\n",
        "            .filterBounds(point)\n",
        "        temperature_count = temperature_collection.size().getInfo()\n",
        "\n",
        "        # Verificar si se pueden extraer datos de temperatura\n",
        "        temperature_extractable = False\n",
        "        if temperature_count > 0:\n",
        "            has_data, valid_count = test_point_data_extraction(\n",
        "                temperature_collection, point, 'LST_Day_1km')\n",
        "            temperature_extractable = has_data\n",
        "\n",
        "        # Evaluar disponibilidad\n",
        "        extractable_count = sum([albedo_extractable, radiation_extractable, temperature_extractable])\n",
        "        if extractable_count >= 2:  # Al menos 2 de 3 tipos de datos son extra√≠bles\n",
        "            good_years.append(year)\n",
        "            print(f\"‚úÖ {year}: Buena disponibilidad de datos extra√≠bles\")\n",
        "            print(f\"   - Albedo: {'‚úì' if albedo_extractable else '‚úó'}\")\n",
        "            print(f\"   - Radiaci√≥n: {'‚úì' if radiation_extractable else '‚úó'}\")\n",
        "            print(f\"   - Temperatura: {'‚úì' if temperature_extractable else '‚úó'}\")\n",
        "\n",
        "            # Limitar a los 3 mejores a√±os\n",
        "            if len(good_years) >= 3:\n",
        "                break\n",
        "        else:\n",
        "            print(f\"‚ùå {year}: Disponibilidad limitada de datos extra√≠bles\")\n",
        "            print(f\"   - Albedo: {'‚úì' if albedo_extractable else '‚úó'}\")\n",
        "            print(f\"   - Radiaci√≥n: {'‚úì' if radiation_extractable else '‚úó'}\")\n",
        "            print(f\"   - Temperatura: {'‚úì' if temperature_extractable else '‚úó'}\")\n",
        "\n",
        "    if good_years:\n",
        "        print(f\"\\n‚ú® Sugerencia: Prueba con el a√±o {good_years[0]} para obtener mejores resultados.\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è No se encontraron a√±os con buena disponibilidad de datos extra√≠bles para esta ubicaci√≥n.\")\n",
        "        print(\"‚ö†Ô∏è Considera probar con otra ubicaci√≥n o utilizar fuentes de datos alternativas.\")\n",
        "\n",
        "    return good_years\n",
        "\n",
        "def extract_solar_data_colab(lat, lon, start_date, end_date, frequency='monthly', output_filename='solar_data.csv', check_availability=True):\n",
        "    \"\"\"\n",
        "    Funci√≥n principal para extraer datos solares en Google Colab.\n",
        "\n",
        "    Args:\n",
        "        lat (float): Latitud del punto de inter√©s\n",
        "        lon (float): Longitud del punto de inter√©s\n",
        "        start_date (str): Fecha de inicio en formato YYYY-MM-DD\n",
        "        end_date (str): Fecha de fin en formato YYYY-MM-DD\n",
        "        frequency (str): Frecuencia de los datos ('daily', 'monthly', o 'annual')\n",
        "        output_filename (str): Nombre del archivo CSV de salida\n",
        "        check_availability (bool): Si es True, verifica la disponibilidad de datos antes de procesar\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame con todos los datos combinados\n",
        "    \"\"\"\n",
        "    # Inicializar Earth Engine\n",
        "    if not initialize_ee_colab():\n",
        "        return None\n",
        "\n",
        "    # Convertir fechas\n",
        "    start_date_dt = parse_date(start_date)\n",
        "    end_date_dt = parse_date(end_date)\n",
        "\n",
        "    # Validar rango de fechas y frecuencia\n",
        "    is_valid = validate_date_range(start_date_dt, end_date_dt, frequency)\n",
        "    if not is_valid:\n",
        "        print(\"‚ö†Ô∏è Continuando con la extracci√≥n, pero puede haber problemas de rendimiento.\")\n",
        "\n",
        "    # Crear punto\n",
        "    point = ee.Geometry.Point([lon, lat])\n",
        "\n",
        "    # Visualizar ubicaci√≥n\n",
        "    print(f\"üìç Ubicaci√≥n seleccionada: Latitud {lat}, Longitud {lon}\")\n",
        "    visualize_location(lat, lon)\n",
        "\n",
        "    # Verificar disponibilidad de datos\n",
        "    if check_availability:\n",
        "        availability = check_data_availability(point, start_date, end_date)\n",
        "\n",
        "        # Verificar si hay datos extra√≠bles\n",
        "        extractable_count = sum(1 for v in availability.values() if v.get('extractable', False))\n",
        "\n",
        "        # Si no hay datos extra√≠bles, sugerir fechas alternativas\n",
        "        if extractable_count < 3:  # Menos de 3 tipos de datos extra√≠bles\n",
        "            good_years = suggest_alternative_dates(point)\n",
        "            if good_years:\n",
        "                print(\"\\n‚ö†Ô∏è Continuando con la extracci√≥n original, pero es probable que no se encuentren suficientes datos.\")\n",
        "            else:\n",
        "                print(\"\\n‚ö†Ô∏è Continuando con la extracci√≥n, pero es probable que no se encuentren datos.\")\n",
        "\n",
        "    print(f\"‚è≥ Extrayendo datos desde {start_date} hasta {end_date} con frecuencia {frequency}...\")\n",
        "\n",
        "    try:\n",
        "        # Obtener datos\n",
        "        print(\"üîÑ Obteniendo datos de albedo...\")\n",
        "        albedo_collection = get_albedo_data(point, start_date, end_date)\n",
        "\n",
        "        print(\"üîÑ Obteniendo datos de radiaci√≥n solar...\")\n",
        "        radiation_collection = get_solar_radiation_data(point, start_date, end_date)\n",
        "\n",
        "        print(\"üîÑ Obteniendo datos de temperatura...\")\n",
        "        temperature_collection = get_temperature_data(point, start_date, end_date)\n",
        "\n",
        "        print(\"üîÑ Obteniendo datos de viento...\")\n",
        "        # No obtenemos la colecci√≥n completa aqu√≠, se procesar√° en chunks\n",
        "\n",
        "        print(\"üîÑ Obteniendo datos topogr√°ficos...\")\n",
        "        topo_data = get_elevation_data(point)\n",
        "\n",
        "        # Para cobertura terrestre, usar el a√±o medio del rango\n",
        "        mid_year = start_date_dt.year + (end_date_dt.year - start_date_dt.year) // 2\n",
        "        print(f\"üîÑ Obteniendo datos de cobertura terrestre para el a√±o {mid_year}...\")\n",
        "        landcover_data = get_landcover_data(point, mid_year)\n",
        "\n",
        "        # Procesar datos\n",
        "        print(\"üîÑ Procesando datos de albedo...\")\n",
        "        albedo_data = process_albedo_data(albedo_collection, point, frequency, start_date_dt, end_date_dt)\n",
        "\n",
        "        print(\"üîÑ Procesando datos de radiaci√≥n solar...\")\n",
        "        radiation_data = process_radiation_data(radiation_collection, point, frequency, start_date_dt, end_date_dt)\n",
        "\n",
        "        print(\"üîÑ Procesando datos de temperatura...\")\n",
        "        temperature_data = process_temperature_data(temperature_collection, point, frequency, start_date_dt, end_date_dt)\n",
        "\n",
        "        print(\"üîÑ Procesando datos de viento (en chunks para evitar problemas de memoria)...\")\n",
        "        wind_data = process_wind_data_chunked(point, start_date_dt, end_date_dt, frequency)\n",
        "\n",
        "        print(\"üîÑ Extrayendo datos topogr√°ficos...\")\n",
        "        topo_values = extract_static_values(topo_data, point)\n",
        "\n",
        "        print(\"üîÑ Extrayendo datos de cobertura terrestre...\")\n",
        "        landcover_values = {}\n",
        "        if landcover_data is not None:\n",
        "            landcover_values = extract_static_values(landcover_data, point)\n",
        "\n",
        "        # Combinar todos los datos\n",
        "        print(\"üîÑ Combinando todos los datos...\")\n",
        "        merged_df = merge_all_data(albedo_data, radiation_data, temperature_data, wind_data, topo_values, landcover_values)\n",
        "\n",
        "        if merged_df.empty or 'date' not in merged_df.columns or len(merged_df) == 0:\n",
        "            print(\"‚ùå No se encontraron datos para el per√≠odo y ubicaci√≥n especificados.\")\n",
        "\n",
        "            # Sugerir fechas alternativas si no se encontraron datos\n",
        "            good_years = suggest_alternative_dates(point)\n",
        "\n",
        "            # Crear un DataFrame vac√≠o con columna 'date' para evitar errores\n",
        "            empty_df = pd.DataFrame({'date': []})\n",
        "            empty_df.to_csv(output_filename, index=False)\n",
        "            files.download(output_filename)\n",
        "            print(f\"‚úÖ Se ha generado un archivo CSV vac√≠o: {output_filename}\")\n",
        "            return empty_df\n",
        "\n",
        "        # Guardar a CSV\n",
        "        print(f\"üíæ Guardando datos en {output_filename}...\")\n",
        "        merged_df.to_csv(output_filename, index=False)\n",
        "\n",
        "        # Descargar archivo\n",
        "        files.download(output_filename)\n",
        "\n",
        "        print(f\"‚úÖ ¬°Completado! Los datos se han guardado y descargado como {output_filename}\")\n",
        "\n",
        "        # Mostrar algunas visualizaciones\n",
        "        print(\"\\nüìä Visualizaciones de los datos:\")\n",
        "\n",
        "        # Buscar columnas de radiaci√≥n\n",
        "        radiation_cols = [col for col in merged_df.columns if 'radiation' in col.lower()]\n",
        "        if radiation_cols and not merged_df[radiation_cols[0]].isna().all():\n",
        "            plot_data(merged_df, radiation_cols[0], f'Radiaci√≥n Solar ({radiation_cols[0]})', 'W/m¬≤')\n",
        "\n",
        "        # Buscar columnas de temperatura\n",
        "        if 'temp_mean' in merged_df.columns and not merged_df['temp_mean'].isna().all():\n",
        "            plot_data(merged_df, 'temp_mean', 'Temperatura Media', '¬∞C')\n",
        "        elif 'temp_day' in merged_df.columns and not merged_df['temp_day'].isna().all():\n",
        "            plot_data(merged_df, 'temp_day', 'Temperatura Diurna', '¬∞C')\n",
        "\n",
        "        # Buscar columnas de albedo\n",
        "        albedo_cols = [col for col in merged_df.columns if 'bsa' in col.lower() or 'wsa' in col.lower()]\n",
        "        if albedo_cols and not merged_df[albedo_cols[0]].isna().all():\n",
        "            plot_data(merged_df, albedo_cols[0], f'Albedo ({albedo_cols[0]})', 'Albedo')\n",
        "\n",
        "        # Buscar columnas de viento\n",
        "        if 'wind_speed' in merged_df.columns and not merged_df['wind_speed'].isna().all():\n",
        "            plot_data(merged_df, 'wind_speed', 'Velocidad del Viento', 'm/s')\n",
        "\n",
        "        # Mostrar resumen de los datos\n",
        "        if not merged_df.empty and len(merged_df) > 0:\n",
        "            print(\"\\nüìã Resumen de los datos extra√≠dos:\")\n",
        "            print(merged_df.describe())\n",
        "\n",
        "        return merged_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error durante la extracci√≥n de datos: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        # Crear un DataFrame vac√≠o con columna 'date' para evitar errores\n",
        "        empty_df = pd.DataFrame({'date': []})\n",
        "        empty_df.to_csv(output_filename, index=False)\n",
        "        files.download(output_filename)\n",
        "        print(f\"‚úÖ Se ha generado un archivo CSV vac√≠o: {output_filename}\")\n",
        "        return empty_df\n"
      ],
      "metadata": {
        "id": "u3UQc_WFg5hx",
        "outputId": "c4431950-d1a1-4057-e94e-2340c8707e2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = extract_solar_data_colab(\n",
        "    lat=37.290019,\n",
        "    lon=-5.966487,\n",
        "    start_date='2018-01-01',\n",
        "    end_date='2018-12-31',\n",
        "    frequency='monthly',\n",
        "    output_filename='svq_2018_monthly.csv',\n",
        "    check_availability=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lU92_tNqX4g_",
        "outputId": "6d1546b8-7e09-48fb-cd78-15dfb2534bfb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Earth Engine inicializado correctamente.\n",
            "‚úÖ Autenticaci√≥n completada con √©xito.\n",
            "üìç Ubicaci√≥n seleccionada: Latitud 37.290019, Longitud -5.966487\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<folium.folium.Map at 0x7f8237e79e10>"
            ],
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_da24cbde4c1962d88a45a09928abd6a1 {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_da24cbde4c1962d88a45a09928abd6a1&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_da24cbde4c1962d88a45a09928abd6a1 = L.map(\n",
              "                &quot;map_da24cbde4c1962d88a45a09928abd6a1&quot;,\n",
              "                {\n",
              "                    center: [37.290019, -5.966487],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    ...{\n",
              "  &quot;zoom&quot;: 10,\n",
              "  &quot;zoomControl&quot;: true,\n",
              "  &quot;preferCanvas&quot;: false,\n",
              "}\n",
              "\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_1cc6574c2a515355901b1144aae4846d = L.tileLayer(\n",
              "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {\n",
              "  &quot;minZoom&quot;: 0,\n",
              "  &quot;maxZoom&quot;: 19,\n",
              "  &quot;maxNativeZoom&quot;: 19,\n",
              "  &quot;noWrap&quot;: false,\n",
              "  &quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;,\n",
              "  &quot;subdomains&quot;: &quot;abc&quot;,\n",
              "  &quot;detectRetina&quot;: false,\n",
              "  &quot;tms&quot;: false,\n",
              "  &quot;opacity&quot;: 1,\n",
              "}\n",
              "\n",
              "            );\n",
              "        \n",
              "    \n",
              "            tile_layer_1cc6574c2a515355901b1144aae4846d.addTo(map_da24cbde4c1962d88a45a09928abd6a1);\n",
              "        \n",
              "    \n",
              "            var marker_bdbc3a000e055bc4d1a041ffc54f814d = L.marker(\n",
              "                [37.290019, -5.966487],\n",
              "                {\n",
              "}\n",
              "            ).addTo(map_da24cbde4c1962d88a45a09928abd6a1);\n",
              "        \n",
              "    \n",
              "            var icon_bcec6d63d68f5eeea974c654a2830ab6 = L.AwesomeMarkers.icon(\n",
              "                {\n",
              "  &quot;markerColor&quot;: &quot;red&quot;,\n",
              "  &quot;iconColor&quot;: &quot;white&quot;,\n",
              "  &quot;icon&quot;: &quot;info-sign&quot;,\n",
              "  &quot;prefix&quot;: &quot;glyphicon&quot;,\n",
              "  &quot;extraClasses&quot;: &quot;fa-rotate-0&quot;,\n",
              "}\n",
              "            );\n",
              "        \n",
              "    \n",
              "        var popup_c989cca7d71705fc351fe677304427ad = L.popup({\n",
              "  &quot;maxWidth&quot;: &quot;100%&quot;,\n",
              "});\n",
              "\n",
              "        \n",
              "            \n",
              "                var html_464e7639ecffb50ab56df5ab097b2951 = $(`&lt;div id=&quot;html_464e7639ecffb50ab56df5ab097b2951&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Lat: 37.290019, Lon: -5.966487&lt;/div&gt;`)[0];\n",
              "                popup_c989cca7d71705fc351fe677304427ad.setContent(html_464e7639ecffb50ab56df5ab097b2951);\n",
              "            \n",
              "        \n",
              "\n",
              "        marker_bdbc3a000e055bc4d1a041ffc54f814d.bindPopup(popup_c989cca7d71705fc351fe677304427ad)\n",
              "        ;\n",
              "\n",
              "        \n",
              "    \n",
              "    \n",
              "                marker_bdbc3a000e055bc4d1a041ffc54f814d.setIcon(icon_bcec6d63d68f5eeea974c654a2830ab6);\n",
              "            \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "üìä Disponibilidad de datos de albedo: 364 im√°genes en la colecci√≥n, 0 extra√≠bles para el punto\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "üìä Disponibilidad de datos de radiaci√≥n solar: 364 im√°genes en la colecci√≥n, 0 extra√≠bles para el punto\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "üìä Disponibilidad de datos de temperatura: 364 im√°genes en la colecci√≥n, 0 extra√≠bles para el punto\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "üìä Disponibilidad de datos de viento: 24 im√°genes en la colecci√≥n, 0 extra√≠bles para el punto\n",
            "üìä Disponibilidad de datos de elevaci√≥n: S√≠\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "üìä Disponibilidad de datos de cobertura terrestre: 1 im√°genes en la colecci√≥n, 0 extra√≠bles para el punto\n",
            "\n",
            "üìã Resumen de disponibilidad:\n",
            "  - 6/6 tipos de datos disponibles en las colecciones\n",
            "  - 1/6 tipos de datos extra√≠bles para el punto espec√≠fico\n",
            "\n",
            "‚ö†Ô∏è ADVERTENCIA: Pocos tipos de datos extra√≠bles para esta ubicaci√≥n y per√≠odo.\n",
            "‚ö†Ô∏è El CSV resultante tendr√° informaci√≥n limitada.\n",
            "üîç Buscando per√≠odos con mejor disponibilidad de datos...\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ùå 2022: Disponibilidad limitada de datos extra√≠bles\n",
            "   - Albedo: ‚úó\n",
            "   - Radiaci√≥n: ‚úó\n",
            "   - Temperatura: ‚úó\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ùå 2021: Disponibilidad limitada de datos extra√≠bles\n",
            "   - Albedo: ‚úó\n",
            "   - Radiaci√≥n: ‚úó\n",
            "   - Temperatura: ‚úó\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ùå 2020: Disponibilidad limitada de datos extra√≠bles\n",
            "   - Albedo: ‚úó\n",
            "   - Radiaci√≥n: ‚úó\n",
            "   - Temperatura: ‚úó\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ùå 2019: Disponibilidad limitada de datos extra√≠bles\n",
            "   - Albedo: ‚úó\n",
            "   - Radiaci√≥n: ‚úó\n",
            "   - Temperatura: ‚úó\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ùå 2018: Disponibilidad limitada de datos extra√≠bles\n",
            "   - Albedo: ‚úó\n",
            "   - Radiaci√≥n: ‚úó\n",
            "   - Temperatura: ‚úó\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ùå 2017: Disponibilidad limitada de datos extra√≠bles\n",
            "   - Albedo: ‚úó\n",
            "   - Radiaci√≥n: ‚úó\n",
            "   - Temperatura: ‚úó\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ö†Ô∏è Error al probar extracci√≥n de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "‚ùå 2016: Disponibilidad limitada de datos extra√≠bles\n",
            "   - Albedo: ‚úó\n",
            "   - Radiaci√≥n: ‚úó\n",
            "   - Temperatura: ‚úó\n",
            "\n",
            "‚ö†Ô∏è No se encontraron a√±os con buena disponibilidad de datos extra√≠bles para esta ubicaci√≥n.\n",
            "‚ö†Ô∏è Considera probar con otra ubicaci√≥n o utilizar fuentes de datos alternativas.\n",
            "\n",
            "‚ö†Ô∏è Continuando con la extracci√≥n, pero es probable que no se encuentren datos.\n",
            "‚è≥ Extrayendo datos desde 2018-01-01 hasta 2018-12-31 con frecuencia monthly...\n",
            "üîÑ Obteniendo datos de albedo...\n",
            "üîÑ Obteniendo datos de radiaci√≥n solar...\n",
            "üîÑ Obteniendo datos de temperatura...\n",
            "üîÑ Obteniendo datos de viento...\n",
            "üîÑ Obteniendo datos topogr√°ficos...\n",
            "üîÑ Obteniendo datos de cobertura terrestre para el a√±o 2018...\n",
            "üîÑ Procesando datos de albedo...\n",
            "‚ö†Ô∏è No se encontraron valores v√°lidos para el punto en ninguna de las 364 im√°genes\n",
            "‚ö†Ô∏è No se encontraron valores v√°lidos para el punto en ninguna de las 364 im√°genes\n",
            "‚ö†Ô∏è No se encontraron valores v√°lidos para el punto en ninguna de las 364 im√°genes\n",
            "‚ö†Ô∏è No se encontraron valores v√°lidos para el punto en ninguna de las 364 im√°genes\n",
            "‚ö†Ô∏è No se encontraron valores v√°lidos para el punto en ninguna de las 364 im√°genes\n",
            "‚ö†Ô∏è No se encontraron valores v√°lidos para el punto en ninguna de las 364 im√°genes\n",
            "‚ö†Ô∏è Advertencia: No hay datos de albedo disponibles para el per√≠odo seleccionado\n",
            "üîÑ Procesando datos de radiaci√≥n solar...\n",
            "‚ö†Ô∏è No se encontraron valores v√°lidos para el punto en ninguna de las 364 im√°genes\n",
            "‚ö†Ô∏è No se encontraron valores v√°lidos para el punto en ninguna de las 364 im√°genes\n",
            "‚ö†Ô∏è No se encontraron valores v√°lidos para el punto en ninguna de las 364 im√°genes\n",
            "‚ö†Ô∏è Advertencia: No hay datos de radiaci√≥n solar disponibles para el per√≠odo seleccionado\n",
            "üîÑ Procesando datos de temperatura...\n",
            "‚ö†Ô∏è No se encontraron valores v√°lidos para el punto en ninguna de las 364 im√°genes\n",
            "‚ö†Ô∏è No se encontraron valores v√°lidos para el punto en ninguna de las 364 im√°genes\n",
            "‚ö†Ô∏è Advertencia: No hay datos de temperatura disponibles para el per√≠odo seleccionado\n",
            "üîÑ Procesando datos de viento (en chunks para evitar problemas de memoria)...\n",
            "üîÑ Procesando chunk de viento 1/13: 2018-01-01 a 2018-01-30\n",
            "‚ö†Ô∏è No se encontraron valores v√°lidos para el punto en ninguna de las 29 im√°genes\n",
            "‚ö†Ô∏è No se encontraron valores v√°lidos para el punto en ninguna de las 29 im√°genes\n",
            "‚ö†Ô∏è No hay datos de viento disponibles para el chunk 2018-01-01 a 2018-01-30\n",
            "üîÑ Procesando chunk de viento 2/13: 2018-01-31 a 2018-03-01\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-1184aa342cb8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m data = extract_solar_data_colab(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mlat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m37.290019\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5.966487\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstart_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2018-01-01'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mend_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2018-12-31'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-7111cbf89c92>\u001b[0m in \u001b[0;36mextract_solar_data_colab\u001b[0;34m(lat, lon, start_date, end_date, frequency, output_filename, check_availability)\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üîÑ Procesando datos de viento (en chunks para evitar problemas de memoria)...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1381\u001b[0;31m         \u001b[0mwind_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_wind_data_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üîÑ Extrayendo datos topogr√°ficos...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-7111cbf89c92>\u001b[0m in \u001b[0;36mprocess_wind_data_chunked\u001b[0;34m(point, start_date, end_date, frequency, max_chunk_days)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mu_band\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                     \u001b[0mu_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_point_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwind_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_band\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mu_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                         \u001b[0mu_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wind_u'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_band\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-7111cbf89c92>\u001b[0m in \u001b[0;36mextract_point_values\u001b[0;34m(image_collection, point, scale, band_name)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;31m# Convertir a lista para descargar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'properties'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0;31m# Filtrar resultados para eliminar valores vac√≠os\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ee/computedobject.py\u001b[0m in \u001b[0;36mgetInfo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0mto\u001b[0m \u001b[0manything\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ee/data.py\u001b[0m in \u001b[0;36mcomputeValue\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0m_maybe_populate_workload_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m   return _execute_cloud_call(\n\u001b[0m\u001b[1;32m   1129\u001b[0m       \u001b[0m_get_cloud_projects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ee/data.py\u001b[0m in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    406\u001b[0m   \u001b[0mnum_retries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_max_retries\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum_retries\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0m_translate_cloud_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=raise-missing-from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;31m# Handle retries for server-side errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         resp, content = _retry_request(\n\u001b[0m\u001b[1;32m    924\u001b[0m             \u001b[0mhttp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0mnum_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Retry on SSL errors and socket timeout errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_ssl_SSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mssl_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google_auth_httplib2.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;31m# Make the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         response, content = self.http.request(\n\u001b[0m\u001b[1;32m    219\u001b[0m             \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ee/_cloud_api_utils.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0;31m# requests errors should be converted to kinds that googleapiclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;31m# consider transient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m       response = self._session.request(\n\u001b[0m\u001b[1;32m     71\u001b[0m           \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I_Fr0L5AFmu"
      },
      "source": [
        "## Test the API\n",
        "\n",
        "Test the API by printing the elevation of Mount Everest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7pD6pDOAhOW"
      },
      "source": [
        "# Print the elevation of Mount Everest.\n",
        "dem = ee.Image('USGS/SRTMGL1_003')\n",
        "xy = ee.Geometry.Point([86.9250, 27.9881])\n",
        "elev = dem.sample(xy, 30).first().get('elevation').getInfo()\n",
        "print('Mount Everest elevation (m):', elev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDLAqiNWeD6t"
      },
      "source": [
        "## Map visualization\n",
        "\n",
        "`ee.Image` objects can be displayed to notebook output cells. The following two\n",
        "examples demonstrate displaying a static image and an interactive map.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45BfeVygwmKm"
      },
      "source": [
        "### Static image\n",
        "\n",
        "The `IPython.display` module contains the `Image` function, which can display\n",
        "the results of a URL representing an image generated from a call to the Earth\n",
        "Engine `getThumbUrl` function. The following cell will display a thumbnail\n",
        "of the global elevation model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp4rdpy0eGjx"
      },
      "source": [
        "# Import the Image function from the IPython.display module.\n",
        "from IPython.display import Image\n",
        "\n",
        "# Display a thumbnail of global elevation.\n",
        "Image(url = dem.updateMask(dem.gt(0))\n",
        "  .getThumbURL({'min': 0, 'max': 4000, 'dimensions': 512,\n",
        "                'palette': ['006633', 'E5FFCC', '662A00', 'D8D8D8', 'F5F5F5']}))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljo5dbLkfmVm"
      },
      "source": [
        "### Interactive map\n",
        "\n",
        "The [geemap](https://github.com/gee-community/geemap)\n",
        "library can be used to display `ee.Image` objects on an interactive\n",
        "[ipyleaflet](https://github.com/jupyter-widgets/ipyleaflet) map.\n",
        "\n",
        "The following cell provides an example of using the `geemap.Map` object to\n",
        "display an elevation model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIiyf6azf4mU"
      },
      "source": [
        "# Import the geemap library.\n",
        "import geemap\n",
        "\n",
        "# Set visualization parameters.\n",
        "vis_params = {\n",
        "  'min': 0,\n",
        "  'max': 4000,\n",
        "  'palette': ['006633', 'E5FFCC', '662A00', 'D8D8D8', 'F5F5F5']}\n",
        "\n",
        "# Create a map object.\n",
        "m = geemap.Map(center=[20, 0], zoom=3)\n",
        "\n",
        "# Add the elevation model to the map object.\n",
        "m.add_ee_layer(dem.updateMask(dem.gt(0)), vis_params, 'DEM')\n",
        "\n",
        "# Display the map.\n",
        "display(m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYfinjFhg0HN"
      },
      "source": [
        "## Chart visualization\n",
        "\n",
        "Some Earth Engine functions produce tabular data that can be plotted by\n",
        "data visualization packages such as `matplotlib`. The following example\n",
        "demonstrates the display of tabular data from Earth Engine as a scatter\n",
        "plot. See [Charting in Colaboratory](https://colab.sandbox.google.com/notebooks/charts.ipynb)\n",
        "for more information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRPULejJhBSl"
      },
      "source": [
        "# Import the matplotlib.pyplot module.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fetch a Landsat TOA image.\n",
        "img = ee.Image('LANDSAT/LT05/C02/T1_TOA/LT05_034033_20000913')\n",
        "\n",
        "# Select Red and NIR bands and sample 500 points.\n",
        "samp_fc = img.select(['B3','B4']).sample(scale=30, numPixels=500)\n",
        "\n",
        "# Arrange the sample as a list of lists.\n",
        "samp_dict = samp_fc.reduceColumns(ee.Reducer.toList().repeat(2), ['B3', 'B4'])\n",
        "samp_list = ee.List(samp_dict.get('list'))\n",
        "\n",
        "# Save server-side ee.List as a client-side Python list.\n",
        "samp_data = samp_list.getInfo()\n",
        "\n",
        "# Display a scatter plot of Red-NIR sample pairs using matplotlib.\n",
        "plt.scatter(samp_data[0], samp_data[1], alpha=0.2)\n",
        "plt.xlabel('Red', fontsize=12)\n",
        "plt.ylabel('NIR', fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}