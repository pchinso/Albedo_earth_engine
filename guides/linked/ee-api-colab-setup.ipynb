{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ee-api-colab-setup.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "krsLgVBYZw_A"
      },
      "source": [
        "#@title Copyright 2019 Google LLC. { display-mode: \"form\" }\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV1xZ1CPi3Nw"
      },
      "source": [
        "<table class=\"ee-notebook-buttons\" align=\"left\"><td>\n",
        "<a target=\"_blank\"  href=\"http://colab.research.google.com/github/google/earthengine-community/blob/master/guides/linked/ee-api-colab-setup.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /> Run in Google Colab</a>\n",
        "</td><td>\n",
        "<a target=\"_blank\"  href=\"https://github.com/google/earthengine-community/blob/master/guides/linked/ee-api-colab-setup.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /> View source on GitHub</a></td></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAZiVi13zTE7"
      },
      "source": [
        "# Earth Engine Python API Colab Setup\n",
        "\n",
        "This notebook demonstrates how to setup the Earth Engine Python API in Colab and provides several examples of how to print and visualize Earth Engine processed data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a69CuP5Q6OI7"
      },
      "source": [
        "## Import API and get credentials\n",
        "\n",
        "The Earth Engine API is installed by default in Google Colaboratory so requires only importing and authenticating. These steps must be completed for each new Colab session, if you restart your Colab kernel, or if your Colab virtual machine is recycled due to inactivity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNh-QBc36Mvk"
      },
      "source": [
        "### Import the API\n",
        "\n",
        "Run the following cell to import the API into your session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65RChERMzQHZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5d69d2ee-19a3-4fd0-f314-f13e5935f4c5"
      },
      "source": [
        "import ee\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import folium"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-dN42MTzg-w"
      },
      "source": [
        "### Authenticate and initialize\n",
        "\n",
        "Run the `ee.Authenticate` function to authenticate your access to Earth Engine servers and `ee.Initialize` to initialize it. Upon running the following cell you'll be asked to grant Earth Engine access to your Google account. Follow the instructions printed to the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMp9Ei9b0XXL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c7463434-698e-424e-fa60-797cd977a909"
      },
      "source": [
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize(project='gen-lang-client-0253961861')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V2"
      ],
      "metadata": {
        "id": "3GIS85utg4Ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_date(date_str):\n",
        "    \"\"\"Convierte una cadena de fecha en formato YYYY-MM-DD a objeto datetime.\"\"\"\n",
        "    try:\n",
        "        return datetime.datetime.strptime(date_str, '%Y-%m-%d')\n",
        "    except ValueError:\n",
        "        raise ValueError(\"El formato de fecha debe ser YYYY-MM-DD\")\n",
        "\n",
        "def get_date_ranges(start_date, end_date, frequency, max_chunk_days=30):\n",
        "    \"\"\"\n",
        "    Genera rangos de fechas según la frecuencia especificada, divididos en chunks para evitar problemas de memoria.\n",
        "\n",
        "    Args:\n",
        "        start_date (datetime): Fecha de inicio\n",
        "        end_date (datetime): Fecha de fin\n",
        "        frequency (str): 'daily', 'monthly', o 'annual'\n",
        "        max_chunk_days (int): Número máximo de días por chunk para frecuencia diaria\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de tuplas (fecha_inicio, fecha_fin) para cada período\n",
        "    \"\"\"\n",
        "    date_ranges = []\n",
        "\n",
        "    if frequency == 'daily':\n",
        "        # Para frecuencia diaria, dividir en chunks para evitar problemas de memoria\n",
        "        current = start_date\n",
        "        while current <= end_date:\n",
        "            chunk_end = min(current + datetime.timedelta(days=max_chunk_days-1), end_date)\n",
        "            date_ranges.append((current.strftime('%Y-%m-%d'), chunk_end.strftime('%Y-%m-%d')))\n",
        "            current = chunk_end + datetime.timedelta(days=1)\n",
        "\n",
        "    elif frequency == 'monthly':\n",
        "        current = datetime.datetime(start_date.year, start_date.month, 1)\n",
        "        while current <= end_date:\n",
        "            next_month = current + relativedelta(months=1)\n",
        "            end_of_month = (next_month - datetime.timedelta(days=1))\n",
        "            if end_of_month > end_date:\n",
        "                end_of_month = end_date\n",
        "            date_ranges.append((current.strftime('%Y-%m-%d'), end_of_month.strftime('%Y-%m-%d')))\n",
        "            current = next_month\n",
        "\n",
        "    elif frequency == 'annual':\n",
        "        current_year = start_date.year\n",
        "        while current_year <= end_date.year:\n",
        "            year_start = max(datetime.datetime(current_year, 1, 1), start_date)\n",
        "            year_end = min(datetime.datetime(current_year, 12, 31), end_date)\n",
        "            date_ranges.append((year_start.strftime('%Y-%m-%d'), year_end.strftime('%Y-%m-%d')))\n",
        "            current_year += 1\n",
        "\n",
        "    return date_ranges\n",
        "\n",
        "def test_point_data_extraction(collection, point, band_name=None, scale=500):\n",
        "    \"\"\"\n",
        "    Prueba la extracción de datos para un punto específico y verifica si hay valores válidos.\n",
        "\n",
        "    Args:\n",
        "        collection (ee.ImageCollection): Colección de imágenes\n",
        "        point (ee.Geometry.Point): Punto de interés\n",
        "        band_name (str, optional): Nombre de la banda específica a extraer\n",
        "        scale (int): Escala en metros\n",
        "\n",
        "    Returns:\n",
        "        tuple: (bool, int) - (True si hay datos extraíbles, número de imágenes con datos válidos)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Verificar si la colección está vacía\n",
        "        count = collection.size().getInfo()\n",
        "        if count == 0:\n",
        "            return False, 0\n",
        "\n",
        "        # Limitar a 10 imágenes para la prueba\n",
        "        test_collection = collection.limit(10)\n",
        "\n",
        "        # Si se especifica una banda, verificar que exista\n",
        "        if band_name:\n",
        "            first_image = test_collection.first()\n",
        "            if first_image is None:\n",
        "                return False, 0\n",
        "\n",
        "            available_bands = first_image.bandNames().getInfo()\n",
        "            if band_name not in available_bands:\n",
        "                return False, 0\n",
        "\n",
        "            test_collection = test_collection.select(band_name)\n",
        "\n",
        "        # Función para extraer valores y verificar si son válidos\n",
        "        def check_valid_data(image):\n",
        "            # Extraer valor en el punto\n",
        "            value_dict = image.reduceRegion(\n",
        "                reducer=ee.Reducer.first(),\n",
        "                geometry=point,\n",
        "                scale=scale\n",
        "            )\n",
        "\n",
        "            # Verificar si hay valores no nulos\n",
        "            # Método correcto para Python: verificar si el diccionario tiene elementos después de getInfo()\n",
        "            value_info = value_dict.getInfo()\n",
        "            has_data = 1 if value_info and any(v is not None for v in value_info.values()) else 0\n",
        "\n",
        "            return image.set('has_data', has_data)\n",
        "\n",
        "        # Aplicar la función a cada imagen en la colección\n",
        "        test_collection = test_collection.map(check_valid_data)\n",
        "\n",
        "        # Contar imágenes con datos válidos\n",
        "        images_with_data = test_collection.filterMetadata('has_data', 'equals', 1).size().getInfo()\n",
        "\n",
        "        return images_with_data > 0, images_with_data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error al probar extracción de datos: {e}\")\n",
        "        return False, 0\n",
        "\n",
        "def check_data_availability(point, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Verifica la disponibilidad de datos para un punto y período específicos.\n",
        "\n",
        "    Args:\n",
        "        point (ee.Geometry.Point): Punto de interés\n",
        "        start_date (str): Fecha de inicio en formato YYYY-MM-DD\n",
        "        end_date (str): Fecha de fin en formato YYYY-MM-DD\n",
        "\n",
        "    Returns:\n",
        "        dict: Diccionario con la disponibilidad de cada tipo de datos\n",
        "    \"\"\"\n",
        "    availability = {\n",
        "        'albedo': {'available': False, 'images': 0, 'extractable': False, 'extractable_images': 0},\n",
        "        'radiation': {'available': False, 'images': 0, 'extractable': False, 'extractable_images': 0},\n",
        "        'temperature': {'available': False, 'images': 0, 'extractable': False, 'extractable_images': 0},\n",
        "        'wind': {'available': False, 'images': 0, 'extractable': False, 'extractable_images': 0},\n",
        "        'elevation': {'available': False, 'extractable': False},\n",
        "        'landcover': {'available': False, 'images': 0, 'extractable': False, 'extractable_images': 0}\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Verificar albedo\n",
        "        albedo_collection = ee.ImageCollection('MODIS/061/MCD43A3') \\\n",
        "            .filterDate(start_date, end_date) \\\n",
        "            .filterBounds(point)\n",
        "        albedo_count = albedo_collection.size().getInfo()\n",
        "        availability['albedo']['available'] = albedo_count > 0\n",
        "        availability['albedo']['images'] = albedo_count\n",
        "\n",
        "        if albedo_count > 0:\n",
        "            # Verificar si se pueden extraer datos de albedo\n",
        "            has_data, valid_count = test_point_data_extraction(\n",
        "                albedo_collection, point, 'Albedo_BSA_vis')\n",
        "            availability['albedo']['extractable'] = has_data\n",
        "            availability['albedo']['extractable_images'] = valid_count\n",
        "\n",
        "            print(f\"📊 Disponibilidad de datos de albedo: {albedo_count} imágenes en la colección, {valid_count} extraíbles para el punto\")\n",
        "        else:\n",
        "            print(f\"📊 Disponibilidad de datos de albedo: {albedo_count} imágenes\")\n",
        "\n",
        "        # Verificar radiación solar\n",
        "        radiation_collection = ee.ImageCollection('MODIS/061/MCD18A1') \\\n",
        "            .filterDate(start_date, end_date) \\\n",
        "            .filterBounds(point)\n",
        "        radiation_count = radiation_collection.size().getInfo()\n",
        "        availability['radiation']['available'] = radiation_count > 0\n",
        "        availability['radiation']['images'] = radiation_count\n",
        "\n",
        "        if radiation_count > 0:\n",
        "            # Verificar si se pueden extraer datos de radiación\n",
        "            # Primero verificar qué bandas están disponibles\n",
        "            first_image = radiation_collection.first()\n",
        "            if first_image:\n",
        "                available_bands = first_image.bandNames().getInfo()\n",
        "                test_band = None\n",
        "                if 'DSR' in available_bands:\n",
        "                    test_band = 'DSR'\n",
        "                elif 'Direct' in available_bands:\n",
        "                    test_band = 'Direct'\n",
        "                elif 'Diffuse' in available_bands:\n",
        "                    test_band = 'Diffuse'\n",
        "\n",
        "                if test_band:\n",
        "                    has_data, valid_count = test_point_data_extraction(\n",
        "                        radiation_collection, point, test_band)\n",
        "                    availability['radiation']['extractable'] = has_data\n",
        "                    availability['radiation']['extractable_images'] = valid_count\n",
        "\n",
        "                    print(f\"📊 Disponibilidad de datos de radiación solar: {radiation_count} imágenes en la colección, {valid_count} extraíbles para el punto\")\n",
        "                else:\n",
        "                    print(f\"📊 Disponibilidad de datos de radiación solar: {radiation_count} imágenes, pero no se encontraron bandas esperadas\")\n",
        "            else:\n",
        "                print(f\"📊 Disponibilidad de datos de radiación solar: {radiation_count} imágenes, pero no se pudo acceder a la primera imagen\")\n",
        "        else:\n",
        "            print(f\"📊 Disponibilidad de datos de radiación solar: {radiation_count} imágenes\")\n",
        "\n",
        "        # Verificar temperatura\n",
        "        temperature_collection = ee.ImageCollection('MODIS/061/MOD11A1') \\\n",
        "            .filterDate(start_date, end_date) \\\n",
        "            .filterBounds(point)\n",
        "        temperature_count = temperature_collection.size().getInfo()\n",
        "        availability['temperature']['available'] = temperature_count > 0\n",
        "        availability['temperature']['images'] = temperature_count\n",
        "\n",
        "        if temperature_count > 0:\n",
        "            # Verificar si se pueden extraer datos de temperatura\n",
        "            has_data, valid_count = test_point_data_extraction(\n",
        "                temperature_collection, point, 'LST_Day_1km')\n",
        "            availability['temperature']['extractable'] = has_data\n",
        "            availability['temperature']['extractable_images'] = valid_count\n",
        "\n",
        "            print(f\"📊 Disponibilidad de datos de temperatura: {temperature_count} imágenes en la colección, {valid_count} extraíbles para el punto\")\n",
        "        else:\n",
        "            print(f\"📊 Disponibilidad de datos de temperatura: {temperature_count} imágenes\")\n",
        "\n",
        "        # Verificar viento\n",
        "        wind_collection = ee.ImageCollection('ECMWF/ERA5_LAND/HOURLY') \\\n",
        "            .filterDate(start_date, end_date) \\\n",
        "            .filterBounds(point) \\\n",
        "            .limit(24)  # Solo verificar un día (24 horas)\n",
        "        wind_count = wind_collection.size().getInfo()\n",
        "        availability['wind']['available'] = wind_count > 0\n",
        "        availability['wind']['images'] = wind_count\n",
        "\n",
        "        if wind_count > 0:\n",
        "            # Verificar si se pueden extraer datos de viento\n",
        "            has_data, valid_count = test_point_data_extraction(\n",
        "                wind_collection, point, 'u_component_of_wind_10m')\n",
        "            availability['wind']['extractable'] = has_data\n",
        "            availability['wind']['extractable_images'] = valid_count\n",
        "\n",
        "            print(f\"📊 Disponibilidad de datos de viento: {wind_count} imágenes en la colección, {valid_count} extraíbles para el punto\")\n",
        "        else:\n",
        "            print(f\"📊 Disponibilidad de datos de viento: {wind_count} imágenes\")\n",
        "\n",
        "        # Verificar elevación (siempre disponible globalmente)\n",
        "        elevation = ee.Image('USGS/SRTMGL1_003').select('elevation')\n",
        "        elevation_value = elevation.reduceRegion(\n",
        "            reducer=ee.Reducer.first(),\n",
        "            geometry=point,\n",
        "            scale=30\n",
        "        ).getInfo()\n",
        "        availability['elevation']['available'] = 'elevation' in elevation_value and elevation_value['elevation'] is not None\n",
        "        availability['elevation']['extractable'] = availability['elevation']['available']\n",
        "\n",
        "        print(f\"📊 Disponibilidad de datos de elevación: {'Sí' if availability['elevation']['available'] else 'No'}\")\n",
        "\n",
        "        # Verificar cobertura terrestre\n",
        "        year = int(start_date.split('-')[0])\n",
        "        landcover_collection = ee.ImageCollection('MODIS/006/MCD12Q1') \\\n",
        "            .filterDate(f\"{year}-01-01\", f\"{year}-12-31\") \\\n",
        "            .filterBounds(point)\n",
        "        landcover_count = landcover_collection.size().getInfo()\n",
        "        availability['landcover']['available'] = landcover_count > 0\n",
        "        availability['landcover']['images'] = landcover_count\n",
        "\n",
        "        if landcover_count > 0:\n",
        "            # Verificar si se pueden extraer datos de cobertura terrestre\n",
        "            has_data, valid_count = test_point_data_extraction(\n",
        "                landcover_collection, point, 'LC_Type1')\n",
        "            availability['landcover']['extractable'] = has_data\n",
        "            availability['landcover']['extractable_images'] = valid_count\n",
        "\n",
        "            print(f\"📊 Disponibilidad de datos de cobertura terrestre: {landcover_count} imágenes en la colección, {valid_count} extraíbles para el punto\")\n",
        "        else:\n",
        "            print(f\"📊 Disponibilidad de datos de cobertura terrestre: {landcover_count} imágenes\")\n",
        "\n",
        "        # Resumen general\n",
        "        available_count = sum(1 for v in availability.values() if v['available'])\n",
        "        extractable_count = sum(1 for v in availability.values() if v['extractable'])\n",
        "\n",
        "        print(f\"\\n📋 Resumen de disponibilidad:\")\n",
        "        print(f\"  - {available_count}/6 tipos de datos disponibles en las colecciones\")\n",
        "        print(f\"  - {extractable_count}/6 tipos de datos extraíbles para el punto específico\")\n",
        "\n",
        "        if extractable_count == 0:\n",
        "            print(\"\\n⚠️ ADVERTENCIA: No hay datos extraíbles para esta ubicación y período.\")\n",
        "            print(\"⚠️ Sugerencias:\")\n",
        "            print(\"  - Prueba con un período más reciente (2021-2022)\")\n",
        "            print(\"  - Verifica las coordenadas (algunas regiones tienen menos cobertura)\")\n",
        "            print(\"  - Intenta con una ubicación diferente\")\n",
        "        elif extractable_count < 3:\n",
        "            print(\"\\n⚠️ ADVERTENCIA: Pocos tipos de datos extraíbles para esta ubicación y período.\")\n",
        "            print(\"⚠️ El CSV resultante tendrá información limitada.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error al verificar disponibilidad de datos: {e}\")\n",
        "\n",
        "    return availability\n",
        "\n",
        "def check_available_bands(image_collection, expected_bands):\n",
        "    \"\"\"\n",
        "    Verifica si las bandas esperadas están disponibles en la colección de imágenes.\n",
        "\n",
        "    Args:\n",
        "        image_collection (ee.ImageCollection): Colección de imágenes\n",
        "        expected_bands (list): Lista de nombres de bandas esperadas\n",
        "\n",
        "    Returns:\n",
        "        tuple: (bool, list) - (True si todas las bandas están disponibles, lista de bandas disponibles)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Obtener la primera imagen de la colección\n",
        "        first_image = image_collection.first()\n",
        "        if first_image is None:\n",
        "            print(\"⚠️ Advertencia: Colección de imágenes vacía\")\n",
        "            return False, []\n",
        "\n",
        "        # Obtener las bandas disponibles\n",
        "        available_bands = first_image.bandNames().getInfo()\n",
        "        if not available_bands:\n",
        "            print(\"⚠️ Advertencia: No se pudieron obtener los nombres de las bandas\")\n",
        "            return False, []\n",
        "\n",
        "        # Verificar si todas las bandas esperadas están disponibles\n",
        "        all_available = all(band in available_bands for band in expected_bands)\n",
        "\n",
        "        if not all_available:\n",
        "            missing_bands = [band for band in expected_bands if band not in available_bands]\n",
        "            print(f\"⚠️ Advertencia: Algunas bandas esperadas no están disponibles: {missing_bands}\")\n",
        "            print(f\"⚠️ Bandas disponibles: {available_bands}\")\n",
        "\n",
        "        return all_available, available_bands\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error al verificar bandas disponibles: {e}\")\n",
        "        return False, []\n",
        "\n",
        "def get_albedo_data(point, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Extrae datos de albedo (black-sky y white-sky) para un punto y período específicos.\n",
        "\n",
        "    Args:\n",
        "        point (ee.Geometry.Point): Punto de interés\n",
        "        start_date (str): Fecha de inicio en formato YYYY-MM-DD\n",
        "        end_date (str): Fecha de fin en formato YYYY-MM-DD\n",
        "\n",
        "    Returns:\n",
        "        ee.ImageCollection: Colección de imágenes con datos de albedo\n",
        "    \"\"\"\n",
        "    albedo_collection = ee.ImageCollection('MODIS/061/MCD43A3') \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .filterBounds(point)\n",
        "\n",
        "    # Verificar bandas disponibles\n",
        "    expected_bands = ['Albedo_BSA_vis', 'Albedo_WSA_vis', 'Albedo_BSA_nir', 'Albedo_WSA_nir', 'Albedo_BSA_shortwave', 'Albedo_WSA_shortwave']\n",
        "    bands_available, available_bands = check_available_bands(albedo_collection, expected_bands)\n",
        "\n",
        "    if bands_available:\n",
        "        albedo_collection = albedo_collection.select(expected_bands)\n",
        "    else:\n",
        "        print(\"⚠️ No se pudieron seleccionar todas las bandas de albedo esperadas\")\n",
        "        # Seleccionar solo las bandas disponibles que coinciden con el patrón esperado\n",
        "        available_albedo_bands = [band for band in available_bands if 'Albedo' in band]\n",
        "        if available_albedo_bands:\n",
        "            print(f\"🔄 Seleccionando bandas de albedo disponibles: {available_albedo_bands}\")\n",
        "            albedo_collection = albedo_collection.select(available_albedo_bands)\n",
        "\n",
        "    return albedo_collection\n",
        "\n",
        "def get_solar_radiation_data(point, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Extrae datos de radiación solar para un punto y período específicos.\n",
        "\n",
        "    Args:\n",
        "        point (ee.Geometry.Point): Punto de interés\n",
        "        start_date (str): Fecha de inicio en formato YYYY-MM-DD\n",
        "        end_date (str): Fecha de fin en formato YYYY-MM-DD\n",
        "\n",
        "    Returns:\n",
        "        ee.ImageCollection: Colección de imágenes con datos de radiación solar\n",
        "    \"\"\"\n",
        "    radiation_collection = ee.ImageCollection('MODIS/061/MCD18A1') \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .filterBounds(point)\n",
        "\n",
        "    # Verificar bandas disponibles\n",
        "    # Nombres de bandas actualizados según el error reportado\n",
        "    expected_bands = ['DSR', 'Direct', 'Diffuse']\n",
        "    bands_available, available_bands = check_available_bands(radiation_collection, expected_bands)\n",
        "\n",
        "    if bands_available:\n",
        "        radiation_collection = radiation_collection.select(expected_bands)\n",
        "    else:\n",
        "        print(\"⚠️ No se pudieron seleccionar todas las bandas de radiación solar esperadas\")\n",
        "        # Intentar seleccionar bandas disponibles relacionadas con radiación solar\n",
        "        radiation_bands = [band for band in available_bands if 'DSR' in band or 'Direct' in band or 'Diffuse' in band]\n",
        "        if radiation_bands:\n",
        "            print(f\"🔄 Seleccionando bandas de radiación solar disponibles: {radiation_bands}\")\n",
        "            radiation_collection = radiation_collection.select(radiation_bands)\n",
        "\n",
        "    return radiation_collection\n",
        "\n",
        "def get_temperature_data(point, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Extrae datos de temperatura superficial para un punto y período específicos.\n",
        "\n",
        "    Args:\n",
        "        point (ee.Geometry.Point): Punto de interés\n",
        "        start_date (str): Fecha de inicio en formato YYYY-MM-DD\n",
        "        end_date (str): Fecha de fin en formato YYYY-MM-DD\n",
        "\n",
        "    Returns:\n",
        "        ee.ImageCollection: Colección de imágenes con datos de temperatura\n",
        "    \"\"\"\n",
        "    temperature_collection = ee.ImageCollection('MODIS/061/MOD11A1') \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .filterBounds(point)\n",
        "\n",
        "    # Verificar bandas disponibles\n",
        "    expected_bands = ['LST_Day_1km', 'LST_Night_1km', 'QC_Day', 'QC_Night']\n",
        "    bands_available, available_bands = check_available_bands(temperature_collection, expected_bands)\n",
        "\n",
        "    if bands_available:\n",
        "        temperature_collection = temperature_collection.select(expected_bands)\n",
        "    else:\n",
        "        print(\"⚠️ No se pudieron seleccionar todas las bandas de temperatura esperadas\")\n",
        "        # Intentar seleccionar bandas disponibles relacionadas con temperatura\n",
        "        temp_bands = [band for band in available_bands if 'LST' in band]\n",
        "        if temp_bands:\n",
        "            print(f\"🔄 Seleccionando bandas de temperatura disponibles: {temp_bands}\")\n",
        "            temperature_collection = temperature_collection.select(temp_bands)\n",
        "\n",
        "    return temperature_collection\n",
        "\n",
        "def get_wind_data_chunk(point, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Extrae datos de viento para un punto y período específicos (un chunk).\n",
        "\n",
        "    Args:\n",
        "        point (ee.Geometry.Point): Punto de interés\n",
        "        start_date (str): Fecha de inicio en formato YYYY-MM-DD\n",
        "        end_date (str): Fecha de fin en formato YYYY-MM-DD\n",
        "\n",
        "    Returns:\n",
        "        ee.ImageCollection: Colección de imágenes con datos de viento\n",
        "    \"\"\"\n",
        "    # Obtener datos de viento horarios\n",
        "    wind_collection = ee.ImageCollection('ECMWF/ERA5_LAND/HOURLY') \\\n",
        "        .filterDate(start_date, end_date) \\\n",
        "        .filterBounds(point)\n",
        "\n",
        "    # Verificar bandas disponibles\n",
        "    expected_bands = ['u_component_of_wind_10m', 'v_component_of_wind_10m']\n",
        "    bands_available, available_bands = check_available_bands(wind_collection, expected_bands)\n",
        "\n",
        "    if bands_available:\n",
        "        wind_collection = wind_collection.select(expected_bands)\n",
        "    else:\n",
        "        print(\"⚠️ No se pudieron seleccionar todas las bandas de viento esperadas\")\n",
        "        # Intentar seleccionar bandas disponibles relacionadas con viento\n",
        "        wind_bands = [band for band in available_bands if 'wind' in band.lower()]\n",
        "        if wind_bands:\n",
        "            print(f\"🔄 Seleccionando bandas de viento disponibles: {wind_bands}\")\n",
        "            wind_collection = wind_collection.select(wind_bands)\n",
        "\n",
        "    # Método alternativo para agrupar por día sin usar startOfDay()\n",
        "    # Usamos format() para truncar la hora y obtener solo la fecha\n",
        "    def add_date_band(image):\n",
        "        # Obtener la fecha como string en formato YYYY-MM-DD\n",
        "        date_string = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd')\n",
        "        # Añadir como propiedad\n",
        "        return image.set('date_string', date_string)\n",
        "\n",
        "    # Añadir la propiedad de fecha a cada imagen\n",
        "    wind_collection_with_date = wind_collection.map(add_date_band)\n",
        "\n",
        "    # Obtener lista de fechas únicas como strings\n",
        "    unique_dates = wind_collection_with_date.aggregate_array('date_string').distinct()\n",
        "\n",
        "    # Función para calcular la media diaria\n",
        "    def calculate_daily_mean(date_string):\n",
        "        # Filtrar imágenes para esta fecha\n",
        "        daily_images = wind_collection_with_date.filter(ee.Filter.eq('date_string', date_string))\n",
        "        # Calcular la media\n",
        "        mean_image = daily_images.mean()\n",
        "        # Convertir la fecha string a timestamp\n",
        "        timestamp = ee.Date(date_string).millis()\n",
        "        # Añadir timestamp y fecha string como propiedades\n",
        "        return mean_image.set('system:time_start', timestamp).set('date_string', date_string)\n",
        "\n",
        "    # Calcular medias diarias\n",
        "    daily_wind = ee.ImageCollection.fromImages(unique_dates.map(calculate_daily_mean))\n",
        "\n",
        "    return daily_wind\n",
        "\n",
        "def get_elevation_data(point):\n",
        "    \"\"\"\n",
        "    Extrae datos de elevación y variables topográficas derivadas para un punto específico.\n",
        "\n",
        "    Args:\n",
        "        point (ee.Geometry.Point): Punto de interés\n",
        "\n",
        "    Returns:\n",
        "        ee.Image: Imagen con datos de elevación y variables derivadas\n",
        "    \"\"\"\n",
        "    # Obtener datos de elevación SRTM\n",
        "    elevation = ee.Image('USGS/SRTMGL1_003').select('elevation')\n",
        "\n",
        "    # Calcular pendiente y aspecto (orientación)\n",
        "    slope = ee.Terrain.slope(elevation)\n",
        "    aspect = ee.Terrain.aspect(elevation)\n",
        "\n",
        "    # Combinar en una sola imagen\n",
        "    topo = elevation.addBands(slope).addBands(aspect).rename(['elevation', 'slope', 'aspect'])\n",
        "\n",
        "    return topo\n",
        "\n",
        "def get_landcover_data(point, year):\n",
        "    \"\"\"\n",
        "    Extrae datos de cobertura terrestre para un punto y año específicos.\n",
        "\n",
        "    Args:\n",
        "        point (ee.Geometry.Point): Punto de interés\n",
        "        year (int): Año para el cual obtener la cobertura terrestre\n",
        "\n",
        "    Returns:\n",
        "        ee.Image: Imagen con datos de cobertura terrestre\n",
        "    \"\"\"\n",
        "    # Usar el producto de cobertura terrestre MODIS\n",
        "    landcover_collection = ee.ImageCollection('MODIS/006/MCD12Q1') \\\n",
        "        .filterBounds(point)\n",
        "\n",
        "    # Filtrar por el año especificado\n",
        "    year_start = f\"{year}-01-01\"\n",
        "    year_end = f\"{year}-12-31\"\n",
        "    landcover = landcover_collection.filterDate(year_start, year_end).first()\n",
        "\n",
        "    if landcover is None:\n",
        "        print(f\"⚠️ Advertencia: No hay datos de cobertura terrestre disponibles para el año {year}\")\n",
        "        # Intentar con años anteriores si no hay datos para el año especificado\n",
        "        for prev_year in range(year-1, year-5, -1):\n",
        "            print(f\"🔄 Intentando con datos de cobertura terrestre del año {prev_year}...\")\n",
        "            prev_year_start = f\"{prev_year}-01-01\"\n",
        "            prev_year_end = f\"{prev_year}-12-31\"\n",
        "            landcover = landcover_collection.filterDate(prev_year_start, prev_year_end).first()\n",
        "            if landcover is not None:\n",
        "                print(f\"✅ Se encontraron datos de cobertura terrestre para el año {prev_year}\")\n",
        "                break\n",
        "\n",
        "        if landcover is None:\n",
        "            return None\n",
        "\n",
        "    # Verificar bandas disponibles\n",
        "    expected_bands = ['LC_Type1']\n",
        "    bands_available, available_bands = check_available_bands(landcover_collection, expected_bands)\n",
        "\n",
        "    if bands_available:\n",
        "        landcover = landcover.select('LC_Type1')\n",
        "    else:\n",
        "        print(\"⚠️ No se pudieron seleccionar las bandas de cobertura terrestre esperadas\")\n",
        "        # Intentar seleccionar bandas disponibles relacionadas con cobertura terrestre\n",
        "        lc_bands = [band for band in available_bands if 'LC' in band or 'Type' in band]\n",
        "        if lc_bands:\n",
        "            print(f\"🔄 Seleccionando bandas de cobertura terrestre disponibles: {lc_bands}\")\n",
        "            landcover = landcover.select(lc_bands[0])  # Seleccionar la primera banda disponible\n",
        "\n",
        "    return landcover\n",
        "\n",
        "def extract_point_values(image_collection, point, scale=500, band_name=None):\n",
        "    \"\"\"\n",
        "    Extrae valores para un punto específico de una colección de imágenes.\n",
        "\n",
        "    Args:\n",
        "        image_collection (ee.ImageCollection): Colección de imágenes\n",
        "        point (ee.Geometry.Point): Punto de interés\n",
        "        scale (int): Escala en metros\n",
        "        band_name (str, optional): Nombre de la banda específica a extraer\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de diccionarios con fecha y valores\n",
        "    \"\"\"\n",
        "    # Verificar si la colección está vacía\n",
        "    count = image_collection.size().getInfo()\n",
        "    if count == 0:\n",
        "        print(\"⚠️ Advertencia: Colección de imágenes vacía\")\n",
        "        return []\n",
        "\n",
        "    # Si se especifica una banda, verificar que exista\n",
        "    if band_name:\n",
        "        first_image = image_collection.first()\n",
        "        if first_image is None:\n",
        "            print(\"⚠️ Advertencia: No hay imágenes en la colección\")\n",
        "            return []\n",
        "\n",
        "        available_bands = first_image.bandNames().getInfo()\n",
        "        if band_name not in available_bands:\n",
        "            print(f\"⚠️ Advertencia: La banda '{band_name}' no está disponible. Bandas disponibles: {available_bands}\")\n",
        "            return []\n",
        "\n",
        "    def extract_from_image(image):\n",
        "        try:\n",
        "            # Si se especifica una banda, seleccionarla\n",
        "            if band_name:\n",
        "                image = image.select(band_name)\n",
        "\n",
        "            # Extraer valor en el punto\n",
        "            value = image.reduceRegion(\n",
        "                reducer=ee.Reducer.first(),\n",
        "                geometry=point,\n",
        "                scale=scale\n",
        "            )\n",
        "\n",
        "            # Crear feature con fecha y valor\n",
        "            return ee.Feature(None, {\n",
        "                'date': ee.Date(image.get('system:time_start')).format('YYYY-MM-dd'),\n",
        "                'values': value\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error al extraer valores de la imagen: {e}\")\n",
        "            return ee.Feature(None, {\n",
        "                'date': ee.Date(image.get('system:time_start')).format('YYYY-MM-dd'),\n",
        "                'values': {}\n",
        "            })\n",
        "\n",
        "    try:\n",
        "        # Aplicar la función a cada imagen en la colección\n",
        "        features = image_collection.map(extract_from_image)\n",
        "\n",
        "        # Convertir a lista para descargar\n",
        "        result = features.aggregate_array('properties').getInfo()\n",
        "\n",
        "        # Filtrar resultados para eliminar valores vacíos\n",
        "        filtered_result = []\n",
        "        for item in result:\n",
        "            if item['values'] and len(item['values']) > 0 and any(v is not None for v in item['values'].values()):\n",
        "                filtered_result.append(item)\n",
        "\n",
        "        if len(filtered_result) == 0:\n",
        "            print(f\"⚠️ No se encontraron valores válidos para el punto en ninguna de las {count} imágenes\")\n",
        "        else:\n",
        "            print(f\"✅ Se encontraron valores válidos en {len(filtered_result)} de {count} imágenes\")\n",
        "\n",
        "        return filtered_result\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error al extraer valores de la colección: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_static_values(image, point, scale=500):\n",
        "    \"\"\"\n",
        "    Extrae valores para un punto específico de una imagen estática.\n",
        "\n",
        "    Args:\n",
        "        image (ee.Image): Imagen\n",
        "        point (ee.Geometry.Point): Punto de interés\n",
        "        scale (int): Escala en metros\n",
        "\n",
        "    Returns:\n",
        "        dict: Diccionario con valores\n",
        "    \"\"\"\n",
        "    if image is None:\n",
        "        print(\"⚠️ Advertencia: Imagen nula\")\n",
        "        return {}\n",
        "\n",
        "    try:\n",
        "        values = image.reduceRegion(\n",
        "            reducer=ee.Reducer.first(),\n",
        "            geometry=point,\n",
        "            scale=scale\n",
        "        ).getInfo()\n",
        "\n",
        "        # Verificar si se obtuvieron valores válidos\n",
        "        if not values or all(v is None for v in values.values()):\n",
        "            print(\"⚠️ No se encontraron valores válidos para el punto en la imagen estática\")\n",
        "            return {}\n",
        "\n",
        "        return values\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error al extraer valores estáticos: {e}\")\n",
        "        return {}\n",
        "\n",
        "def safe_merge(df_list):\n",
        "    \"\"\"\n",
        "    Combina de forma segura una lista de DataFrames, verificando que tengan la columna 'date'.\n",
        "\n",
        "    Args:\n",
        "        df_list (list): Lista de DataFrames a combinar\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame combinado o DataFrame vacío con columna 'date'\n",
        "    \"\"\"\n",
        "    # Filtrar DataFrames vacíos o sin columna 'date'\n",
        "    valid_dfs = [df for df in df_list if not df.empty and 'date' in df.columns]\n",
        "\n",
        "    if not valid_dfs:\n",
        "        # Retornar DataFrame vacío con columna 'date'\n",
        "        return pd.DataFrame({'date': []})\n",
        "\n",
        "    # Comenzar con el primer DataFrame válido\n",
        "    result = valid_dfs[0].copy()\n",
        "\n",
        "    # Combinar con el resto de DataFrames válidos\n",
        "    for df in valid_dfs[1:]:\n",
        "        result = pd.merge(result, df, on='date', how='outer')\n",
        "\n",
        "    return result\n",
        "\n",
        "def process_albedo_data(albedo_collection, point, frequency, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Procesa datos de albedo y los agrega según la frecuencia especificada.\n",
        "\n",
        "    Args:\n",
        "        albedo_collection (ee.ImageCollection): Colección de imágenes de albedo\n",
        "        point (ee.Geometry.Point): Punto de interés\n",
        "        frequency (str): 'daily', 'monthly', o 'annual'\n",
        "        start_date (datetime): Fecha de inicio\n",
        "        end_date (datetime): Fecha de fin\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de diccionarios con datos de albedo agregados\n",
        "    \"\"\"\n",
        "    # Verificar bandas disponibles\n",
        "    first_image = albedo_collection.first()\n",
        "    if first_image is None:\n",
        "        print(\"⚠️ Advertencia: No hay imágenes de albedo disponibles\")\n",
        "        return []\n",
        "\n",
        "    available_bands = first_image.bandNames().getInfo()\n",
        "\n",
        "    # Extraer valores para cada banda disponible\n",
        "    valid_dfs = []\n",
        "\n",
        "    # Bandas BSA (Black-Sky Albedo)\n",
        "    bsa_bands = [band for band in available_bands if 'BSA' in band]\n",
        "    for band in bsa_bands:\n",
        "        try:\n",
        "            data = extract_point_values(albedo_collection.select(band), point)\n",
        "            if data:\n",
        "                df_name = band.lower().replace('albedo_', '')\n",
        "                df = pd.DataFrame([{'date': item['date'], df_name: item['values'].get(band, None)} for item in data])\n",
        "                if not df.empty and 'date' in df.columns:\n",
        "                    # Convertir valores a escala correcta (dividir por 1000)\n",
        "                    df[df_name] = df[df_name].apply(lambda x: x / 1000.0 if x is not None else None)\n",
        "                    valid_dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error al procesar datos de {band}: {e}\")\n",
        "\n",
        "    # Bandas WSA (White-Sky Albedo)\n",
        "    wsa_bands = [band for band in available_bands if 'WSA' in band]\n",
        "    for band in wsa_bands:\n",
        "        try:\n",
        "            data = extract_point_values(albedo_collection.select(band), point)\n",
        "            if data:\n",
        "                df_name = band.lower().replace('albedo_', '')\n",
        "                df = pd.DataFrame([{'date': item['date'], df_name: item['values'].get(band, None)} for item in data])\n",
        "                if not df.empty and 'date' in df.columns:\n",
        "                    # Convertir valores a escala correcta (dividir por 1000)\n",
        "                    df[df_name] = df[df_name].apply(lambda x: x / 1000.0 if x is not None else None)\n",
        "                    valid_dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error al procesar datos de {band}: {e}\")\n",
        "\n",
        "    # Verificar si hay datos disponibles\n",
        "    if not valid_dfs:\n",
        "        print(\"⚠️ Advertencia: No hay datos de albedo disponibles para el período seleccionado\")\n",
        "        return []\n",
        "\n",
        "    # Combinar DataFrames de forma segura\n",
        "    albedo_df = safe_merge(valid_dfs)\n",
        "\n",
        "    # Si el DataFrame resultante está vacío o no tiene columna 'date', retornar lista vacía\n",
        "    if albedo_df.empty or 'date' not in albedo_df.columns:\n",
        "        print(\"⚠️ El DataFrame combinado de albedo está vacío o no tiene columna 'date'\")\n",
        "        return []\n",
        "\n",
        "    # Convertir fechas a datetime\n",
        "    albedo_df['date'] = pd.to_datetime(albedo_df['date'])\n",
        "\n",
        "    # Agregar según frecuencia\n",
        "    if frequency == 'daily':\n",
        "        return albedo_df.to_dict('records')\n",
        "    elif frequency == 'monthly':\n",
        "        albedo_df.set_index('date', inplace=True)\n",
        "        monthly_df = albedo_df.resample('M').mean()\n",
        "        monthly_df.index = monthly_df.index.strftime('%Y-%m-%d')\n",
        "        return monthly_df.reset_index().to_dict('records')\n",
        "    elif frequency == 'annual':\n",
        "        albedo_df.set_index('date', inplace=True)\n",
        "        annual_df = albedo_df.resample('Y').mean()\n",
        "        annual_df.index = annual_df.index.strftime('%Y-%m-%d')\n",
        "        return annual_df.reset_index().to_dict('records')\n",
        "\n",
        "def process_radiation_data(radiation_collection, point, frequency, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Procesa datos de radiación solar y los agrega según la frecuencia especificada.\n",
        "\n",
        "    Args:\n",
        "        radiation_collection (ee.ImageCollection): Colección de imágenes de radiación\n",
        "        point (ee.Geometry.Point): Punto de interés\n",
        "        frequency (str): 'daily', 'monthly', o 'annual'\n",
        "        start_date (datetime): Fecha de inicio\n",
        "        end_date (datetime): Fecha de fin\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de diccionarios con datos de radiación agregados\n",
        "    \"\"\"\n",
        "    # Verificar bandas disponibles\n",
        "    first_image = radiation_collection.first()\n",
        "    if first_image is None:\n",
        "        print(\"⚠️ Advertencia: No hay imágenes de radiación solar disponibles\")\n",
        "        return []\n",
        "\n",
        "    available_bands = first_image.bandNames().getInfo()\n",
        "\n",
        "    # Extraer valores para cada banda disponible\n",
        "    valid_dfs = []\n",
        "\n",
        "    for band in available_bands:\n",
        "        try:\n",
        "            data = extract_point_values(radiation_collection.select(band), point)\n",
        "            if data:\n",
        "                df_name = f\"radiation_{band.lower()}\"\n",
        "                df = pd.DataFrame([{'date': item['date'], df_name: item['values'].get(band, None)} for item in data])\n",
        "                if not df.empty and 'date' in df.columns:\n",
        "                    valid_dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error al procesar datos de radiación {band}: {e}\")\n",
        "\n",
        "    # Verificar si hay datos disponibles\n",
        "    if not valid_dfs:\n",
        "        print(\"⚠️ Advertencia: No hay datos de radiación solar disponibles para el período seleccionado\")\n",
        "        return []\n",
        "\n",
        "    # Combinar DataFrames de forma segura\n",
        "    radiation_df = safe_merge(valid_dfs)\n",
        "\n",
        "    # Si el DataFrame resultante está vacío o no tiene columna 'date', retornar lista vacía\n",
        "    if radiation_df.empty or 'date' not in radiation_df.columns:\n",
        "        print(\"⚠️ El DataFrame combinado de radiación está vacío o no tiene columna 'date'\")\n",
        "        return []\n",
        "\n",
        "    # Convertir fechas a datetime\n",
        "    radiation_df['date'] = pd.to_datetime(radiation_df['date'])\n",
        "\n",
        "    # Agregar según frecuencia\n",
        "    if frequency == 'daily':\n",
        "        return radiation_df.to_dict('records')\n",
        "    elif frequency == 'monthly':\n",
        "        radiation_df.set_index('date', inplace=True)\n",
        "        monthly_df = radiation_df.resample('M').mean()\n",
        "        monthly_df.index = monthly_df.index.strftime('%Y-%m-%d')\n",
        "        return monthly_df.reset_index().to_dict('records')\n",
        "    elif frequency == 'annual':\n",
        "        radiation_df.set_index('date', inplace=True)\n",
        "        annual_df = radiation_df.resample('Y').mean()\n",
        "        annual_df.index = annual_df.index.strftime('%Y-%m-%d')\n",
        "        return annual_df.reset_index().to_dict('records')\n",
        "\n",
        "def process_temperature_data(temperature_collection, point, frequency, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Procesa datos de temperatura y los agrega según la frecuencia especificada.\n",
        "\n",
        "    Args:\n",
        "        temperature_collection (ee.ImageCollection): Colección de imágenes de temperatura\n",
        "        point (ee.Geometry.Point): Punto de interés\n",
        "        frequency (str): 'daily', 'monthly', o 'annual'\n",
        "        start_date (datetime): Fecha de inicio\n",
        "        end_date (datetime): Fecha de fin\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de diccionarios con datos de temperatura agregados\n",
        "    \"\"\"\n",
        "    # Verificar bandas disponibles\n",
        "    first_image = temperature_collection.first()\n",
        "    if first_image is None:\n",
        "        print(\"⚠️ Advertencia: No hay imágenes de temperatura disponibles\")\n",
        "        return []\n",
        "\n",
        "    available_bands = first_image.bandNames().getInfo()\n",
        "\n",
        "    # Extraer valores para bandas de temperatura\n",
        "    valid_dfs = []\n",
        "    temp_bands = [band for band in available_bands if 'LST' in band]\n",
        "\n",
        "    for band in temp_bands:\n",
        "        try:\n",
        "            data = extract_point_values(temperature_collection.select(band), point)\n",
        "            if data:\n",
        "                df_name = f\"temp_{band.lower().replace('lst_', '')}\"\n",
        "                df = pd.DataFrame([{'date': item['date'], df_name: item['values'].get(band, None)} for item in data])\n",
        "                if not df.empty and 'date' in df.columns:\n",
        "                    # Convertir valores a escala correcta (convertir a Celsius)\n",
        "                    df[df_name] = df[df_name].apply(lambda x: (x * 0.02) - 273.15 if x is not None else None)\n",
        "                    valid_dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error al procesar datos de temperatura {band}: {e}\")\n",
        "\n",
        "    # Verificar si hay datos disponibles\n",
        "    if not valid_dfs:\n",
        "        print(\"⚠️ Advertencia: No hay datos de temperatura disponibles para el período seleccionado\")\n",
        "        return []\n",
        "\n",
        "    # Combinar DataFrames de forma segura\n",
        "    temp_df = safe_merge(valid_dfs)\n",
        "\n",
        "    # Si el DataFrame resultante está vacío o no tiene columna 'date', retornar lista vacía\n",
        "    if temp_df.empty or 'date' not in temp_df.columns:\n",
        "        print(\"⚠️ El DataFrame combinado de temperatura está vacío o no tiene columna 'date'\")\n",
        "        return []\n",
        "\n",
        "    # Añadir temperatura media si hay datos de día y noche\n",
        "    day_col = next((col for col in temp_df.columns if 'day' in col.lower()), None)\n",
        "    night_col = next((col for col in temp_df.columns if 'night' in col.lower()), None)\n",
        "\n",
        "    if day_col and night_col:\n",
        "        temp_df['temp_mean'] = temp_df[[day_col, night_col]].mean(axis=1)\n",
        "    elif day_col:\n",
        "        temp_df['temp_mean'] = temp_df[day_col]\n",
        "    elif night_col:\n",
        "        temp_df['temp_mean'] = temp_df[night_col]\n",
        "\n",
        "    # Convertir fechas a datetime\n",
        "    temp_df['date'] = pd.to_datetime(temp_df['date'])\n",
        "\n",
        "    # Agregar según frecuencia\n",
        "    if frequency == 'daily':\n",
        "        return temp_df.to_dict('records')\n",
        "    elif frequency == 'monthly':\n",
        "        temp_df.set_index('date', inplace=True)\n",
        "        monthly_df = temp_df.resample('M').mean()\n",
        "        monthly_df.index = monthly_df.index.strftime('%Y-%m-%d')\n",
        "        return monthly_df.reset_index().to_dict('records')\n",
        "    elif frequency == 'annual':\n",
        "        temp_df.set_index('date', inplace=True)\n",
        "        annual_df = temp_df.resample('Y').mean()\n",
        "        annual_df.index = annual_df.index.strftime('%Y-%m-%d')\n",
        "        return annual_df.reset_index().to_dict('records')\n",
        "\n",
        "def process_wind_data_chunked(point, start_date, end_date, frequency, max_chunk_days=30):\n",
        "    \"\"\"\n",
        "    Procesa datos de viento en chunks para evitar problemas de memoria.\n",
        "\n",
        "    Args:\n",
        "        point (ee.Geometry.Point): Punto de interés\n",
        "        start_date (datetime): Fecha de inicio\n",
        "        end_date (datetime): Fecha de fin\n",
        "        frequency (str): 'daily', 'monthly', o 'annual'\n",
        "        max_chunk_days (int): Número máximo de días por chunk\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de diccionarios con datos de viento agregados\n",
        "    \"\"\"\n",
        "    # Generar rangos de fechas en chunks\n",
        "    date_ranges = get_date_ranges(start_date, end_date, 'daily', max_chunk_days)\n",
        "\n",
        "    # Procesar cada chunk\n",
        "    all_wind_data = []\n",
        "\n",
        "    for i, (chunk_start, chunk_end) in enumerate(date_ranges):\n",
        "        print(f\"🔄 Procesando chunk de viento {i+1}/{len(date_ranges)}: {chunk_start} a {chunk_end}\")\n",
        "\n",
        "        try:\n",
        "            # Obtener datos para este chunk\n",
        "            wind_collection = get_wind_data_chunk(point, chunk_start, chunk_end)\n",
        "\n",
        "            # Verificar bandas disponibles\n",
        "            first_image = wind_collection.first()\n",
        "            if first_image is None:\n",
        "                print(f\"⚠️ No hay imágenes de viento disponibles para el chunk {chunk_start} a {chunk_end}\")\n",
        "                continue\n",
        "\n",
        "            available_bands = first_image.bandNames().getInfo()\n",
        "\n",
        "            # Extraer valores para cada componente\n",
        "            valid_dfs = []\n",
        "\n",
        "            # Buscar componentes U y V del viento\n",
        "            u_band = next((band for band in available_bands if 'u_component' in band.lower()), None)\n",
        "            v_band = next((band for band in available_bands if 'v_component' in band.lower()), None)\n",
        "\n",
        "            if u_band:\n",
        "                try:\n",
        "                    u_data = extract_point_values(wind_collection.select(u_band), point)\n",
        "                    if u_data:\n",
        "                        u_df = pd.DataFrame([{'date': item['date'], 'wind_u': item['values'].get(u_band, None)} for item in u_data])\n",
        "                        if not u_df.empty and 'date' in u_df.columns:\n",
        "                            valid_dfs.append(u_df)\n",
        "                except Exception as e:\n",
        "                    print(f\"⚠️ Error al procesar datos de componente U del viento: {e}\")\n",
        "\n",
        "            if v_band:\n",
        "                try:\n",
        "                    v_data = extract_point_values(wind_collection.select(v_band), point)\n",
        "                    if v_data:\n",
        "                        v_df = pd.DataFrame([{'date': item['date'], 'wind_v': item['values'].get(v_band, None)} for item in v_data])\n",
        "                        if not v_df.empty and 'date' in v_df.columns:\n",
        "                            valid_dfs.append(v_df)\n",
        "                except Exception as e:\n",
        "                    print(f\"⚠️ Error al procesar datos de componente V del viento: {e}\")\n",
        "\n",
        "            # Verificar si hay datos disponibles\n",
        "            if not valid_dfs:\n",
        "                print(f\"⚠️ No hay datos de viento disponibles para el chunk {chunk_start} a {chunk_end}\")\n",
        "                continue\n",
        "\n",
        "            # Combinar DataFrames de forma segura\n",
        "            wind_df = safe_merge(valid_dfs)\n",
        "\n",
        "            # Si el DataFrame resultante está vacío o no tiene columna 'date', continuar con el siguiente chunk\n",
        "            if wind_df.empty or 'date' not in wind_df.columns:\n",
        "                print(f\"⚠️ El DataFrame combinado de viento está vacío para el chunk {chunk_start} a {chunk_end}\")\n",
        "                continue\n",
        "\n",
        "            # Calcular velocidad y dirección del viento si hay ambos componentes\n",
        "            if 'wind_u' in wind_df.columns and 'wind_v' in wind_df.columns:\n",
        "                wind_df['wind_speed'] = wind_df.apply(lambda row: np.sqrt(row['wind_u']**2 + row['wind_v']**2) if pd.notnull(row['wind_u']) and pd.notnull(row['wind_v']) else None, axis=1)\n",
        "                wind_df['wind_direction'] = wind_df.apply(lambda row: (270 - np.degrees(np.arctan2(row['wind_v'], row['wind_u']))) % 360 if pd.notnull(row['wind_u']) and pd.notnull(row['wind_v']) else None, axis=1)\n",
        "\n",
        "            # Convertir fechas a datetime\n",
        "            wind_df['date'] = pd.to_datetime(wind_df['date'])\n",
        "\n",
        "            # Agregar a la lista de todos los datos\n",
        "            all_wind_data.append(wind_df)\n",
        "\n",
        "            # Pausa para evitar sobrecargar la API\n",
        "            time.sleep(1)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error al procesar chunk de viento {chunk_start} a {chunk_end}: {e}\")\n",
        "            # Continuar con el siguiente chunk\n",
        "            continue\n",
        "\n",
        "    # Verificar si hay datos disponibles\n",
        "    if not all_wind_data:\n",
        "        print(\"⚠️ Advertencia: No hay datos de viento disponibles para el período seleccionado\")\n",
        "        return []\n",
        "\n",
        "    # Combinar todos los chunks\n",
        "    combined_wind_df = pd.concat(all_wind_data, ignore_index=True)\n",
        "\n",
        "    # Eliminar duplicados si los hay\n",
        "    combined_wind_df.drop_duplicates(subset=['date'], keep='first', inplace=True)\n",
        "\n",
        "    # Agregar según frecuencia\n",
        "    if frequency == 'daily':\n",
        "        return combined_wind_df.to_dict('records')\n",
        "    elif frequency == 'monthly':\n",
        "        combined_wind_df.set_index('date', inplace=True)\n",
        "        monthly_df = combined_wind_df.resample('M').mean()\n",
        "        monthly_df.index = monthly_df.index.strftime('%Y-%m-%d')\n",
        "        return monthly_df.reset_index().to_dict('records')\n",
        "    elif frequency == 'annual':\n",
        "        combined_wind_df.set_index('date', inplace=True)\n",
        "        annual_df = combined_wind_df.resample('Y').mean()\n",
        "        annual_df.index = annual_df.index.strftime('%Y-%m-%d')\n",
        "        return annual_df.reset_index().to_dict('records')\n",
        "\n",
        "def merge_all_data(albedo_data, radiation_data, temperature_data, wind_data, topo_data, landcover_data):\n",
        "    \"\"\"\n",
        "    Combina todos los datos en un solo DataFrame.\n",
        "\n",
        "    Args:\n",
        "        albedo_data (list): Lista de diccionarios con datos de albedo\n",
        "        radiation_data (list): Lista de diccionarios con datos de radiación\n",
        "        temperature_data (list): Lista de diccionarios con datos de temperatura\n",
        "        wind_data (list): Lista de diccionarios con datos de viento\n",
        "        topo_data (dict): Diccionario con datos topográficos\n",
        "        landcover_data (dict): Diccionario con datos de cobertura terrestre\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame con todos los datos combinados\n",
        "    \"\"\"\n",
        "    # Convertir listas a DataFrames\n",
        "    dfs = []\n",
        "\n",
        "    # Solo agregar DataFrames válidos con columna 'date'\n",
        "    if albedo_data:\n",
        "        try:\n",
        "            df = pd.DataFrame(albedo_data)\n",
        "            if not df.empty and 'date' in df.columns:\n",
        "                dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error al convertir datos de albedo a DataFrame: {e}\")\n",
        "\n",
        "    if radiation_data:\n",
        "        try:\n",
        "            df = pd.DataFrame(radiation_data)\n",
        "            if not df.empty and 'date' in df.columns:\n",
        "                dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error al convertir datos de radiación a DataFrame: {e}\")\n",
        "\n",
        "    if temperature_data:\n",
        "        try:\n",
        "            df = pd.DataFrame(temperature_data)\n",
        "            if not df.empty and 'date' in df.columns:\n",
        "                dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error al convertir datos de temperatura a DataFrame: {e}\")\n",
        "\n",
        "    if wind_data:\n",
        "        try:\n",
        "            df = pd.DataFrame(wind_data)\n",
        "            if not df.empty and 'date' in df.columns:\n",
        "                dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error al convertir datos de viento a DataFrame: {e}\")\n",
        "\n",
        "    # Si no hay DataFrames válidos, retornar DataFrame vacío con columna 'date'\n",
        "    if not dfs:\n",
        "        print(\"⚠️ Advertencia: No hay datos disponibles para el período seleccionado\")\n",
        "        return pd.DataFrame({'date': []})\n",
        "\n",
        "    # Combinar DataFrames de forma segura\n",
        "    merged_df = safe_merge(dfs)\n",
        "\n",
        "    # Si el DataFrame resultante está vacío o no tiene columna 'date', retornar DataFrame vacío con columna 'date'\n",
        "    if merged_df.empty or 'date' not in merged_df.columns:\n",
        "        print(\"⚠️ El DataFrame combinado está vacío o no tiene columna 'date'\")\n",
        "        return pd.DataFrame({'date': []})\n",
        "\n",
        "    # Añadir datos topográficos (constantes para todas las fechas)\n",
        "    if topo_data:\n",
        "        for key, value in topo_data.items():\n",
        "            merged_df[key] = value\n",
        "\n",
        "    # Añadir datos de cobertura terrestre (constantes para todas las fechas)\n",
        "    if landcover_data:\n",
        "        for key, value in landcover_data.items():\n",
        "            merged_df[key] = value\n",
        "\n",
        "    return merged_df\n",
        "\n",
        "def visualize_location(lat, lon, zoom=10):\n",
        "    \"\"\"\n",
        "    Visualiza la ubicación en un mapa interactivo.\n",
        "\n",
        "    Args:\n",
        "        lat (float): Latitud\n",
        "        lon (float): Longitud\n",
        "        zoom (int): Nivel de zoom\n",
        "    \"\"\"\n",
        "    # Crear mapa centrado en la ubicación\n",
        "    m = folium.Map(location=[lat, lon], zoom_start=zoom)\n",
        "\n",
        "    # Añadir marcador\n",
        "    folium.Marker(\n",
        "        location=[lat, lon],\n",
        "        popup=f\"Lat: {lat}, Lon: {lon}\",\n",
        "        icon=folium.Icon(color=\"red\", icon=\"info-sign\")\n",
        "    ).add_to(m)\n",
        "\n",
        "    # Mostrar mapa\n",
        "    display(m)\n",
        "\n",
        "def plot_data(df, variable, title=None, ylabel=None):\n",
        "    \"\"\"\n",
        "    Genera un gráfico de línea para una variable específica.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame con los datos\n",
        "        variable (str): Nombre de la columna a graficar\n",
        "        title (str, optional): Título del gráfico\n",
        "        ylabel (str, optional): Etiqueta del eje Y\n",
        "    \"\"\"\n",
        "    if df.empty or variable not in df.columns:\n",
        "        print(f\"⚠️ No hay datos disponibles para graficar {variable}\")\n",
        "        return\n",
        "\n",
        "    # Verificar que hay datos no nulos para graficar\n",
        "    if df[variable].isna().all():\n",
        "        print(f\"⚠️ Todos los valores de {variable} son nulos, no se puede graficar\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(df['date'], df[variable], marker='o', linestyle='-')\n",
        "    plt.title(title or f\"{variable} a lo largo del tiempo\")\n",
        "    plt.xlabel(\"Fecha\")\n",
        "    plt.ylabel(ylabel or variable)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def validate_date_range(start_date, end_date, frequency):\n",
        "    \"\"\"\n",
        "    Valida el rango de fechas y la frecuencia, mostrando advertencias si es necesario.\n",
        "\n",
        "    Args:\n",
        "        start_date (datetime): Fecha de inicio\n",
        "        end_date (datetime): Fecha de fin\n",
        "        frequency (str): Frecuencia de los datos ('daily', 'monthly', o 'annual')\n",
        "\n",
        "    Returns:\n",
        "        bool: True si el rango es válido, False si es potencialmente problemático\n",
        "    \"\"\"\n",
        "    # Calcular la duración en días\n",
        "    duration_days = (end_date - start_date).days + 1\n",
        "\n",
        "    # Validar según la frecuencia\n",
        "    if frequency == 'daily':\n",
        "        if duration_days > 90:  # Más de 3 meses\n",
        "            print(f\"⚠️ ADVERTENCIA: Has seleccionado {duration_days} días con frecuencia diaria.\")\n",
        "            print(\"⚠️ Esto puede causar problemas de memoria o tiempos de procesamiento muy largos.\")\n",
        "            print(\"⚠️ Se recomienda reducir el rango de fechas o cambiar a frecuencia mensual.\")\n",
        "            return False\n",
        "    elif frequency == 'monthly':\n",
        "        if duration_days > 1095:  # Más de 3 años\n",
        "            print(f\"⚠️ ADVERTENCIA: Has seleccionado un período de más de 3 años con frecuencia mensual.\")\n",
        "            print(\"⚠️ Esto puede causar tiempos de procesamiento largos.\")\n",
        "            print(\"⚠️ Considera reducir el rango de fechas o cambiar a frecuencia anual para períodos muy largos.\")\n",
        "            return False\n",
        "\n",
        "    return True\n",
        "\n",
        "def suggest_alternative_dates(point):\n",
        "    \"\"\"\n",
        "    Sugiere fechas alternativas con buena disponibilidad de datos.\n",
        "\n",
        "    Args:\n",
        "        point (ee.Geometry.Point): Punto de interés\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de años con buena disponibilidad de datos\n",
        "    \"\"\"\n",
        "    print(\"🔍 Buscando períodos con mejor disponibilidad de datos...\")\n",
        "\n",
        "    # Lista de años a verificar (más recientes primero)\n",
        "    years_to_check = list(range(2022, 2015, -1))\n",
        "    good_years = []\n",
        "\n",
        "    for year in years_to_check:\n",
        "        year_start = f\"{year}-01-01\"\n",
        "        year_end = f\"{year}-12-31\"\n",
        "\n",
        "        # Verificar albedo\n",
        "        albedo_collection = ee.ImageCollection('MODIS/061/MCD43A3') \\\n",
        "            .filterDate(year_start, year_end) \\\n",
        "            .filterBounds(point)\n",
        "        albedo_count = albedo_collection.size().getInfo()\n",
        "\n",
        "        # Verificar si se pueden extraer datos de albedo\n",
        "        albedo_extractable = False\n",
        "        if albedo_count > 0:\n",
        "            has_data, valid_count = test_point_data_extraction(\n",
        "                albedo_collection, point, 'Albedo_BSA_vis')\n",
        "            albedo_extractable = has_data\n",
        "\n",
        "        # Verificar radiación\n",
        "        radiation_collection = ee.ImageCollection('MODIS/061/MCD18A1') \\\n",
        "            .filterDate(year_start, year_end) \\\n",
        "            .filterBounds(point)\n",
        "        radiation_count = radiation_collection.size().getInfo()\n",
        "\n",
        "        # Verificar si se pueden extraer datos de radiación\n",
        "        radiation_extractable = False\n",
        "        if radiation_count > 0:\n",
        "            first_image = radiation_collection.first()\n",
        "            if first_image:\n",
        "                available_bands = first_image.bandNames().getInfo()\n",
        "                test_band = None\n",
        "                if 'DSR' in available_bands:\n",
        "                    test_band = 'DSR'\n",
        "                elif 'Direct' in available_bands:\n",
        "                    test_band = 'Direct'\n",
        "                elif 'Diffuse' in available_bands:\n",
        "                    test_band = 'Diffuse'\n",
        "\n",
        "                if test_band:\n",
        "                    has_data, valid_count = test_point_data_extraction(\n",
        "                        radiation_collection, point, test_band)\n",
        "                    radiation_extractable = has_data\n",
        "\n",
        "        # Verificar temperatura\n",
        "        temperature_collection = ee.ImageCollection('MODIS/061/MOD11A1') \\\n",
        "            .filterDate(year_start, year_end) \\\n",
        "            .filterBounds(point)\n",
        "        temperature_count = temperature_collection.size().getInfo()\n",
        "\n",
        "        # Verificar si se pueden extraer datos de temperatura\n",
        "        temperature_extractable = False\n",
        "        if temperature_count > 0:\n",
        "            has_data, valid_count = test_point_data_extraction(\n",
        "                temperature_collection, point, 'LST_Day_1km')\n",
        "            temperature_extractable = has_data\n",
        "\n",
        "        # Evaluar disponibilidad\n",
        "        extractable_count = sum([albedo_extractable, radiation_extractable, temperature_extractable])\n",
        "        if extractable_count >= 2:  # Al menos 2 de 3 tipos de datos son extraíbles\n",
        "            good_years.append(year)\n",
        "            print(f\"✅ {year}: Buena disponibilidad de datos extraíbles\")\n",
        "            print(f\"   - Albedo: {'✓' if albedo_extractable else '✗'}\")\n",
        "            print(f\"   - Radiación: {'✓' if radiation_extractable else '✗'}\")\n",
        "            print(f\"   - Temperatura: {'✓' if temperature_extractable else '✗'}\")\n",
        "\n",
        "            # Limitar a los 3 mejores años\n",
        "            if len(good_years) >= 3:\n",
        "                break\n",
        "        else:\n",
        "            print(f\"❌ {year}: Disponibilidad limitada de datos extraíbles\")\n",
        "            print(f\"   - Albedo: {'✓' if albedo_extractable else '✗'}\")\n",
        "            print(f\"   - Radiación: {'✓' if radiation_extractable else '✗'}\")\n",
        "            print(f\"   - Temperatura: {'✓' if temperature_extractable else '✗'}\")\n",
        "\n",
        "    if good_years:\n",
        "        print(f\"\\n✨ Sugerencia: Prueba con el año {good_years[0]} para obtener mejores resultados.\")\n",
        "    else:\n",
        "        print(\"\\n⚠️ No se encontraron años con buena disponibilidad de datos extraíbles para esta ubicación.\")\n",
        "        print(\"⚠️ Considera probar con otra ubicación o utilizar fuentes de datos alternativas.\")\n",
        "\n",
        "    return good_years\n",
        "\n",
        "def extract_solar_data_colab(lat, lon, start_date, end_date, frequency='monthly', output_filename='solar_data.csv', check_availability=True):\n",
        "    \"\"\"\n",
        "    Función principal para extraer datos solares en Google Colab.\n",
        "\n",
        "    Args:\n",
        "        lat (float): Latitud del punto de interés\n",
        "        lon (float): Longitud del punto de interés\n",
        "        start_date (str): Fecha de inicio en formato YYYY-MM-DD\n",
        "        end_date (str): Fecha de fin en formato YYYY-MM-DD\n",
        "        frequency (str): Frecuencia de los datos ('daily', 'monthly', o 'annual')\n",
        "        output_filename (str): Nombre del archivo CSV de salida\n",
        "        check_availability (bool): Si es True, verifica la disponibilidad de datos antes de procesar\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame con todos los datos combinados\n",
        "    \"\"\"\n",
        "    # Inicializar Earth Engine\n",
        "    if not initialize_ee_colab():\n",
        "        return None\n",
        "\n",
        "    # Convertir fechas\n",
        "    start_date_dt = parse_date(start_date)\n",
        "    end_date_dt = parse_date(end_date)\n",
        "\n",
        "    # Validar rango de fechas y frecuencia\n",
        "    is_valid = validate_date_range(start_date_dt, end_date_dt, frequency)\n",
        "    if not is_valid:\n",
        "        print(\"⚠️ Continuando con la extracción, pero puede haber problemas de rendimiento.\")\n",
        "\n",
        "    # Crear punto\n",
        "    point = ee.Geometry.Point([lon, lat])\n",
        "\n",
        "    # Visualizar ubicación\n",
        "    print(f\"📍 Ubicación seleccionada: Latitud {lat}, Longitud {lon}\")\n",
        "    visualize_location(lat, lon)\n",
        "\n",
        "    # Verificar disponibilidad de datos\n",
        "    if check_availability:\n",
        "        availability = check_data_availability(point, start_date, end_date)\n",
        "\n",
        "        # Verificar si hay datos extraíbles\n",
        "        extractable_count = sum(1 for v in availability.values() if v.get('extractable', False))\n",
        "\n",
        "        # Si no hay datos extraíbles, sugerir fechas alternativas\n",
        "        if extractable_count < 3:  # Menos de 3 tipos de datos extraíbles\n",
        "            good_years = suggest_alternative_dates(point)\n",
        "            if good_years:\n",
        "                print(\"\\n⚠️ Continuando con la extracción original, pero es probable que no se encuentren suficientes datos.\")\n",
        "            else:\n",
        "                print(\"\\n⚠️ Continuando con la extracción, pero es probable que no se encuentren datos.\")\n",
        "\n",
        "    print(f\"⏳ Extrayendo datos desde {start_date} hasta {end_date} con frecuencia {frequency}...\")\n",
        "\n",
        "    try:\n",
        "        # Obtener datos\n",
        "        print(\"🔄 Obteniendo datos de albedo...\")\n",
        "        albedo_collection = get_albedo_data(point, start_date, end_date)\n",
        "\n",
        "        print(\"🔄 Obteniendo datos de radiación solar...\")\n",
        "        radiation_collection = get_solar_radiation_data(point, start_date, end_date)\n",
        "\n",
        "        print(\"🔄 Obteniendo datos de temperatura...\")\n",
        "        temperature_collection = get_temperature_data(point, start_date, end_date)\n",
        "\n",
        "        print(\"🔄 Obteniendo datos de viento...\")\n",
        "        # No obtenemos la colección completa aquí, se procesará en chunks\n",
        "\n",
        "        print(\"🔄 Obteniendo datos topográficos...\")\n",
        "        topo_data = get_elevation_data(point)\n",
        "\n",
        "        # Para cobertura terrestre, usar el año medio del rango\n",
        "        mid_year = start_date_dt.year + (end_date_dt.year - start_date_dt.year) // 2\n",
        "        print(f\"🔄 Obteniendo datos de cobertura terrestre para el año {mid_year}...\")\n",
        "        landcover_data = get_landcover_data(point, mid_year)\n",
        "\n",
        "        # Procesar datos\n",
        "        print(\"🔄 Procesando datos de albedo...\")\n",
        "        albedo_data = process_albedo_data(albedo_collection, point, frequency, start_date_dt, end_date_dt)\n",
        "\n",
        "        print(\"🔄 Procesando datos de radiación solar...\")\n",
        "        radiation_data = process_radiation_data(radiation_collection, point, frequency, start_date_dt, end_date_dt)\n",
        "\n",
        "        print(\"🔄 Procesando datos de temperatura...\")\n",
        "        temperature_data = process_temperature_data(temperature_collection, point, frequency, start_date_dt, end_date_dt)\n",
        "\n",
        "        print(\"🔄 Procesando datos de viento (en chunks para evitar problemas de memoria)...\")\n",
        "        wind_data = process_wind_data_chunked(point, start_date_dt, end_date_dt, frequency)\n",
        "\n",
        "        print(\"🔄 Extrayendo datos topográficos...\")\n",
        "        topo_values = extract_static_values(topo_data, point)\n",
        "\n",
        "        print(\"🔄 Extrayendo datos de cobertura terrestre...\")\n",
        "        landcover_values = {}\n",
        "        if landcover_data is not None:\n",
        "            landcover_values = extract_static_values(landcover_data, point)\n",
        "\n",
        "        # Combinar todos los datos\n",
        "        print(\"🔄 Combinando todos los datos...\")\n",
        "        merged_df = merge_all_data(albedo_data, radiation_data, temperature_data, wind_data, topo_values, landcover_values)\n",
        "\n",
        "        if merged_df.empty or 'date' not in merged_df.columns or len(merged_df) == 0:\n",
        "            print(\"❌ No se encontraron datos para el período y ubicación especificados.\")\n",
        "\n",
        "            # Sugerir fechas alternativas si no se encontraron datos\n",
        "            good_years = suggest_alternative_dates(point)\n",
        "\n",
        "            # Crear un DataFrame vacío con columna 'date' para evitar errores\n",
        "            empty_df = pd.DataFrame({'date': []})\n",
        "            empty_df.to_csv(output_filename, index=False)\n",
        "            files.download(output_filename)\n",
        "            print(f\"✅ Se ha generado un archivo CSV vacío: {output_filename}\")\n",
        "            return empty_df\n",
        "\n",
        "        # Guardar a CSV\n",
        "        print(f\"💾 Guardando datos en {output_filename}...\")\n",
        "        merged_df.to_csv(output_filename, index=False)\n",
        "\n",
        "        # Descargar archivo\n",
        "        files.download(output_filename)\n",
        "\n",
        "        print(f\"✅ ¡Completado! Los datos se han guardado y descargado como {output_filename}\")\n",
        "\n",
        "        # Mostrar algunas visualizaciones\n",
        "        print(\"\\n📊 Visualizaciones de los datos:\")\n",
        "\n",
        "        # Buscar columnas de radiación\n",
        "        radiation_cols = [col for col in merged_df.columns if 'radiation' in col.lower()]\n",
        "        if radiation_cols and not merged_df[radiation_cols[0]].isna().all():\n",
        "            plot_data(merged_df, radiation_cols[0], f'Radiación Solar ({radiation_cols[0]})', 'W/m²')\n",
        "\n",
        "        # Buscar columnas de temperatura\n",
        "        if 'temp_mean' in merged_df.columns and not merged_df['temp_mean'].isna().all():\n",
        "            plot_data(merged_df, 'temp_mean', 'Temperatura Media', '°C')\n",
        "        elif 'temp_day' in merged_df.columns and not merged_df['temp_day'].isna().all():\n",
        "            plot_data(merged_df, 'temp_day', 'Temperatura Diurna', '°C')\n",
        "\n",
        "        # Buscar columnas de albedo\n",
        "        albedo_cols = [col for col in merged_df.columns if 'bsa' in col.lower() or 'wsa' in col.lower()]\n",
        "        if albedo_cols and not merged_df[albedo_cols[0]].isna().all():\n",
        "            plot_data(merged_df, albedo_cols[0], f'Albedo ({albedo_cols[0]})', 'Albedo')\n",
        "\n",
        "        # Buscar columnas de viento\n",
        "        if 'wind_speed' in merged_df.columns and not merged_df['wind_speed'].isna().all():\n",
        "            plot_data(merged_df, 'wind_speed', 'Velocidad del Viento', 'm/s')\n",
        "\n",
        "        # Mostrar resumen de los datos\n",
        "        if not merged_df.empty and len(merged_df) > 0:\n",
        "            print(\"\\n📋 Resumen de los datos extraídos:\")\n",
        "            print(merged_df.describe())\n",
        "\n",
        "        return merged_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error durante la extracción de datos: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        # Crear un DataFrame vacío con columna 'date' para evitar errores\n",
        "        empty_df = pd.DataFrame({'date': []})\n",
        "        empty_df.to_csv(output_filename, index=False)\n",
        "        files.download(output_filename)\n",
        "        print(f\"✅ Se ha generado un archivo CSV vacío: {output_filename}\")\n",
        "        return empty_df\n"
      ],
      "metadata": {
        "id": "u3UQc_WFg5hx",
        "outputId": "c4431950-d1a1-4057-e94e-2340c8707e2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = extract_solar_data_colab(\n",
        "    lat=37.290019,\n",
        "    lon=-5.966487,\n",
        "    start_date='2018-01-01',\n",
        "    end_date='2018-12-31',\n",
        "    frequency='monthly',\n",
        "    output_filename='svq_2018_monthly.csv',\n",
        "    check_availability=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lU92_tNqX4g_",
        "outputId": "6d1546b8-7e09-48fb-cd78-15dfb2534bfb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Earth Engine inicializado correctamente.\n",
            "✅ Autenticación completada con éxito.\n",
            "📍 Ubicación seleccionada: Latitud 37.290019, Longitud -5.966487\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<folium.folium.Map at 0x7f8237e79e10>"
            ],
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_da24cbde4c1962d88a45a09928abd6a1 {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_da24cbde4c1962d88a45a09928abd6a1&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_da24cbde4c1962d88a45a09928abd6a1 = L.map(\n",
              "                &quot;map_da24cbde4c1962d88a45a09928abd6a1&quot;,\n",
              "                {\n",
              "                    center: [37.290019, -5.966487],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    ...{\n",
              "  &quot;zoom&quot;: 10,\n",
              "  &quot;zoomControl&quot;: true,\n",
              "  &quot;preferCanvas&quot;: false,\n",
              "}\n",
              "\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_1cc6574c2a515355901b1144aae4846d = L.tileLayer(\n",
              "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {\n",
              "  &quot;minZoom&quot;: 0,\n",
              "  &quot;maxZoom&quot;: 19,\n",
              "  &quot;maxNativeZoom&quot;: 19,\n",
              "  &quot;noWrap&quot;: false,\n",
              "  &quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;,\n",
              "  &quot;subdomains&quot;: &quot;abc&quot;,\n",
              "  &quot;detectRetina&quot;: false,\n",
              "  &quot;tms&quot;: false,\n",
              "  &quot;opacity&quot;: 1,\n",
              "}\n",
              "\n",
              "            );\n",
              "        \n",
              "    \n",
              "            tile_layer_1cc6574c2a515355901b1144aae4846d.addTo(map_da24cbde4c1962d88a45a09928abd6a1);\n",
              "        \n",
              "    \n",
              "            var marker_bdbc3a000e055bc4d1a041ffc54f814d = L.marker(\n",
              "                [37.290019, -5.966487],\n",
              "                {\n",
              "}\n",
              "            ).addTo(map_da24cbde4c1962d88a45a09928abd6a1);\n",
              "        \n",
              "    \n",
              "            var icon_bcec6d63d68f5eeea974c654a2830ab6 = L.AwesomeMarkers.icon(\n",
              "                {\n",
              "  &quot;markerColor&quot;: &quot;red&quot;,\n",
              "  &quot;iconColor&quot;: &quot;white&quot;,\n",
              "  &quot;icon&quot;: &quot;info-sign&quot;,\n",
              "  &quot;prefix&quot;: &quot;glyphicon&quot;,\n",
              "  &quot;extraClasses&quot;: &quot;fa-rotate-0&quot;,\n",
              "}\n",
              "            );\n",
              "        \n",
              "    \n",
              "        var popup_c989cca7d71705fc351fe677304427ad = L.popup({\n",
              "  &quot;maxWidth&quot;: &quot;100%&quot;,\n",
              "});\n",
              "\n",
              "        \n",
              "            \n",
              "                var html_464e7639ecffb50ab56df5ab097b2951 = $(`&lt;div id=&quot;html_464e7639ecffb50ab56df5ab097b2951&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Lat: 37.290019, Lon: -5.966487&lt;/div&gt;`)[0];\n",
              "                popup_c989cca7d71705fc351fe677304427ad.setContent(html_464e7639ecffb50ab56df5ab097b2951);\n",
              "            \n",
              "        \n",
              "\n",
              "        marker_bdbc3a000e055bc4d1a041ffc54f814d.bindPopup(popup_c989cca7d71705fc351fe677304427ad)\n",
              "        ;\n",
              "\n",
              "        \n",
              "    \n",
              "    \n",
              "                marker_bdbc3a000e055bc4d1a041ffc54f814d.setIcon(icon_bcec6d63d68f5eeea974c654a2830ab6);\n",
              "            \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "📊 Disponibilidad de datos de albedo: 364 imágenes en la colección, 0 extraíbles para el punto\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "📊 Disponibilidad de datos de radiación solar: 364 imágenes en la colección, 0 extraíbles para el punto\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "📊 Disponibilidad de datos de temperatura: 364 imágenes en la colección, 0 extraíbles para el punto\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "📊 Disponibilidad de datos de viento: 24 imágenes en la colección, 0 extraíbles para el punto\n",
            "📊 Disponibilidad de datos de elevación: Sí\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "📊 Disponibilidad de datos de cobertura terrestre: 1 imágenes en la colección, 0 extraíbles para el punto\n",
            "\n",
            "📋 Resumen de disponibilidad:\n",
            "  - 6/6 tipos de datos disponibles en las colecciones\n",
            "  - 1/6 tipos de datos extraíbles para el punto específico\n",
            "\n",
            "⚠️ ADVERTENCIA: Pocos tipos de datos extraíbles para esta ubicación y período.\n",
            "⚠️ El CSV resultante tendrá información limitada.\n",
            "🔍 Buscando períodos con mejor disponibilidad de datos...\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "❌ 2022: Disponibilidad limitada de datos extraíbles\n",
            "   - Albedo: ✗\n",
            "   - Radiación: ✗\n",
            "   - Temperatura: ✗\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "❌ 2021: Disponibilidad limitada de datos extraíbles\n",
            "   - Albedo: ✗\n",
            "   - Radiación: ✗\n",
            "   - Temperatura: ✗\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "❌ 2020: Disponibilidad limitada de datos extraíbles\n",
            "   - Albedo: ✗\n",
            "   - Radiación: ✗\n",
            "   - Temperatura: ✗\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "❌ 2019: Disponibilidad limitada de datos extraíbles\n",
            "   - Albedo: ✗\n",
            "   - Radiación: ✗\n",
            "   - Temperatura: ✗\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "❌ 2018: Disponibilidad limitada de datos extraíbles\n",
            "   - Albedo: ✗\n",
            "   - Radiación: ✗\n",
            "   - Temperatura: ✗\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "❌ 2017: Disponibilidad limitada de datos extraíbles\n",
            "   - Albedo: ✗\n",
            "   - Radiación: ✗\n",
            "   - Temperatura: ✗\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "⚠️ Error al probar extracción de datos: A mapped function's arguments cannot be used in client-side operations\n",
            "❌ 2016: Disponibilidad limitada de datos extraíbles\n",
            "   - Albedo: ✗\n",
            "   - Radiación: ✗\n",
            "   - Temperatura: ✗\n",
            "\n",
            "⚠️ No se encontraron años con buena disponibilidad de datos extraíbles para esta ubicación.\n",
            "⚠️ Considera probar con otra ubicación o utilizar fuentes de datos alternativas.\n",
            "\n",
            "⚠️ Continuando con la extracción, pero es probable que no se encuentren datos.\n",
            "⏳ Extrayendo datos desde 2018-01-01 hasta 2018-12-31 con frecuencia monthly...\n",
            "🔄 Obteniendo datos de albedo...\n",
            "🔄 Obteniendo datos de radiación solar...\n",
            "🔄 Obteniendo datos de temperatura...\n",
            "🔄 Obteniendo datos de viento...\n",
            "🔄 Obteniendo datos topográficos...\n",
            "🔄 Obteniendo datos de cobertura terrestre para el año 2018...\n",
            "🔄 Procesando datos de albedo...\n",
            "⚠️ No se encontraron valores válidos para el punto en ninguna de las 364 imágenes\n",
            "⚠️ No se encontraron valores válidos para el punto en ninguna de las 364 imágenes\n",
            "⚠️ No se encontraron valores válidos para el punto en ninguna de las 364 imágenes\n",
            "⚠️ No se encontraron valores válidos para el punto en ninguna de las 364 imágenes\n",
            "⚠️ No se encontraron valores válidos para el punto en ninguna de las 364 imágenes\n",
            "⚠️ No se encontraron valores válidos para el punto en ninguna de las 364 imágenes\n",
            "⚠️ Advertencia: No hay datos de albedo disponibles para el período seleccionado\n",
            "🔄 Procesando datos de radiación solar...\n",
            "⚠️ No se encontraron valores válidos para el punto en ninguna de las 364 imágenes\n",
            "⚠️ No se encontraron valores válidos para el punto en ninguna de las 364 imágenes\n",
            "⚠️ No se encontraron valores válidos para el punto en ninguna de las 364 imágenes\n",
            "⚠️ Advertencia: No hay datos de radiación solar disponibles para el período seleccionado\n",
            "🔄 Procesando datos de temperatura...\n",
            "⚠️ No se encontraron valores válidos para el punto en ninguna de las 364 imágenes\n",
            "⚠️ No se encontraron valores válidos para el punto en ninguna de las 364 imágenes\n",
            "⚠️ Advertencia: No hay datos de temperatura disponibles para el período seleccionado\n",
            "🔄 Procesando datos de viento (en chunks para evitar problemas de memoria)...\n",
            "🔄 Procesando chunk de viento 1/13: 2018-01-01 a 2018-01-30\n",
            "⚠️ No se encontraron valores válidos para el punto en ninguna de las 29 imágenes\n",
            "⚠️ No se encontraron valores válidos para el punto en ninguna de las 29 imágenes\n",
            "⚠️ No hay datos de viento disponibles para el chunk 2018-01-01 a 2018-01-30\n",
            "🔄 Procesando chunk de viento 2/13: 2018-01-31 a 2018-03-01\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-1184aa342cb8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m data = extract_solar_data_colab(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mlat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m37.290019\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5.966487\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstart_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2018-01-01'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mend_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2018-12-31'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-7111cbf89c92>\u001b[0m in \u001b[0;36mextract_solar_data_colab\u001b[0;34m(lat, lon, start_date, end_date, frequency, output_filename, check_availability)\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🔄 Procesando datos de viento (en chunks para evitar problemas de memoria)...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1381\u001b[0;31m         \u001b[0mwind_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_wind_data_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🔄 Extrayendo datos topográficos...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-7111cbf89c92>\u001b[0m in \u001b[0;36mprocess_wind_data_chunked\u001b[0;34m(point, start_date, end_date, frequency, max_chunk_days)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mu_band\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                     \u001b[0mu_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_point_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwind_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_band\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mu_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                         \u001b[0mu_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wind_u'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_band\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mu_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-7111cbf89c92>\u001b[0m in \u001b[0;36mextract_point_values\u001b[0;34m(image_collection, point, scale, band_name)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;31m# Convertir a lista para descargar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'properties'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0;31m# Filtrar resultados para eliminar valores vacíos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ee/computedobject.py\u001b[0m in \u001b[0;36mgetInfo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0mto\u001b[0m \u001b[0manything\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ee/data.py\u001b[0m in \u001b[0;36mcomputeValue\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0m_maybe_populate_workload_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m   return _execute_cloud_call(\n\u001b[0m\u001b[1;32m   1129\u001b[0m       \u001b[0m_get_cloud_projects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ee/data.py\u001b[0m in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    406\u001b[0m   \u001b[0mnum_retries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_max_retries\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum_retries\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0m_translate_cloud_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=raise-missing-from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;31m# Handle retries for server-side errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         resp, content = _retry_request(\n\u001b[0m\u001b[1;32m    924\u001b[0m             \u001b[0mhttp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0mnum_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Retry on SSL errors and socket timeout errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_ssl_SSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mssl_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google_auth_httplib2.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;31m# Make the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         response, content = self.http.request(\n\u001b[0m\u001b[1;32m    219\u001b[0m             \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ee/_cloud_api_utils.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0;31m# requests errors should be converted to kinds that googleapiclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;31m# consider transient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m       response = self._session.request(\n\u001b[0m\u001b[1;32m     71\u001b[0m           \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I_Fr0L5AFmu"
      },
      "source": [
        "## Test the API\n",
        "\n",
        "Test the API by printing the elevation of Mount Everest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7pD6pDOAhOW"
      },
      "source": [
        "# Print the elevation of Mount Everest.\n",
        "dem = ee.Image('USGS/SRTMGL1_003')\n",
        "xy = ee.Geometry.Point([86.9250, 27.9881])\n",
        "elev = dem.sample(xy, 30).first().get('elevation').getInfo()\n",
        "print('Mount Everest elevation (m):', elev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDLAqiNWeD6t"
      },
      "source": [
        "## Map visualization\n",
        "\n",
        "`ee.Image` objects can be displayed to notebook output cells. The following two\n",
        "examples demonstrate displaying a static image and an interactive map.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45BfeVygwmKm"
      },
      "source": [
        "### Static image\n",
        "\n",
        "The `IPython.display` module contains the `Image` function, which can display\n",
        "the results of a URL representing an image generated from a call to the Earth\n",
        "Engine `getThumbUrl` function. The following cell will display a thumbnail\n",
        "of the global elevation model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp4rdpy0eGjx"
      },
      "source": [
        "# Import the Image function from the IPython.display module.\n",
        "from IPython.display import Image\n",
        "\n",
        "# Display a thumbnail of global elevation.\n",
        "Image(url = dem.updateMask(dem.gt(0))\n",
        "  .getThumbURL({'min': 0, 'max': 4000, 'dimensions': 512,\n",
        "                'palette': ['006633', 'E5FFCC', '662A00', 'D8D8D8', 'F5F5F5']}))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljo5dbLkfmVm"
      },
      "source": [
        "### Interactive map\n",
        "\n",
        "The [geemap](https://github.com/gee-community/geemap)\n",
        "library can be used to display `ee.Image` objects on an interactive\n",
        "[ipyleaflet](https://github.com/jupyter-widgets/ipyleaflet) map.\n",
        "\n",
        "The following cell provides an example of using the `geemap.Map` object to\n",
        "display an elevation model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIiyf6azf4mU"
      },
      "source": [
        "# Import the geemap library.\n",
        "import geemap\n",
        "\n",
        "# Set visualization parameters.\n",
        "vis_params = {\n",
        "  'min': 0,\n",
        "  'max': 4000,\n",
        "  'palette': ['006633', 'E5FFCC', '662A00', 'D8D8D8', 'F5F5F5']}\n",
        "\n",
        "# Create a map object.\n",
        "m = geemap.Map(center=[20, 0], zoom=3)\n",
        "\n",
        "# Add the elevation model to the map object.\n",
        "m.add_ee_layer(dem.updateMask(dem.gt(0)), vis_params, 'DEM')\n",
        "\n",
        "# Display the map.\n",
        "display(m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYfinjFhg0HN"
      },
      "source": [
        "## Chart visualization\n",
        "\n",
        "Some Earth Engine functions produce tabular data that can be plotted by\n",
        "data visualization packages such as `matplotlib`. The following example\n",
        "demonstrates the display of tabular data from Earth Engine as a scatter\n",
        "plot. See [Charting in Colaboratory](https://colab.sandbox.google.com/notebooks/charts.ipynb)\n",
        "for more information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRPULejJhBSl"
      },
      "source": [
        "# Import the matplotlib.pyplot module.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fetch a Landsat TOA image.\n",
        "img = ee.Image('LANDSAT/LT05/C02/T1_TOA/LT05_034033_20000913')\n",
        "\n",
        "# Select Red and NIR bands and sample 500 points.\n",
        "samp_fc = img.select(['B3','B4']).sample(scale=30, numPixels=500)\n",
        "\n",
        "# Arrange the sample as a list of lists.\n",
        "samp_dict = samp_fc.reduceColumns(ee.Reducer.toList().repeat(2), ['B3', 'B4'])\n",
        "samp_list = ee.List(samp_dict.get('list'))\n",
        "\n",
        "# Save server-side ee.List as a client-side Python list.\n",
        "samp_data = samp_list.getInfo()\n",
        "\n",
        "# Display a scatter plot of Red-NIR sample pairs using matplotlib.\n",
        "plt.scatter(samp_data[0], samp_data[1], alpha=0.2)\n",
        "plt.xlabel('Red', fontsize=12)\n",
        "plt.ylabel('NIR', fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}